

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>3. Word and Sentence Embedding &mdash; GenAI: Best Practices 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />

  
    <link rel="shortcut icon" href="_static/icon.ico"/>
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Prompt Engineering" href="prompt.html" />
    <link rel="prev" title="2. Preliminary" href="prelim.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            GenAI: Best Practices
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="preface.html">1. Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="prelim.html">2. Preliminary</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. Word and Sentence Embedding</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#bag-of-word">3.1. Bag-of-Word</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#one-hot-encoder">3.1.1. One Hot Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#countvectorizer">3.1.2. CountVectorizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tf-idf">3.2. TF-IDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="#word2vec">3.3. Word2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="#glove">3.4. GloVE</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fast-text">3.5. Fast Text</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bert">3.6. BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="prompt.html">4. Prompt Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="rag.html">5. Retrieval-Augmented Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="finetuning.html">6. Fine Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretraining.html">7. Pre-training</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">8. Main Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GenAI: Best Practices</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">3. </span>Word and Sentence Embedding</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/embedding.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="word-and-sentence-embedding">
<span id="embedding"></span><h1><span class="section-number">3. </span>Word and Sentence Embedding<a class="headerlink" href="#word-and-sentence-embedding" title="Link to this heading"></a></h1>
<p>Word embedding is a method in natural language processing (NLP) to represent words as dense
vectors of real numbers, capturing semantic relationships between them. Instead of treating
words as discrete symbols (like one-hot encoding), word embeddings map words into a
continuous vector space where similar words are located closer together.</p>
<figure class="align-center" id="id1">
<span id="fig-logo"></span><img alt="_images/embedding_diagram.png" src="_images/embedding_diagram.png" />
<figcaption>
<p><span class="caption-text">Embedding Diagram</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="bag-of-word">
<h2><span class="section-number">3.1. </span>Bag-of-Word<a class="headerlink" href="#bag-of-word" title="Link to this heading"></a></h2>
<p><strong>Bag of Words (BoW)</strong> is a simple and widely used text representation technique in natural language processing (NLP). It represents a text (e.g., a document or a sentence) as a collection of words, ignoring grammar, order, and context but keeping their frequency.</p>
<p>Key Features of Bag of Words:</p>
<ol class="arabic simple">
<li><p><strong>Vocabulary Creation</strong>:
- A list of all unique words in the dataset (the “vocabulary”) is created.
- Each word becomes a feature.</p></li>
<li><p><strong>Representation</strong>:
- Each document is represented as a vector or a frequency count of words from the vocabulary.
- If a word from the vocabulary is present in the document, its count is included in the vector.
- Words not present in the document are assigned a count of zero.</p></li>
<li><p><strong>Simplicity</strong>:
- The method is computationally efficient and straightforward.
- However, it ignores the sequence and semantic meaning of the words.</p></li>
</ol>
<p>Applications:</p>
<ul class="simple">
<li><p>Text Classification</p></li>
<li><p>Sentiment Analysis</p></li>
<li><p>Document Similarity</p></li>
</ul>
<p>Limitations:</p>
<ol class="arabic simple">
<li><p><strong>Context Ignorance</strong>:
- BoW does not capture word order or semantics.
- For example, “not good” and “good” might appear similar in BoW.</p></li>
<li><p><strong>Dimensionality</strong>:
- As the vocabulary size increases, the vector representation grows, leading to high-dimensional data.</p></li>
<li><p><strong>Sparse Representations</strong>:
- Many entries in the vectors might be zeros, leading to sparsity.</p></li>
</ol>
<section id="one-hot-encoder">
<h3><span class="section-number">3.1.1. </span>One Hot Encoder<a class="headerlink" href="#one-hot-encoder" title="Link to this heading"></a></h3>
</section>
<section id="countvectorizer">
<h3><span class="section-number">3.1.2. </span>CountVectorizer<a class="headerlink" href="#countvectorizer" title="Link to this heading"></a></h3>
<p>To overcome these limitations, advanced techniques like <strong>TF-IDF</strong>, <strong>word embeddings</strong> (e.g., Word2Vec, GloVe), and contextual embeddings (e.g., BERT) are often used.</p>
</section>
</section>
<section id="tf-idf">
<h2><span class="section-number">3.2. </span>TF-IDF<a class="headerlink" href="#tf-idf" title="Link to this heading"></a></h2>
</section>
<section id="word2vec">
<h2><span class="section-number">3.3. </span>Word2Vec<a class="headerlink" href="#word2vec" title="Link to this heading"></a></h2>
</section>
<section id="glove">
<h2><span class="section-number">3.4. </span>GloVE<a class="headerlink" href="#glove" title="Link to this heading"></a></h2>
</section>
<section id="fast-text">
<h2><span class="section-number">3.5. </span>Fast Text<a class="headerlink" href="#fast-text" title="Link to this heading"></a></h2>
</section>
<section id="bert">
<h2><span class="section-number">3.6. </span>BERT<a class="headerlink" href="#bert" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="prelim.html" class="btn btn-neutral float-left" title="2. Preliminary" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="prompt.html" class="btn btn-neutral float-right" title="4. Prompt Engineering" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Wenqiang Feng and Di Zhen.
      <span class="lastupdated">Last updated on Dec 10, 2024.
      </span></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>