%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,11pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{2}



\title{GenAI: Best Practices}
\date{December 24, 2024}
\release{1.0}
\author{Wenqiang Feng, Di Zhen and Wenyun Wang}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{logo.png}\par}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}\phantomsection\label{\detokenize{index:index}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{logo}.png}
\end{figure}
\end{quote}

\sphinxAtStartPar
Welcome to our \sphinxstylestrong{GenAI: Best Practices}!!! For each chapter, we provide detailed
Colab notebooks \sphinxincludegraphics{{colab-badge}.png} that you can open and run directly in Google Colab.
The PDF version can be downloaded from \sphinxhref{../latex/GenAI.pdf}{HERE}.



\sphinxstepscope


\chapter{Preface}
\label{\detokenize{preface:id1}}\label{\detokenize{preface::doc}}

\section{About}
\label{\detokenize{preface:about}}

\subsection{About this book}
\label{\detokenize{preface:about-this-book}}
\sphinxAtStartPar
This is the book for our Generative AI: Best practics \sphinxcite{reference:genai}.
The PDF version can be downloaded from \sphinxhref{../latex/GenAI.pdf}{HERE}.
\sphinxstylestrong{You may download and distribute it. Please beaware,
however, that the note contains typos as well as inaccurate or incorrect description.}

\sphinxAtStartPar
In this book, we aim to demonstrate best practices for Generative AI
through detailed demo code and practical examples. For each chapter, we provide detailed
Colab notebooks \sphinxincludegraphics{{colab-badge}.png} that you can open and run directly in Google Colab.


\subsection{About the authors}
\label{\detokenize{preface:about-the-authors}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Authors}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Wenqiang Feng}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Sr. Mgr Data Enginner and PhD in Mathematics

\item {} 
\sphinxAtStartPar
University of Tennessee at Knoxville

\item {} 
\sphinxAtStartPar
Webpage: \sphinxurl{https://github.com/runawayhorse001}

\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:von198@gmail.com}{von198@gmail.com}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Di Zhen}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Sr. Analyst \sphinxhyphen{} Data Science and M.S. in Computational Biology

\item {} 
\sphinxAtStartPar
Harvard University

\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:dizhen318@gmail.com}{dizhen318@gmail.com}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Wenyun Wang}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Ph.D. candidate in Applied Physics

\item {} 
\sphinxAtStartPar
Harvard University

\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:wenyunw08@gmail.com}{wenyunw08@gmail.com}

\end{itemize}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Biography}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Wenqiang Feng} is the Senior Manager of Data Engineering and former Director of
AI Engineering/Data Science at American Express (AMEX). Before his tenure at
AMEX, Dr. Feng served as a Senior Data Scientist in the Machine Learning Lab
at H\&R Block and as a Data Scientist at Applied Analytics Group, DST (now SS\&C).
Throughout his career, Dr. Feng has focused on equipping clients with cutting\sphinxhyphen{}edge
skills and technologies, including Big Data analytics, advanced modeling
techniques, and data enhancement strategies.

\sphinxAtStartPar
Dr. Feng brings extensive expertise in data mining, analytic systems, machine
learning algorithms, business intelligence, and the application of Big Data
tools to solve complex, cross\sphinxhyphen{}functional industry challenges. Prior to his
role at DST, Dr. Feng was an IMA Data Science Fellow at the Institute for
Mathematics and its Applications (IMA) at the University of Minnesota.
In this capacity, he collaborated with startups to develop predictive
analytics solutions that informed strategic marketing decisions.

\sphinxAtStartPar
Dr. Feng holds a Ph.D. in Computational Mathematics and a Master’s degree
in Statistics from the University of Tennessee, Knoxville. He also earned a
Master’s degree in Computational Mathematics from Missouri University
of Science and Technology (MST) and a Master’s degree in Applied
Mathematics from the University of Science and Technology of China (USTC).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Di Zhen} is a Senior Data Science Analyst at American Express, where she
drives impactful business decisions by leveraging advanced analytics and
cutting\sphinxhyphen{}edge technologies. Her expertise spans causal inference, predictive
modeling, natural language processing, and generative AI, with a focus on
empowering sales enablement through data\sphinxhyphen{}driven insights.

\sphinxAtStartPar
Di earned her Master of Science in Computational Biology and Quantitative
Genetics from Harvard University in 2023, where she developed a robust
foundation in computation and statistical analysis. Passionate about
solving complex, real\sphinxhyphen{}world problems, she combines technical precision
with innovative thinking to deliver actionable solutions that enhance
business performance and customer experiences. Dedicated to continuous
learning, Di is committed to staying at the fore front of data science
advancements to unlock new possibilities.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Wenyun Wang} is currently a Ph.D. candidate in Applied Physics at
Harvard University. She also holds a Master’s degree in Computational
Science and Engineering from Harvard University. Her research interests
lie at the intersection of data science, machine learning, and
generative AI, with a focus on solving practical problems in scientific
research and real\sphinxhyphen{}world applications. She is passionate about leveraging
advanced computational techniques to extract insights from complex data
and drive innovation across diverse domains.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Declaration}

\sphinxAtStartPar
The work of Wenqiang Feng was supported by the IMA, while working at IMA. However, any opinion, finding,
and conclusions or recommendations expressed in this material are those of the author and do not necessarily
reflect the views of the IMA, UTK and DST.

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
ChatGPT has been extensively used in the creation of this book. If you notice that your work has not been
cited or has been cited incorrectly, please notify us.
\end{sphinxadmonition}

\end{itemize}


\section{Feedback and suggestions}
\label{\detokenize{preface:feedback-and-suggestions}}
\sphinxAtStartPar
Your comments and suggestions are highly appreciated. I am more than happy to receive
corrections, suggestions or feedback through email (Wenqiang Feng: \sphinxhref{mailto:von198@gmail.com}{von198@gmail.com},
Di Zhen: \sphinxhref{mailto:dizhen318@gmail.com}{dizhen318@gmail.com} and Wenyun Wang: \sphinxhref{mailto:wenyunw08@gmail.com}{wenyunw08@gmail.com}) for improvements.

\sphinxstepscope


\chapter{Preliminary}
\label{\detokenize{prelim:preliminary}}\label{\detokenize{prelim:prelim}}\label{\detokenize{prelim::doc}}
\begin{sphinxadmonition}{note}{Chinese proverb}

\sphinxAtStartPar
A journey of a thousand miles begins with a single step. \textendash{} Lao Tzu
\end{sphinxadmonition}

\sphinxAtStartPar
In this chapter, we will introduce some math and NLP preliminaries which are highly
used in Generative AI.

\begin{sphinxadmonition}{note}{Colab Notebook for This Chapter}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Math Preliminary: \sphinxhref{https://colab.research.google.com/drive/1V\_mBtDF1tTBv06-ipmkoeBWZ9JU-rnni?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Ollama in Colab: \sphinxhref{https://colab.research.google.com/drive/1tALgzu-v6NnN5yUCY7fvyWehuPwQ9rHG?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
BERT Tokenization: \sphinxhref{https://colab.research.google.com/drive/16JUj0Tk8zBuCnZLGtN6kHHzwT-p4Ggr6?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\end{sphinxadmonition}


\section{Math Preliminary}
\label{\detokenize{prelim:math-preliminary}}

\subsection{Vector}
\label{\detokenize{prelim:vector}}
\sphinxAtStartPar
A vector is a mathematical representation of data characterized by both magnitude and
direction. In this context, each data point is represented as a feature vector, with
each component corresponding to a specific feature or attribute of the data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{gensim}\PYG{n+nn}{.}\PYG{n+nn}{downloader} \PYG{k}{as} \PYG{n+nn}{api}
\PYG{c+c1}{\PYGZsh{} Download pre\PYGZhy{}trained GloVe model}
\PYG{n}{glove\PYGZus{}vectors} \PYG{o}{=} \PYG{n}{api}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{glove\PYGZhy{}twitter\PYGZhy{}25}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Get word vectors (embeddings)}
\PYG{n}{word1} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{king}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{word2} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{queen}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} embedding}
\PYG{n}{king} \PYG{o}{=} \PYG{n}{glove\PYGZus{}vectors}\PYG{p}{[}\PYG{n}{word1}\PYG{p}{]}
\PYG{n}{queen} \PYG{o}{=} \PYG{n}{glove\PYGZus{}vectors}\PYG{p}{[}\PYG{n}{word2}\PYG{p}{]}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{king:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{king}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{queen:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{queen}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{king}\PYG{p}{:}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.74501}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11992}   \PYG{l+m+mf}{0.37329}   \PYG{l+m+mf}{0.36847}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.4472}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2288}    \PYG{l+m+mf}{0.70118}
\PYG{l+m+mf}{0.82872}   \PYG{l+m+mf}{0.39486}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.58347}   \PYG{l+m+mf}{0.41488}   \PYG{l+m+mf}{0.37074}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.6906}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20101}
\PYG{l+m+mf}{0.11472}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.34661}   \PYG{l+m+mf}{0.36208}   \PYG{l+m+mf}{0.095679} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01765}   \PYG{l+m+mf}{0.68498}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.049013}
\PYG{l+m+mf}{0.54049}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.21005}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.65397}   \PYG{l+m+mf}{0.64556} \PYG{p}{]}
\PYG{n}{queen}\PYG{p}{:}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.1266}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.52064}   \PYG{l+m+mf}{0.45565}   \PYG{l+m+mf}{0.21079}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05081}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.65158}   \PYG{l+m+mf}{1.1395}
\PYG{l+m+mf}{0.69897}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20612}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.71803}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02811}   \PYG{l+m+mf}{0.10977}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.3089}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.49299}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.51375}   \PYG{l+m+mf}{0.10363}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11764}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.084972}  \PYG{l+m+mf}{0.02558}   \PYG{l+m+mf}{0.6859}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.29196}
\PYG{l+m+mf}{0.4594}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.39955}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.40371}   \PYG{l+m+mf}{0.31828} \PYG{p}{]}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vector}.png}
\caption{Vector}\label{\detokenize{prelim:id2}}\label{\detokenize{prelim:fig-logo}}\end{figure}


\subsection{Norm}
\label{\detokenize{prelim:norm}}
\sphinxAtStartPar
A norm is a function that maps a vector to a single positive value, representing its
magnitude. Norms are essential for calculating distances between vectors, which play
a crucial role in measuring prediction errors, performing feature selection, and
applying regularization techniques in models.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{1Bauo}.png}
\caption{Geometrical Interpretation of Norm (\sphinxhref{https://math.stackexchange.com/questions/805954/what-does-the-dot-product-of-two-vectors-represent}{source\_1})}\label{\detokenize{prelim:id3}}\label{\detokenize{prelim:fig-1bauo}}\end{figure}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Formula:
\begin{quote}

\sphinxAtStartPar
The \(\displaystyle \ell^p\) norm for \(\vec{v} = (v_1, v_2, \cdots, v_n)\) is
\begin{equation*}
\begin{split}||\vec{v}||_p = \sqrt[p]{|v_1|^p + |v_2|^p + \cdots +|v_n|^p }\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
\(\displaystyle \ell^1\) norm: Sum of absolute values of vector components, often used for feature selection due to its tendency to produce sparse solutions.
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} l1 norm}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{king}\PYG{p}{,}\PYG{n+nb}{ord}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}    max(sum(abs(x), axis=0))}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} 13.188952}
\end{sphinxVerbatim}
\end{quote}

\item {} 
\sphinxAtStartPar
\(\displaystyle \ell^2\) norm: Square root of the sum of squared vector components, the most common norm used in many machine learning algorithms.
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} l2 norm}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{king}\PYG{p}{,}\PYG{n+nb}{ord}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} 4.3206835}
\end{sphinxVerbatim}
\end{quote}

\item {} 
\sphinxAtStartPar
\(\displaystyle \ell^\infty\) norm (Maximum norm): The largest absolute value of a vector component.

\end{itemize}


\subsection{Distances}
\label{\detokenize{prelim:distances}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Manhattan Distance (\(\displaystyle \ell^1\) Distance)
\begin{quote}

\sphinxAtStartPar
Also known as taxicab or city block distance, Manhattan distance measures the absolute differences
between the components of two vectors. It represents the distance a point would travel along grid
lines in a Cartesian plane, similar to navigating through city streets.

\sphinxAtStartPar
For two vector \(\vec{u} = (u_1, u_2, \cdots, u_n)\) and \(\vec{v} = (v_1, v_2, \cdots, v_n)\), the
Manhattan Distance distance \(d(\vec{u},\vec{v})\) is
\begin{equation*}
\begin{split}d(\vec{u},\vec{v}) = ||\vec{u}-\vec{v}||_1 = |u_1-v_1| + |u_2-v_2|+ \cdots +|u_n-v_n|\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Euclidean Distance (\(\displaystyle \ell^2\) Distance)
\begin{quote}

\sphinxAtStartPar
Euclidean distance is the most common way to measure the distance between two points (vectors) in space.
It is essentially the straight\sphinxhyphen{}line distance between them, calculated using the Pythagorean theorem.

\sphinxAtStartPar
For two vector \(\vec{u} = (u_1, u_2, \cdots, u_n)\) and \(\vec{v} = (v_1, v_2, \cdots, v_n)\), the
Euclidean Distance distance \(d(\vec{u},\vec{v})\) is
\begin{equation*}
\begin{split}d(\vec{u},\vec{v}) = ||\vec{u}-\vec{v}||_2 = \sqrt{(u_1-v_1)^2 + (u_2-v_2)^2+ \cdots +(u_n-v_n)^2}\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Minkowski Distance (\(\displaystyle \ell^p\) Distance)
\begin{quote}

\sphinxAtStartPar
Minkowski distance is a generalization of both Euclidean and Manhattan distances. It incorporates a parameter,
\(p\), which allows for adjusting the sensitivity of the distance metric.
\end{quote}

\item {} 
\sphinxAtStartPar
Cos Similarity
\begin{quote}

\sphinxAtStartPar
Cosine similarity measures the angle between two vectors rather than their straight\sphinxhyphen{}line distance.
It evaluates the similarity of two vectors by focusing on their orientation rather than their magnitude.
This makes it particularly useful for high\sphinxhyphen{}dimensional data, such as text, where the direction of the
vectors is often more significant than their magnitude.

\sphinxAtStartPar
The Cos similarity for two vector \(\vec{u} = (u_1, u_2, \cdots, u_n)\) and \(\vec{v} = (v_1, v_2, \cdots, v_n)\) is
\begin{equation*}
\begin{split}cos(\theta) = \frac{\vec{u}\cdot\vec{v}}{||\vec{u}|| ||\vec{v}||}\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
1 means the vectors point in exactly the same direction (perfect similarity).

\item {} 
\sphinxAtStartPar
0 means they are orthogonal (no similarity).

\item {} 
\sphinxAtStartPar
\sphinxhyphen{}1 means they point in opposite directions (complete dissimilarity).

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute cosine similarity between the two word vectors}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{king}\PYG{p}{,}\PYG{n}{queen}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{king}\PYG{p}{)}\PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{queen}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} 0.92024213}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute cosine similarity between the two word vectors}
\PYG{n}{similarity} \PYG{o}{=} \PYG{n}{glove\PYGZus{}vectors}\PYG{o}{.}\PYG{n}{similarity}\PYG{p}{(}\PYG{n}{word1}\PYG{p}{,} \PYG{n}{word2}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Word vectors for }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{king}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Word vectors for }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word2}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{queen}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cosine similarity between }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word2}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{similarity}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Word} \PYG{n}{vectors} \PYG{k}{for} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{king}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.74501}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11992}   \PYG{l+m+mf}{0.37329}   \PYG{l+m+mf}{0.36847}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.4472}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2288}    \PYG{l+m+mf}{0.70118}
\PYG{l+m+mf}{0.82872}   \PYG{l+m+mf}{0.39486}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.58347}   \PYG{l+m+mf}{0.41488}   \PYG{l+m+mf}{0.37074}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.6906}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20101}
\PYG{l+m+mf}{0.11472}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.34661}   \PYG{l+m+mf}{0.36208}   \PYG{l+m+mf}{0.095679} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01765}   \PYG{l+m+mf}{0.68498}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.049013}
\PYG{l+m+mf}{0.54049}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.21005}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.65397}   \PYG{l+m+mf}{0.64556} \PYG{p}{]}
\PYG{n}{Word} \PYG{n}{vectors} \PYG{k}{for} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{queen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.1266}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.52064}   \PYG{l+m+mf}{0.45565}   \PYG{l+m+mf}{0.21079}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05081}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.65158}   \PYG{l+m+mf}{1.1395}
\PYG{l+m+mf}{0.69897}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20612}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.71803}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02811}   \PYG{l+m+mf}{0.10977}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.3089}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.49299}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.51375}   \PYG{l+m+mf}{0.10363}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11764}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.084972}  \PYG{l+m+mf}{0.02558}   \PYG{l+m+mf}{0.6859}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.29196}
\PYG{l+m+mf}{0.4594}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.39955}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.40371}   \PYG{l+m+mf}{0.31828} \PYG{p}{]}
\PYG{n}{Cosine} \PYG{n}{similarity} \PYG{n}{between} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{king}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o+ow}{and} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{queen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.920242190361023}
\end{sphinxVerbatim}
\end{quote}

\end{itemize}


\section{NLP Preliminary}
\label{\detokenize{prelim:nlp-preliminary}}

\subsection{Vocabulary}
\label{\detokenize{prelim:vocabulary}}
\sphinxAtStartPar
In Natural Language Processing (NLP), \sphinxstylestrong{vocabulary} refers to the complete set of unique words or tokens
that a model recognizes or works with during training and inference. Vocabulary plays a critical role in
text processing and understanding, as it defines the scope of linguistic units a model can handle.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Types of Vocabulary in NLP
\begin{quote}

\sphinxAtStartPar
1. \sphinxstylestrong{Word\sphinxhyphen{}level Vocabulary}:
\sphinxhyphen{} Each word in the text is treated as a unique token.
\sphinxhyphen{} For example, the sentence “I love NLP” would generate the vocabulary: \sphinxcode{\sphinxupquote{\{I, love, NLP\}}}.

\sphinxAtStartPar
2. \sphinxstylestrong{Subword\sphinxhyphen{}level Vocabulary}:
\sphinxhyphen{} Text is broken down into smaller units like prefixes, suffixes, or character sequences.
\sphinxhyphen{} For example, the word “loving” might be split into \sphinxcode{\sphinxupquote{\{lov, ing\}}} using techniques like Byte Pair Encoding (BPE) or SentencePiece.
\sphinxhyphen{} Subword vocabularies handle rare or unseen words more effectively.

\sphinxAtStartPar
3. \sphinxstylestrong{Character\sphinxhyphen{}level Vocabulary}:
\sphinxhyphen{} Each character is treated as a token.
\sphinxhyphen{} For example, the word “love” would generate the vocabulary: \sphinxcode{\sphinxupquote{\{l, o, v, e\}}}.
\end{quote}

\item {} 
\sphinxAtStartPar
Importance of Vocabulary
\begin{quote}

\sphinxAtStartPar
1. \sphinxstylestrong{Text Representation}:
\sphinxhyphen{} Vocabulary is the basis for converting text into numerical representations like one\sphinxhyphen{}hot vectors, embeddings, or input IDs for machine learning models.

\sphinxAtStartPar
2. \sphinxstylestrong{Model Efficiency}:
\sphinxhyphen{} A larger vocabulary increases the model’s memory and computational requirements.
\sphinxhyphen{} A smaller vocabulary may lack the capacity to represent all words effectively, leading to a loss of meaning.

\sphinxAtStartPar
3. \sphinxstylestrong{Handling Out\sphinxhyphen{}of\sphinxhyphen{}Vocabulary (OOV) Words}:
\sphinxhyphen{} Words not present in the vocabulary are either replaced with a special token like \sphinxcode{\sphinxupquote{\textless{}UNK\textgreater{}}} or processed using subword/character\sphinxhyphen{}based techniques.
\end{quote}

\item {} 
\sphinxAtStartPar
Building a Vocabulary
\begin{quote}

\sphinxAtStartPar
Common practices include:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Tokenizing the text into words, subwords, or characters.

\item {} 
\sphinxAtStartPar
Counting the frequency of tokens.

\item {} 
\sphinxAtStartPar
Keeping only the most frequent tokens up to a predefined size (e.g., top 50,000 tokens).

\item {} 
\sphinxAtStartPar
Adding special tokens like \sphinxcode{\sphinxupquote{\textless{}PAD\textgreater{}}}, \sphinxcode{\sphinxupquote{\textless{}UNK\textgreater{}}}, \sphinxcode{\sphinxupquote{\textless{}BOS\textgreater{}}} (beginning of sentence), and \sphinxcode{\sphinxupquote{\textless{}EOS\textgreater{}}} (end of sentence).

\end{enumerate}
\end{quote}

\item {} 
\sphinxAtStartPar
Challenges

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Balancing Vocabulary Size}:
A larger vocabulary increases the richness of representation but requires more computational resources.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Domain\sphinxhyphen{}specific Vocabularies}:
In specialized fields like medicine or law, standard vocabularies may not be sufficient, requiring domain\sphinxhyphen{}specific tokenization strategies.

\end{itemize}


\subsection{Tagging}
\label{\detokenize{prelim:tagging}}
\sphinxAtStartPar
Tagging in NLP refers to the process of assigning labels or annotations
to words, phrases, or other linguistic units in a text. These labels provide additional information about
the syntactic, semantic, or structural role of the elements in the text.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Types of Tagging
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Part\sphinxhyphen{}of\sphinxhyphen{}Speech (POS) Tagging}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Assigns grammatical tags (e.g., noun, verb, adjective) to each word in a sentence.

\item {} 
\sphinxAtStartPar
Example: For the sentence “The dog barks,” the tags might be:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{The/DET}} (Determiner)
\sphinxhyphen{} \sphinxcode{\sphinxupquote{dog/NOUN}} (Noun)
\sphinxhyphen{} \sphinxcode{\sphinxupquote{barks/VERB}} (Verb).

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Named Entity Recognition (NER) Tagging}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Identifies and classifies named entities in a text, such as names of people, organizations, locations, dates, or monetary values.

\item {} 
\sphinxAtStartPar
Example: In the sentence “John works at Google in California,” the tags might be:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{John/PERSON}}
\sphinxhyphen{} \sphinxcode{\sphinxupquote{Google/ORGANIZATION}}
\sphinxhyphen{} \sphinxcode{\sphinxupquote{California/LOCATION}}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Chunking (Syntactic Tagging)}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Groups words into syntactic chunks like noun phrases (NP) or verb phrases (VP).

\item {} 
\sphinxAtStartPar
Example: For the sentence “The quick brown fox jumps,” a chunking result might be:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{{[}NP The quick brown fox{]} {[}VP jumps{]}}}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Sentiment Tagging}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Assigns sentiment labels (e.g., positive, negative, neutral) to words, phrases, or entire documents.

\item {} 
\sphinxAtStartPar
Example: The word “happy” might be tagged as \sphinxcode{\sphinxupquote{positive}}, while “sad” might be tagged as \sphinxcode{\sphinxupquote{negative}}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dependency Parsing Tags}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Identifies the grammatical relationships between words in a sentence, such as subject, object, or modifier.

\item {} \begin{description}
\sphinxlineitem{Example: In “She enjoys cooking,” the tags might show:}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{She/nsubj}} (nominal subject)

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{enjoys/ROOT}} (root of the sentence)

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{cooking/dobj}} (direct object).

\end{itemize}

\end{description}

\end{itemize}

\end{enumerate}

\item {} 
\sphinxAtStartPar
Importance of Tagging
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Understanding Language Structure}: Tags help NLP models understand the grammatical and syntactic structure of text.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Improving Downstream Tasks}: Tagging is foundational for tasks like machine
translation, sentiment analysis, question answering, and summarization.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Feature Engineering}: Tags serve as features for training machine learning models in
text classification or sequence labeling tasks.

\end{itemize}

\item {} 
\sphinxAtStartPar
Tagging Techniques
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Rule\sphinxhyphen{}based Tagging}: Relies on predefined linguistic rules to assign tags.
Example: Using dictionaries or regular expressions to match specific patterns.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Statistical Tagging}: Uses probabilistic models like Hidden Markov Models (HMMs)
to predict tags based on word sequences.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Neural Network\sphinxhyphen{}based Tagging}: Employs deep learning models like LSTMs, GRUs, or Transformers
to tag text with high accuracy.

\end{enumerate}

\item {} 
\sphinxAtStartPar
Challenges
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Ambiguity}:Words with multiple meanings can lead to incorrect tagging.
Example: The word “bank” could mean a financial institution or a riverbank.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Domain\sphinxhyphen{}Specific Language}: General tagging models may fail to perform well on specialized text
like medical or legal documents.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Data Sparsity}: Rare words or phrases may lack sufficient training data for accurate tagging.

\end{itemize}

\end{itemize}


\subsection{Lemmatization}
\label{\detokenize{prelim:lemmatization}}
\sphinxAtStartPar
Lemmatization in NLP is the process of reducing a word to its base or dictionary form, known as
the \sphinxstylestrong{lemma}. Unlike stemming, which simply removes word suffixes, lemmatization considers
the context and grammatical role of the word to produce a linguistically accurate root form.
\begin{itemize}
\item {} 
\sphinxAtStartPar
How Lemmatization Works
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Contextual Analysis}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lemmatization relies on a vocabulary (lexicon) and morphological analysis to identify a word’s base form.

\item {} 
\sphinxAtStartPar
For example:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{running}} \(\rightarrow\) \sphinxcode{\sphinxupquote{run}}
\sphinxhyphen{} \sphinxcode{\sphinxupquote{better}} \(\rightarrow\) \sphinxcode{\sphinxupquote{good}}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Part\sphinxhyphen{}of\sphinxhyphen{}Speech (POS) Tagging}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The process uses POS tags to determine the correct lemma for a word.

\item {} 
\sphinxAtStartPar
Example:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{barking}} (verb) \(\rightarrow\) \sphinxcode{\sphinxupquote{bark}}
\sphinxhyphen{} \sphinxcode{\sphinxupquote{barking}} (adjective, as in “barking dog”) \(\rightarrow\) \sphinxcode{\sphinxupquote{barking}}.

\end{itemize}

\end{enumerate}

\item {} 
\sphinxAtStartPar
Importance of Lemmatization
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Improves Text Normalization}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lemmatization helps normalize text by grouping different forms of a word into a single representation.

\item {} 
\sphinxAtStartPar
Example:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{run}}, \sphinxcode{\sphinxupquote{running}}, and \sphinxcode{\sphinxupquote{ran}} \(\rightarrow\) \sphinxcode{\sphinxupquote{run}}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Enhances NLP Applications}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lemmatized text improves the performance of tasks like information retrieval, text classification, and sentiment analysis.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Reduces Vocabulary Size}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
By mapping inflected forms to their base form, lemmatization reduces redundancy in text, resulting in a smaller vocabulary.

\end{itemize}

\end{enumerate}

\item {} 
\sphinxAtStartPar
Lemmatization vs. Stemming
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Lemmatization}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Produces linguistically accurate root forms.

\item {} 
\sphinxAtStartPar
Considers the word’s context and POS.

\item {} 
\sphinxAtStartPar
Example:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{studies}} \(\rightarrow\) \sphinxcode{\sphinxupquote{study}}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Stemming}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Applies heuristic rules to strip word suffixes without considering context.

\item {} 
\sphinxAtStartPar
May produce non\sphinxhyphen{}dictionary forms.

\item {} 
\sphinxAtStartPar
Example:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{studies}} \(\rightarrow\) \sphinxcode{\sphinxupquote{studi}}.

\end{itemize}

\end{itemize}

\item {} 
\sphinxAtStartPar
Techniques for Lemmatization
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Rule\sphinxhyphen{}Based Lemmatization}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Relies on predefined linguistic rules and dictionaries.

\item {} 
\sphinxAtStartPar
Example: WordNet\sphinxhyphen{}based lemmatizers.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Statistical Lemmatization}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Uses probabilistic models to predict lemmas based on the context.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Deep Learning\sphinxhyphen{}Based Lemmatization}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Employs neural networks and sequence\sphinxhyphen{}to\sphinxhyphen{}sequence models for highly accurate lemmatization in complex contexts.

\end{itemize}

\end{enumerate}

\item {} 
\sphinxAtStartPar
Challenges
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Ambiguity}:
Words with multiple meanings may result in incorrect lemmatization without proper context.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Example:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{left}} (verb) \(\rightarrow\) \sphinxcode{\sphinxupquote{leave}}
\sphinxhyphen{} \sphinxcode{\sphinxupquote{left}} (noun/adjective) \(\rightarrow\) \sphinxcode{\sphinxupquote{left}}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Language\sphinxhyphen{}Specific Complexity}:
Lemmatization rules vary widely across languages, requiring language\sphinxhyphen{}specific tools and resources.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Resource Dependency}:
Lemmatizers require extensive lexicons and morphological rules, which can be resource\sphinxhyphen{}intensive to develop.

\end{itemize}

\end{itemize}


\subsection{Tokenization}
\label{\detokenize{prelim:tokenization}}
\sphinxAtStartPar
Tokenization in NLP refers to the process of splitting a text into smaller units, called \sphinxstylestrong{tokens}, which
can be words, subwords, sentences, or characters. These tokens serve as the basic building blocks for further
analysis in NLP tasks.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Types of Tokenization
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Word Tokenization}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Splits the text into individual words or terms.

\item {} \begin{description}
\sphinxlineitem{Example:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Sentence: “I love NLP.”

\item {} 
\sphinxAtStartPar
Tokens: \sphinxcode{\sphinxupquote{{[}"I", "love", "NLP"{]}}}.

\end{itemize}

\end{description}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Sentence Tokenization}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Divides a text into sentences.

\item {} \begin{description}
\sphinxlineitem{Example:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Text: “I love NLP. It’s amazing.”

\item {} 
\sphinxAtStartPar
Tokens: \sphinxcode{\sphinxupquote{{[}"I love NLP.", "It’s amazing."{]}}}.

\end{itemize}

\end{description}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Subword Tokenization}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Breaks words into smaller units, often using methods like Byte Pair Encoding (BPE) or SentencePiece.

\item {} \begin{description}
\sphinxlineitem{Example:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Word: \sphinxcode{\sphinxupquote{unhappiness}}.

\item {} 
\sphinxAtStartPar
Tokens: \sphinxcode{\sphinxupquote{{[}"un", "happiness"{]}}} (or subword units like \sphinxcode{\sphinxupquote{{[}"un", "happi", "ness"{]}}}).

\end{itemize}

\end{description}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Character Tokenization}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Treats each character in a word as a separate token.

\item {} \begin{description}
\sphinxlineitem{Example:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Word: \sphinxcode{\sphinxupquote{hello}}.

\item {} 
\sphinxAtStartPar
Tokens: \sphinxcode{\sphinxupquote{{[}"h", "e", "l", "l", "o"{]}}}.

\end{itemize}

\end{description}

\end{itemize}

\item {} 
\sphinxAtStartPar
Importance of Tokenization
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Text Preprocessing}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Tokenization is the first step in many NLP tasks like text classification, translation, and
summarization, as it converts text into manageable pieces.

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Text Representation}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Tokens are converted into numerical representations (e.g., word embeddings) for model input
in tasks like sentiment analysis, named entity recognition (NER), or language modeling.

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Improving Accuracy}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Proper tokenization ensures that a model processes text at the correct granularity (e.g.,
words or subwords), improving accuracy for tasks like machine translation or text generation.

\end{itemize}

\item {} 
\sphinxAtStartPar
Challenges of Tokenization
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Ambiguity}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Certain words or phrases can be tokenized differently based on context.

\item {} 
\sphinxAtStartPar
Example: “New York” can be treated as one token (location) or two separate tokens (\sphinxcode{\sphinxupquote{{[}"New", "York"{]}}}).

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Handling Punctuation}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Deciding how to treat punctuation marks can be challenging. For example, should commas, periods,
or quotes be treated as separate tokens or grouped with adjacent words?

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Multi\sphinxhyphen{}word Expressions (MWEs)}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Some expressions consist of multiple words that should be treated as a single token, such as “New York” or “machine learning.”

\end{itemize}

\item {} 
\sphinxAtStartPar
Techniques for Tokenization
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Rule\sphinxhyphen{}Based Tokenization}: Uses predefined rules to split text based on spaces, punctuation, and other delimiters.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Statistical and Machine Learning\sphinxhyphen{}Based Tokenization}: Uses trained models to predict token boundaries based on patterns learned from large corpora.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Deep Learning\sphinxhyphen{}Based Tokenization}: Modern tokenization models, such as those used in transformers (e.g., BERT, GPT), may rely on subword tokenization and neural networks to handle complex tokenization tasks.

\end{enumerate}

\end{itemize}


\subsection{BERT Tokenization}
\label{\detokenize{prelim:bert-tokenization}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Vocabulary: The BERT Tokenizer’s vocabulary contains 30,522 unique tokens.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{transformers} \PYG{k+kn}{import} \PYG{n}{BertTokenizer}\PYG{p}{,} \PYG{n}{BertModel}
\PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{BertTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bert\PYGZhy{}base\PYGZhy{}uncased}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} model = BertModel.from\PYGZus{}pretrained(\PYGZdq{}bert\PYGZhy{}base\PYGZhy{}uncased\PYGZdq{})}

\PYG{c+c1}{\PYGZsh{} vocabulary size}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{vocab\PYGZus{}size}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} vocabulary}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{vocab}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} vocabulary size}
\PYG{l+m+mi}{30522}

\PYG{c+c1}{\PYGZsh{} vocabulary}
\PYG{n}{OrderedDict}\PYG{p}{(}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[PAD]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[unused0]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
              \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}
              \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{writing}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{3015}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bay}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{3016}\PYG{p}{)}\PYG{p}{,}
              \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}
              \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}\PYGZsh{}?}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{30520}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}\PYGZsh{}\PYGZti{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mi}{30521}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Tokens and IDs
\begin{itemize}
\item {} 
\sphinxAtStartPar
Tokens to IDs

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{text} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Gen AI is awesome}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{encoded\PYGZus{}input} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} tokens to ids}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{encoded\PYGZus{}input}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} output}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,}  \PYG{l+m+mi}{8991}\PYG{p}{,}  \PYG{l+m+mi}{9932}\PYG{p}{,}  \PYG{l+m+mi}{2003}\PYG{p}{,} \PYG{l+m+mi}{12476}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYGZbs{}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{token\PYGZus{}type\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYGZbs{}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{attention\PYGZus{}mask}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
You might notice that there are only four words, yet we have six token IDs.
This is due to the inclusion of two additional special tokens \sphinxcode{\sphinxupquote{{[}CLS{]}}} and \sphinxcode{\sphinxupquote{{[}SEP{]}}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{n}{x} \PYG{p}{:} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{+} \PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}\PYG{o}{+} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} output}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{101}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{8991}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AI}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{9932}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{2003}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{12476}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Special Tokens

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Special tokens}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{n}{x} \PYG{p}{:} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[MASK]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[EOS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} tokens to ids}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{101}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[MASK]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{103}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[EOS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{1031}\PYG{p}{,} \PYG{l+m+mi}{1041}\PYG{p}{,} \PYG{l+m+mi}{2891}\PYG{p}{,} \PYG{l+m+mi}{1033}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
IDs to tokens

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} ids to tokens}
\PYG{n}{token\PYGZus{}id} \PYG{o}{=} \PYG{n}{encoded\PYGZus{}input}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{convert\PYGZus{}ids\PYGZus{}to\PYGZus{}tokens}\PYG{p}{(}\PYG{n+nb}{id}\PYG{p}{,} \PYG{n}{skip\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}\PYG{p}{:}\PYG{n+nb}{id} \PYGZbs{}
      \PYG{k}{for} \PYG{n+nb}{id} \PYG{o+ow}{in} \PYG{n}{token\PYGZus{}id}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} output}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{101}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{8991}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{9932}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{2003}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{12476}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{102}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Out\sphinxhyphen{}of\sphinxhyphen{}vocabulary tokens

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{text} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Gen AI is awesome 👍}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{encoded\PYGZus{}input} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{n}{x} \PYG{p}{:} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{+} \PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}\PYG{o}{+} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{convert\PYGZus{}ids\PYGZus{}to\PYGZus{}tokens}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{skip\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} output}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{101}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{8991}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AI}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{9932}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{2003}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{12476}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{👍}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\PYG{p}{[}\PYG{n}{UNK}\PYG{p}{]}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Subword Tokenization

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Subword Tokenization}
\PYG{n}{text} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{GenAI is awesome 👍}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{n}{x} \PYG{p}{:} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{+} \PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}\PYG{o}{+} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{convert\PYGZus{}ids\PYGZus{}to\PYGZus{}tokens}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{skip\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} output}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{101}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GenAI}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{8991}\PYG{p}{,} \PYG{l+m+mi}{4886}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{2003}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{12476}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{👍}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\PYG{p}{[}\PYG{n}{UNK}\PYG{p}{]}
\end{sphinxVerbatim}

\end{itemize}

\end{itemize}


\subsection{Modern BERT}
\label{\detokenize{prelim:modern-bert}}
\sphinxAtStartPar
ModernBERT is an encoder\sphinxhyphen{}only model. It is based on the architecture of the original
BERT (Bidirectional Encoder Representations from Transformers), which is designed
to process and understand text by encoding it into dense numerical representations (embedding vectors).

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{encoder\sphinxhyphen{}only} model is a type of transformer architecture designed primarily
to understand and process input data by encoding it into a dense numerical representation,
often called an embedding vector.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{decoder\sphinxhyphen{}only} model is a transformer architecture designed for generating or predicting sequences,
such as text. such as GPT, Llama, and Claude.

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
The new architecture delivers significant improvements over its predecessors in both
speed and accuracy (Fig. {\hyperref[\detokenize{prelim:fig-mbert-curve}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Modern BERT Pareto Curve (Source: Modern BERT)}}}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{modernbert_pareto_curve}.png}
\caption{Modern BERT Pareto Curve (Source: \sphinxhref{https://huggingface.co/blog/modernbert}{Modern BERT})}\label{\detokenize{prelim:id4}}\label{\detokenize{prelim:fig-mbert-curve}}\end{figure}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Global and Local Attention

\sphinxAtStartPar
One of ModernBERT’s most impactful features is Alternating Attention, rather than full global attention.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{modernbert_alternating_attention}.png}
\caption{ModernBERT Alternating Attention (Source: \sphinxhref{https://huggingface.co/blog/modernbert}{Modern BERT})}\label{\detokenize{prelim:id5}}\label{\detokenize{prelim:fig-mbert-attention}}\end{figure}

\item {} 
\sphinxAtStartPar
Unpadding and Sequence Packing

\sphinxAtStartPar
Another core mechanism contributing to ModernBERT’s efficiency is its use for Unpadding and Sequence packing.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{modernbert_unpadding}.png}
\caption{ModernBERT Unpadding (Source: \sphinxhref{https://huggingface.co/blog/modernbert}{Modern BERT})}\label{\detokenize{prelim:id6}}\label{\detokenize{prelim:fig-mbert-unpadding}}\end{figure}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{transformers} \PYG{k+kn}{import} \PYG{n}{AutoTokenizer}\PYG{p}{,} \PYG{n}{AutoModelForMaskedLM}

\PYG{n}{model\PYGZus{}id} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{answerdotai/ModernBERT\PYGZhy{}base}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{AutoTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{model\PYGZus{}id}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{AutoModelForMaskedLM}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{model\PYGZus{}id}\PYG{p}{)}

\PYG{n}{text} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The capital of France is [MASK].}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{inputs} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{pt}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{outputs} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{inputs}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} To get predictions for the mask:}
\PYG{n}{masked\PYGZus{}index} \PYG{o}{=} \PYG{n}{inputs}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input\PYGZus{}ids}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{index}\PYG{p}{(}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{mask\PYGZus{}token\PYGZus{}id}\PYG{p}{)}
\PYG{n}{predicted\PYGZus{}token\PYGZus{}id} \PYG{o}{=} \PYG{n}{outputs}\PYG{o}{.}\PYG{n}{logits}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{masked\PYGZus{}index}\PYG{p}{]}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{axis}\PYG{o}{=}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{predicted\PYGZus{}token} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{decode}\PYG{p}{(}\PYG{n}{predicted\PYGZus{}token\PYGZus{}id}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Predicted token:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{predicted\PYGZus{}token}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Predicted token:  Paris}
\end{sphinxVerbatim}


\section{Platform and Packages}
\label{\detokenize{prelim:platform-and-packages}}

\subsection{Google Colab}
\label{\detokenize{prelim:google-colab}}
\sphinxAtStartPar
\sphinxstylestrong{Google Colab} (short for Colaboratory) is a free, cloud\sphinxhyphen{}based platform that provides users with the ability to write
and execute Python code in an interactive notebook environment. It is based on Jupyter notebooks and is powered by
Google Cloud services, allowing for seamless integration with Google Drive and other Google services. We will primarily
use Google Colab with free T4 GPU runtime throughout this book.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Key Features

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Free Access to GPUs and TPUs}
Colab offers free access to Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs), making it an ideal environment for machine learning, deep learning, and other computationally intensive tasks.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Integration with Google Drive}
You can store and access notebooks directly from your Google Drive, making it easy to collaborate with others and keep your projects organized.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{No Setup Required}
Since Colab is entirely cloud\sphinxhyphen{}based, you don’t need to worry about setting up an environment or managing dependencies. Everything is ready to go out of the box.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Support for Python Libraries}
Colab comes pre\sphinxhyphen{}installed with many popular Python libraries, including TensorFlow, PyTorch, Keras, and OpenCV, among others. You can also install any additional libraries using \sphinxtitleref{pip}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Collaborative Features}
Multiple users can work on the same notebook simultaneously, making it ideal for collaboration. Changes are synchronized in real\sphinxhyphen{}time.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Rich Media Support}
Colab supports the inclusion of rich media, such as images, videos, and LaTeX equations, directly within the notebook. This makes it a great tool for data analysis, visualization, and educational purposes.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Easy Sharing}
Notebooks can be easily shared with others via a shareable link, just like Google Docs. Permissions can be set for viewing or editing the document.

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
GPU Activation
\sphinxcode{\sphinxupquote{Runtime \sphinxhyphen{}\sphinxhyphen{}\textgreater{} change runtime type \sphinxhyphen{}\sphinxhyphen{}\textgreater{} T4/A100 GPU}}

\end{itemize}


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\sphinxthistablewithborderlessstyle
\centering
\begin{tabulary}{\linewidth}[t]{TT}
\sphinxtoprule
\sphinxtableatstartofbodyhook
\noindent\sphinxincludegraphics[width=1.000\linewidth]{{runtime}.png}
&
\noindent\sphinxincludegraphics[width=1.000\linewidth]{{T4}.png}
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\begin{sphinxadmonition}{note}{Tips}
\begin{quote}

\sphinxAtStartPar
You can use the Gemini API for code troubleshooting in a Colab notebook for free.
\end{quote}

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{gemini}.png}
\end{figure}
\end{sphinxadmonition}


\subsection{HuggingFace}
\label{\detokenize{prelim:huggingface}}
\sphinxAtStartPar
\sphinxstylestrong{Hugging Face} is a company and open\sphinxhyphen{}source community focused on providing tools and resources for NLP
and machine learning. It is best known for its popular \sphinxstylestrong{Transformers} library, which allows easy access
to pre\sphinxhyphen{}trained models for a wide variety of NLP tasks. MOreover,  Hugging Face’s libraries provide simple
Python APIs that make it easy to load models, preprocess data, and run inference. This simplicity allows
both beginners and advanced users to leverage cutting\sphinxhyphen{}edge NLP models. We will mainly use the embedding models
and Large Language Models (LLMs) from \sphinxstylestrong{Hugging Face Model Hub} central repository.


\subsection{Ollama}
\label{\detokenize{prelim:ollama}}
\sphinxAtStartPar
Ollama is a package designed to run LLMs locally on your personal device or
server, rather than relying on external cloud services. It provides a simple
interface to download and use AI models tailored for various tasks, ensuring
privacy and control over data while still leveraging the power of LLMs.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Key features of Ollama:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Local Execution: Models run entirely on your hardware, making it ideal for users who prioritize data privacy.

\item {} 
\sphinxAtStartPar
Pre\sphinxhyphen{}trained Models: Offers a curated set of LLMs optimized for local usage.

\item {} 
\sphinxAtStartPar
Cross\sphinxhyphen{}Platform: Compatible with macOS, Linux, and other operating systems, depending on hardware specifications.

\item {} 
\sphinxAtStartPar
Ease of Use: Designed to make setting up and using local AI models simple for non\sphinxhyphen{}technical users.

\item {} 
\sphinxAtStartPar
Efficiency: Focused on lightweight models optimized for local performance without needing extensive computational resources.

\end{itemize}

\end{itemize}

\sphinxAtStartPar
To simplify the management of access tokens for various LLMs, we will use Ollama in Google Colab.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Ollama installation in Google Colab
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
colab\sphinxhyphen{}xterm

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
!pip\PYG{+w}{ }install\PYG{+w}{ }colab\PYGZhy{}xterm
\PYGZpc{}load\PYGZus{}ext\PYG{+w}{ }colabxterm
\end{sphinxVerbatim}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
download ollama

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/content\PYGZsh{}\PYG{+w}{ }curl\PYG{+w}{ }https://ollama.ai/install.sh\PYG{+w}{ }\PYG{p}{|}\PYG{+w}{ }sh
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{ollama_download}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
launch Ollama serve

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/content\PYGZsh{}\PYG{+w}{ }ollama\PYG{+w}{ }serve
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{ollama_serve}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
\sphinxAtStartPar
download models

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/content\PYGZsh{}\PYG{+w}{ }ollama\PYG{+w}{ }pull\PYG{+w}{ }mistral\PYG{+w}{ }\PYG{c+c1}{\PYGZsh{}llama3.2 \PYGZsh{}bge\PYGZhy{}m3}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{pull_models}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
\sphinxAtStartPar
check

\end{enumerate}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
!ollama\PYG{+w}{ }list

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
NAME\PYG{+w}{               }ID\PYG{+w}{              }SIZE\PYG{+w}{      }MODIFIED
llama3.2:latest\PYG{+w}{    }a80c4f17acd5\PYG{+w}{    }\PYG{l+m}{2}.0\PYG{+w}{ }GB\PYG{+w}{    }\PYG{l+m}{14}\PYG{+w}{ }seconds\PYG{+w}{ }ago
mistral:latest\PYG{+w}{     }f974a74358d6\PYG{+w}{    }\PYG{l+m}{4}.1\PYG{+w}{ }GB\PYG{+w}{    }About\PYG{+w}{ }a\PYG{+w}{ }minute\PYG{+w}{ }ago
\end{sphinxVerbatim}
\end{quote}

\end{itemize}


\subsection{langchain}
\label{\detokenize{prelim:langchain}}
\sphinxAtStartPar
LangChain is a powerful framework for building AI applications that combine the
capabilities of large language models with external tools, memory, and custom
workflows. It enables developers to create intelligent, context\sphinxhyphen{}aware,
and dynamic applications with ease.

\sphinxAtStartPar
It has widely applied in:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Conversational AI}
Create chatbots or virtual assistants that maintain context, integrate with APIs, and provide intelligent responses.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Knowledge Management}
Combine LLMs with external knowledge bases or databases to answer complex questions or summarize documents.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Automation}
Automate workflows by chaining LLMs with tools for decision\sphinxhyphen{}making, data extraction, or content generation.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Creative Applications}
Use LangChain for generating stories, crafting marketing copy, or producing artistic content.

\end{enumerate}

\sphinxAtStartPar
We will primarily use LangChain in this book. For instance, to work with downloaded Ollama LLMs, the \sphinxcode{\sphinxupquote{langchain\_ollama}}
package is required.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} chain of thought prompting}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{ChatPromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{CommaSeparatedListOutputParser}


\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{Question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}

\PYG{l+s+s2}{Answer: Let}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s think step by step.}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model} \PYG{o}{|} \PYG{n}{output\PYGZus{}parser}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is Mixture of Experts(MoE) in AI?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{answer}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{:}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{MoE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{or Mixture of Experts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{is a neural network architecture that allows for }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{    efficient computation and model parallelism. It consists of multiple }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{experts}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{each of }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s1}{    which is a smaller neural network that specializes in handling different parts of the input }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s1}{    data. The final output is obtained by combining the outputs of these experts based on their }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s1}{    expertise relevance to the input. This architecture is particularly useful in tasks where }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s1}{    the data exhibits complex and diverse patterns.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{Word and Sentence Embedding}
\label{\detokenize{embedding:word-and-sentence-embedding}}\label{\detokenize{embedding:embedding}}\label{\detokenize{embedding::doc}}
\begin{sphinxadmonition}{note}{Chinese proverb}

\sphinxAtStartPar
Though the forms may vary, the essence remains unchanged. \textendash{} old Chinese proverb
\end{sphinxadmonition}

\sphinxAtStartPar
Word embedding is a method in natural language processing (NLP) to represent words as dense
vectors of real numbers, capturing semantic relationships between them. Instead of treating
words as discrete symbols (like one\sphinxhyphen{}hot encoding), word embeddings map words into a
continuous vector space where similar words are located closer together.

\begin{sphinxadmonition}{note}{Colab Notebook for This Chapter}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Word Embedding: \sphinxhref{https://colab.research.google.com/drive/1IZR9vRHAl-jHsHOkt2evsgJJ1\_hCICa?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{embedding_diagram}.png}
\caption{Embedding Diagram}\label{\detokenize{embedding:id2}}\label{\detokenize{embedding:fig-embedding}}\end{figure}


\section{Traditional word embeddings}
\label{\detokenize{embedding:traditional-word-embeddings}}
\sphinxAtStartPar
\sphinxstylestrong{Bag of Words (BoW)} is a simple and widely used text representation technique in natural
language processing (NLP). It represents a text (e.g., a document or a sentence) as a collection
of words, ignoring grammar, order, and context but keeping their frequency.

\sphinxAtStartPar
Key Features of Bag of Words:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Vocabulary Creation}:
\sphinxhyphen{} A list of all unique words in the dataset (the “vocabulary”) is created.
\sphinxhyphen{} Each word becomes a feature.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Representation}:
\sphinxhyphen{} Each document is represented as a vector or a frequency count of words from the vocabulary.
\sphinxhyphen{} If a word from the vocabulary is present in the document, its count is included in the vector.
\sphinxhyphen{} Words not present in the document are assigned a count of zero.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Simplicity}:
\sphinxhyphen{} The method is computationally efficient and straightforward.
\sphinxhyphen{} However, it ignores the sequence and semantic meaning of the words.

\end{enumerate}

\sphinxAtStartPar
Applications:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Text Classification

\item {} 
\sphinxAtStartPar
Sentiment Analysis

\item {} 
\sphinxAtStartPar
Document Similarity

\end{itemize}

\sphinxAtStartPar
Limitations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Context Ignorance}:
\sphinxhyphen{} BoW does not capture word order or semantics.
\sphinxhyphen{} For example, “not good” and “good” might appear similar in BoW.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dimensionality}:
\sphinxhyphen{} As the vocabulary size increases, the vector representation grows, leading to high\sphinxhyphen{}dimensional data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Sparse Representations}:
\sphinxhyphen{} Many entries in the vectors might be zeros, leading to sparsity.

\end{enumerate}


\subsection{One Hot Encoder}
\label{\detokenize{embedding:one-hot-encoder}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{from} \PYG{n+nn}{collections} \PYG{k+kn}{import} \PYG{n}{Counter}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{OneHotEncoder}

\PYG{c+c1}{\PYGZsh{} sample corpus}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{word}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{python}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pyspark}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{genai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pyspark}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{python}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pyspark}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} corpus frequency}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Vocabulary frequency:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{Counter}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{word}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} corpus order}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Vocabulary order:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n+nb}{set}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{word}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} One\PYGZhy{}hot encode the data}
\PYG{n}{onehot\PYGZus{}encoder} \PYG{o}{=} \PYG{n}{OneHotEncoder}\PYG{p}{(}\PYG{n}{sparse\PYGZus{}output}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{onehot\PYGZus{}encoded} \PYG{o}{=} \PYG{n}{onehot\PYGZus{}encoder}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{word}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} the encoded order base on the order of the copus}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Encoded representation:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{onehot\PYGZus{}encoded}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Vocabulary} \PYG{n}{frequency}\PYG{p}{:}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{python}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pyspark}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{genai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{\PYGZcb{}}

\PYG{n}{Vocabulary} \PYG{n}{order}\PYG{p}{:}
\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{genai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pyspark}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{python}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

\PYG{n}{Encoded} \PYG{n}{representation}\PYG{p}{:}
\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.} \PYG{l+m+mf}{0.} \PYG{l+m+mf}{1.}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{0.} \PYG{l+m+mf}{1.} \PYG{l+m+mf}{0.}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{1.} \PYG{l+m+mf}{0.} \PYG{l+m+mf}{0.}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{0.} \PYG{l+m+mf}{1.} \PYG{l+m+mf}{0.}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{0.} \PYG{l+m+mf}{0.} \PYG{l+m+mf}{1.}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{0.} \PYG{l+m+mf}{1.} \PYG{l+m+mf}{0.}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}


\subsection{CountVectorizer}
\label{\detokenize{embedding:countvectorizer}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}extraction}\PYG{n+nn}{.}\PYG{n+nn}{text} \PYG{k+kn}{import} \PYG{n}{CountVectorizer}

\PYG{c+c1}{\PYGZsh{} sample corpus}
\PYG{n}{corpus} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Initialize the CountVectorizer}
\PYG{n}{vectorizer} \PYG{o}{=} \PYG{n}{CountVectorizer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Fit and transform}
\PYG{n}{X} \PYG{o}{=} \PYG{n}{vectorizer}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}


\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Vocabulary:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{vectorizer}\PYG{o}{.}\PYG{n}{get\PYGZus{}feature\PYGZus{}names\PYGZus{}out}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Embedded representation:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X}\PYG{o}{.}\PYG{n}{toarray}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Vocabulary}\PYG{p}{:}
\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fun}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

\PYG{n}{Embedded} \PYG{n}{representation}\PYG{p}{:}
\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
To overcome these limitations, advanced techniques like \sphinxstylestrong{TF\sphinxhyphen{}IDF}, \sphinxstylestrong{word embeddings}
(e.g., Word2Vec, GloVe), and contextual embeddings (e.g., BERT) are often used.


\subsection{TF\sphinxhyphen{}IDF}
\label{\detokenize{embedding:tf-idf}}
\sphinxAtStartPar
\sphinxstylestrong{TF\sphinxhyphen{}IDF (Term Frequency\sphinxhyphen{}Inverse Document Frequency)} is a statistical measure used
in text analysis to evaluate the importance of a word in a document relative to a
collection (or corpus) of documents. It builds upon the \sphinxstylestrong{Bag of Words (BoW)} model
by not only considering the frequency of a word in a document but also taking
into account how common or rare the word is across the corpus. The pyspark implementation
can be found at \sphinxcite{reference:pyspark}.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Components of TF\sphinxhyphen{}ID

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{t}: the term in corpus.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{d}: the document.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{D}: the corpus.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{|D|}: the length of the corpus or total number of documents.
\begin{quote}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Document Frequency (DF)}:

\item {} 
\sphinxAtStartPar
\(DF(t,D)\): the number of documents that contains term \(t\).

\item {} \begin{description}
\sphinxlineitem{\sphinxstylestrong{Term Frequency (TF)}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Measures how frequently a term appears in a document. The higher the frequency, the more important the term is assumed to be to that document.

\item {} 
\sphinxAtStartPar
Formula:

\end{itemize}
\begin{equation*}
\begin{split}TF(t, d) = \frac{\text{Number of occurrences of term } t \text{ in document } d}{\text{Total number of terms in document } d}\end{split}
\end{equation*}
\end{description}

\item {} \begin{description}
\sphinxlineitem{\sphinxstylestrong{Inverse Document Frequency (IDF)}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Measures how important a term is by reducing the weight of common terms (like “the” or “and”) that appear in many documents.

\item {} 
\sphinxAtStartPar
Formula:

\end{itemize}
\begin{equation*}
\begin{split}IDF(t, D) = \log\left(\frac{|D|+1}{DF(t,D) + 1}\right) + 1\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Adding 1 to the denominator avoids division by zero when a term is present in all documents.

\item {} 
\sphinxAtStartPar
Note that the IDF formula above differs from the standard textbook notation that defines the IDF

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The IDF formula above differs from the standard textbook notation that defines the IDF as
\begin{equation*}
\begin{split}IDF(t) = \log [ |D| / (DF(t,D) + 1) ]).\end{split}
\end{equation*}\end{sphinxadmonition}

\end{description}

\item {} \begin{description}
\sphinxlineitem{\sphinxstylestrong{TF\sphinxhyphen{}IDF Score}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
The final score is the product of TF and IDF.

\item {} 
\sphinxAtStartPar
Formula:

\end{itemize}
\begin{equation*}
\begin{split}TF\text{-}IDF(t, d, D) = TF(t, d) \cdot IDF(t, D)\end{split}
\end{equation*}
\end{description}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{collections} \PYG{k+kn}{import} \PYG{n}{Counter}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}extraction}\PYG{n+nn}{.}\PYG{n+nn}{text} \PYG{k+kn}{import} \PYG{n}{TfidfVectorizer}

\PYG{c+c1}{\PYGZsh{} sample corpus}
\PYG{n}{corpus} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Initialize the TfidfVectorizer}
\PYG{n}{vectorizer} \PYG{o}{=} \PYG{n}{TfidfVectorizer}\PYG{p}{(}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} norm default norm=\PYGZsq{}l2\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Fit and transform}
\PYG{n}{X} \PYG{o}{=} \PYG{n}{vectorizer}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Vocabulary:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{vectorizer}\PYG{o}{.}\PYG{n}{get\PYGZus{}feature\PYGZus{}names\PYGZus{}out}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} [item for row in matrix for item in row]}
\PYG{n}{corpus\PYGZus{}flatted} \PYG{o}{=} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{sub\PYGZus{}list} \PYG{o+ow}{in} \PYG{p}{[}\PYG{n}{s}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{k}{for} \PYG{n}{s} \PYG{o+ow}{in} \PYG{n}{corpus}\PYG{p}{]}
                     \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{sub\PYGZus{}list}\PYG{p}{]}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Vocabulary frequency:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb}{dict}\PYG{p}{(}\PYG{n}{Counter}\PYG{p}{(}\PYG{n}{corpus\PYGZus{}flatted}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Embedded representation:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X}\PYG{o}{.}\PYG{n}{toarray}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Vocabulary}\PYG{p}{:}
\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fun}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

\PYG{n}{Vocabulary} \PYG{n}{frequency}\PYG{p}{:}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AI}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{\PYGZcb{}}

\PYG{n}{Embedded} \PYG{n}{representation}\PYG{p}{:}
\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.41285857} \PYG{l+m+mf}{0.69903033} \PYG{l+m+mf}{0.}         \PYG{l+m+mf}{0.41285857} \PYG{l+m+mf}{0.}         \PYG{l+m+mf}{0.41285857}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{0.41285857} \PYG{l+m+mf}{0.}         \PYG{l+m+mf}{0.69903033} \PYG{l+m+mf}{0.41285857} \PYG{l+m+mf}{0.}         \PYG{l+m+mf}{0.41285857}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{0.41285857} \PYG{l+m+mf}{0.}         \PYG{l+m+mf}{0.}         \PYG{l+m+mf}{0.41285857} \PYG{l+m+mf}{0.69903033} \PYG{l+m+mf}{0.41285857}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
The above results can be validated by the following steps (IDF in document 1):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Step 1: Vocabulary  `[\PYGZsq{}ai\PYGZsq{} \PYGZsq{}awesome\PYGZsq{} \PYGZsq{}fun\PYGZsq{} \PYGZsq{}gen\PYGZsq{} \PYGZsq{}hot\PYGZsq{} \PYGZsq{}is\PYGZsq{}]`}

\PYG{n}{tf\PYGZus{}idf} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{term}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{vectorizer}\PYG{o}{.}\PYG{n}{get\PYGZus{}feature\PYGZus{}names\PYGZus{}out}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYGZbs{}
         \PYG{o}{.}\PYG{n}{set\PYGZus{}index}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{term}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 2: |D|}
\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{|D|}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}\PYG{p}{]}\PYG{o}{*}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{vectorizer}\PYG{o}{.}\PYG{n}{get\PYGZus{}feature\PYGZus{}names\PYGZus{}out}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 3: Compute TF for doc 1:  Gen AI is awesome}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} TF for \PYGZdq{}ai\PYGZdq{} in Document 1 = 1 (appears once doc 1)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} TF for \PYGZdq{}awesome\PYGZdq{} in Document 1 = 1 (appears once in doc 1)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} TF for \PYGZdq{}fun\PYGZdq{} in Document 1 = 0 (does not appear in doc 1)}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} TF for \PYGZdq{}gen\PYGZdq{} in Document 1 = 1 (appear oncein doc 1 )}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} TF for \PYGZdq{}hot\PYGZdq{} in Document 1 = 0 (does not appear doc 1 )}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} TF for \PYGZdq{}is\PYGZdq{} in Document 1 = 1 (appear once in doc 1 )}

\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Step 4:  Compute DF for doc 1}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} DF For \PYGZdq{}ai\PYGZdq{}: Appears in all 3 documents.}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} DF For \PYGZdq{}awesome\PYGZdq{}: Appears in 1 document.}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} DF For \PYGZdq{}fun\PYGZdq{}: Appears in 1 document.}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} DF For \PYGZdq{}Gen\PYGZdq{}: Appears in all 3 documents.}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} DF For \PYGZdq{}hot\PYGZdq{}: Appears in 1 document.}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} DF For \PYGZdq{}is\PYGZdq{}: Appears in all 3 documents.}

\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{DF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Step 5: Compute IDF}
\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{IDF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{p}{(}\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{|D|}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{DF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{o}{+}\PYG{l+m+mi}{1}

\PYG{c+c1}{\PYGZsh{} Step 6: Compute TF\PYGZhy{}IDF}
\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TF\PYGZhy{}IDF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{*}\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{IDF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Step 7: l2 normlization}
\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TF\PYGZhy{}IDF(l2)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TF\PYGZhy{}IDF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{/}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{tf\PYGZus{}idf}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TF\PYGZhy{}IDF}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{tf\PYGZus{}idf}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
         \PYG{o}{|}\PYG{n}{D}\PYG{o}{|}  \PYG{n}{TF}  \PYG{n}{DF}       \PYG{n}{IDF}    \PYG{n}{TF}\PYG{o}{\PYGZhy{}}\PYG{n}{IDF}  \PYG{n}{TF}\PYG{o}{\PYGZhy{}}\PYG{n}{IDF}\PYG{p}{(}\PYG{n}{l2}\PYG{p}{)}
\PYG{n}{term}
\PYG{n}{ai}         \PYG{l+m+mi}{3}   \PYG{l+m+mi}{1}   \PYG{l+m+mi}{3}  \PYG{l+m+mf}{1.000000}  \PYG{l+m+mf}{1.000000}    \PYG{l+m+mf}{0.412859}
\PYG{n}{awesome}    \PYG{l+m+mi}{3}   \PYG{l+m+mi}{1}   \PYG{l+m+mi}{1}  \PYG{l+m+mf}{1.693147}  \PYG{l+m+mf}{1.693147}    \PYG{l+m+mf}{0.699030}
\PYG{n}{fun}        \PYG{l+m+mi}{3}   \PYG{l+m+mi}{0}   \PYG{l+m+mi}{1}  \PYG{l+m+mf}{1.693147}  \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{0.000000}
\PYG{n}{gen}        \PYG{l+m+mi}{3}   \PYG{l+m+mi}{1}   \PYG{l+m+mi}{3}  \PYG{l+m+mf}{1.000000}  \PYG{l+m+mf}{1.000000}    \PYG{l+m+mf}{0.412859}
\PYG{n}{hot}        \PYG{l+m+mi}{3}   \PYG{l+m+mi}{0}   \PYG{l+m+mi}{1}  \PYG{l+m+mf}{1.693147}  \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{0.000000}
\PYG{o+ow}{is}         \PYG{l+m+mi}{3}   \PYG{l+m+mi}{1}   \PYG{l+m+mi}{3}  \PYG{l+m+mf}{1.000000}  \PYG{l+m+mf}{1.000000}    \PYG{l+m+mf}{0.412859}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Fun Fact}

\sphinxAtStartPar
TfidfVectorizer is equivalent to CountVectorizer followed by TfidfTransformer.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}extraction}\PYG{n+nn}{.}\PYG{n+nn}{text} \PYG{k+kn}{import} \PYG{n}{CountVectorizer}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}extraction}\PYG{n+nn}{.}\PYG{n+nn}{text} \PYG{k+kn}{import} \PYG{n}{TfidfTransformer}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{pipeline} \PYG{k+kn}{import} \PYG{n}{Pipeline}

\PYG{c+c1}{\PYGZsh{} sample corpus}
\PYG{n}{corpus} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} pipeline}
\PYG{n}{pipe} \PYG{o}{=} \PYG{n}{Pipeline}\PYG{p}{(}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{CountVectorizer}\PYG{p}{(}\PYG{n}{lowercase}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
               \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{tfid}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{TfidfTransformer}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{pipe}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} TF}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{pipe}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{transform}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}\PYG{o}{.}\PYG{n}{toarray}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} IDF}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{pipe}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{tfid}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{idf\PYGZus{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Pipeline}\PYG{p}{(}\PYG{n}{steps}\PYG{o}{=}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{CountVectorizer}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{tfid}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{TfidfTransformer}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}
\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m+mf}{1.}         \PYG{l+m+mf}{1.69314718} \PYG{l+m+mf}{1.69314718} \PYG{l+m+mf}{1.}         \PYG{l+m+mf}{1.69314718} \PYG{l+m+mf}{1.}        \PYG{p}{]}
\end{sphinxVerbatim}
\end{sphinxadmonition}
\end{quote}

\item {} 
\sphinxAtStartPar
Applications of TF\sphinxhyphen{}IDF
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Information Retrieval}: Ranking documents based on relevance to a query.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Text Classification}: Feature extraction for machine learning models.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Document Similarity}: Comparing documents by their weighted term vectors.

\end{enumerate}

\item {} 
\sphinxAtStartPar
Advantages
\begin{itemize}
\item {} 
\sphinxAtStartPar
Highlights important terms while reducing the weight of common terms.

\item {} 
\sphinxAtStartPar
Simple to implement and effective for many tasks.

\end{itemize}

\item {} 
\sphinxAtStartPar
Limitations
\begin{itemize}
\item {} 
\sphinxAtStartPar
Does not capture semantic relationships or word order.

\item {} 
\sphinxAtStartPar
Less effective for very large corpora or when working with very short documents.

\item {} 
\sphinxAtStartPar
Sparse representation due to high\sphinxhyphen{}dimensional feature vectors.

\end{itemize}

\end{itemize}

\sphinxAtStartPar
For more advanced representations, embeddings like \sphinxstylestrong{Word2Vec} or \sphinxstylestrong{BERT} are often used.


\section{Static word embeddings}
\label{\detokenize{embedding:static-word-embeddings}}
\sphinxAtStartPar
Static word embeddings are word representations that assign a fixed vector to each word,
regardless of its context in a sentence or paragraph. These embeddings are pre\sphinxhyphen{}trained on
large corpora and remain unchanged during usage, making them “static.” These embeddings are
usually pre\sphinxhyphen{}trained on large text corpora using algorithms like Word2Vec, GloVe, or FastText.


\subsection{Word2Vec}
\label{\detokenize{embedding:word2vec}}\begin{itemize}
\item {} 
\sphinxAtStartPar
The Context Window

\item {} 
\sphinxAtStartPar
CBOW and Skip\sphinxhyphen{}Gram Model

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gensim}
\PYG{k+kn}{from} \PYG{n+nn}{gensim}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Word2Vec}
\PYG{k+kn}{from} \PYG{n+nn}{nltk}\PYG{n+nn}{.}\PYG{n+nn}{tokenize} \PYG{k+kn}{import} \PYG{n}{sent\PYGZus{}tokenize}\PYG{p}{,} \PYG{n}{word\PYGZus{}tokenize}

\PYG{c+c1}{\PYGZsh{} sample corpus}
\PYG{n}{corpus} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}


\PYG{k}{def} \PYG{n+nf}{tokenize\PYGZus{}gensim}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}\PYG{p}{:}

   \PYG{n}{tokens} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
   \PYG{c+c1}{\PYGZsh{} iterate through each sentence in the corpus}
   \PYG{k}{for} \PYG{n}{s} \PYG{o+ow}{in} \PYG{n}{corpus}\PYG{p}{:}

      \PYG{c+c1}{\PYGZsh{} tokenize the sentence into words}
      \PYG{n}{temp} \PYG{o}{=} \PYG{n}{gensim}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{tokenize}\PYG{p}{(}\PYG{n}{s}\PYG{p}{,} \PYG{n}{lowercase}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{deacc}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYGZbs{}
                                    \PYG{n}{errors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{strict}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{to\PYGZus{}lower}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYGZbs{}
                                    \PYG{n}{lower}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

      \PYG{n}{tokens}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{temp}\PYG{p}{)}\PYG{p}{)}

   \PYG{k}{return} \PYG{n}{tokens}


\PYG{n}{tokens} \PYG{o}{=} \PYG{n}{tokenize\PYGZus{}gensim}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Create Word2Vec model}
\PYG{c+c1}{\PYGZsh{} sg (\PYGZob{}0, 1\PYGZcb{}, optional) \textendash{} Training algorithm: 1 for skip\PYGZhy{}gram; otherwise CBOW.}
\PYG{c+c1}{\PYGZsh{} CBOW}
\PYG{n}{model1} \PYG{o}{=} \PYG{n}{gensim}\PYG{o}{.}\PYG{n}{models}\PYG{o}{.}\PYG{n}{Word2Vec}\PYG{p}{(}\PYG{n}{tokens}\PYG{p}{,} \PYG{n}{sg}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{min\PYGZus{}count}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}
                              \PYG{n}{vector\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{window}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Vocabulary}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model1}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{key\PYGZus{}to\PYGZus{}index}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model1}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{get\PYGZus{}normed\PYGZus{}vectors}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Print results}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cosine similarity between }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{gen}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{and }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ai}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ \PYGZhy{} Word2Vec(CBOW) : }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
      \PYG{n}{model1}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{similarity}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} Create Word2Vec model}
\PYG{c+c1}{\PYGZsh{} sg (\PYGZob{}0, 1\PYGZcb{}, optional) \textendash{} Training algorithm: 1 for skip\PYGZhy{}gram; otherwise CBOW.}
\PYG{c+c1}{\PYGZsh{} skip\PYGZhy{}gram}
\PYG{n}{model2} \PYG{o}{=} \PYG{n}{gensim}\PYG{o}{.}\PYG{n}{models}\PYG{o}{.}\PYG{n}{Word2Vec}\PYG{p}{(}\PYG{n}{tokens}\PYG{p}{,} \PYG{n}{sg}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{min\PYGZus{}count}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}
                              \PYG{n}{vector\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{window}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Vocabulary}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model2}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{key\PYGZus{}to\PYGZus{}index}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model2}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{get\PYGZus{}normed\PYGZus{}vectors}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Print results}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cosine similarity between }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{gen}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{and }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ai}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ \PYGZhy{} Word2Vec(skip\PYGZhy{}gram) : }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
      \PYG{n}{model2}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{similarity}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{5}\PYG{p}{\PYGZcb{}}
\PYG{p}{[}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02660277}  \PYG{l+m+mf}{0.0117296}   \PYG{l+m+mf}{0.25318226}  \PYG{l+m+mf}{0.44695902} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.4615286}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.35307196}
   \PYG{l+m+mf}{0.3204311}   \PYG{l+m+mf}{0.4451589}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.24882038} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.18670462}\PYG{p}{]}
\PYG{p}{[} \PYG{l+m+mf}{0.41619968} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.08647515} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2558276}   \PYG{l+m+mf}{0.3695945}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.274073}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.10240843}
   \PYG{l+m+mf}{0.1622154}   \PYG{l+m+mf}{0.05593351} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.46721786} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5328355} \PYG{p}{]}
\PYG{p}{[} \PYG{l+m+mf}{0.43418837}  \PYG{l+m+mf}{0.30108306}  \PYG{l+m+mf}{0.40128633}  \PYG{l+m+mf}{0.0453006}   \PYG{l+m+mf}{0.37712952} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20221795}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05619935}  \PYG{l+m+mf}{0.34255028} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.44665098} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2337343} \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.41098067} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05088534}  \PYG{l+m+mf}{0.5218584}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.40045303} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.12768732} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.10601949}
   \PYG{l+m+mf}{0.44194022} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.32449666}  \PYG{l+m+mf}{0.00247097} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2600907} \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.44081825}  \PYG{l+m+mf}{0.22984274} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.40207896} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20159177} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00161115} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0135952}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.3516631}   \PYG{l+m+mf}{0.44133204}  \PYG{l+m+mf}{0.2286844}   \PYG{l+m+mf}{0.423816}  \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.42753762}  \PYG{l+m+mf}{0.23561442} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.21681462}  \PYG{l+m+mf}{0.04321203}  \PYG{l+m+mf}{0.44539306} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.23385239}
   \PYG{l+m+mf}{0.23675178} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.35568893} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.18596812}  \PYG{l+m+mf}{0.49255413}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{Cosine} \PYG{n}{similarity} \PYG{n}{between} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o+ow}{and} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o}{\PYGZhy{}} \PYG{n}{Word2Vec}\PYG{p}{(}\PYG{n}{CBOW}\PYG{p}{)} \PYG{p}{:}  \PYG{l+m+mf}{0.32937223}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{5}\PYG{p}{\PYGZcb{}}
\PYG{p}{[}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02660277}  \PYG{l+m+mf}{0.0117296}   \PYG{l+m+mf}{0.25318226}  \PYG{l+m+mf}{0.44695902} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.4615286}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.35307196}
   \PYG{l+m+mf}{0.3204311}   \PYG{l+m+mf}{0.4451589}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.24882038} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.18670462}\PYG{p}{]}
\PYG{p}{[} \PYG{l+m+mf}{0.41619968} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.08647515} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2558276}   \PYG{l+m+mf}{0.3695945}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.274073}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.10240843}
   \PYG{l+m+mf}{0.1622154}   \PYG{l+m+mf}{0.05593351} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.46721786} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5328355} \PYG{p}{]}
\PYG{p}{[} \PYG{l+m+mf}{0.43418837}  \PYG{l+m+mf}{0.30108306}  \PYG{l+m+mf}{0.40128633}  \PYG{l+m+mf}{0.0453006}   \PYG{l+m+mf}{0.37712952} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20221795}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05619935}  \PYG{l+m+mf}{0.34255028} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.44665098} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2337343} \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.41098067} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05088534}  \PYG{l+m+mf}{0.5218584}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.40045303} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.12768732} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.10601949}
   \PYG{l+m+mf}{0.44194022} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.32449666}  \PYG{l+m+mf}{0.00247097} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2600907} \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.44081825}  \PYG{l+m+mf}{0.22984274} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.40207896} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20159177} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00161115} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0135952}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.3516631}   \PYG{l+m+mf}{0.44133204}  \PYG{l+m+mf}{0.2286844}   \PYG{l+m+mf}{0.423816}  \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.42753762}  \PYG{l+m+mf}{0.23561442} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.21681462}  \PYG{l+m+mf}{0.04321203}  \PYG{l+m+mf}{0.44539306} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.23385239}
   \PYG{l+m+mf}{0.23675178} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.35568893} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.18596812}  \PYG{l+m+mf}{0.49255413}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{Cosine} \PYG{n}{similarity} \PYG{n}{between} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o+ow}{and} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o}{\PYGZhy{}} \PYG{n}{Word2Vec}\PYG{p}{(}\PYG{n}{skip}\PYG{o}{\PYGZhy{}}\PYG{n}{gram}\PYG{p}{)} \PYG{p}{:}  \PYG{l+m+mf}{0.32937223}
\end{sphinxVerbatim}


\subsection{GloVE}
\label{\detokenize{embedding:glove}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{gensim}\PYG{n+nn}{.}\PYG{n+nn}{downloader} \PYG{k}{as} \PYG{n+nn}{api}
\PYG{c+c1}{\PYGZsh{} Download pre\PYGZhy{}trained GloVe model}
\PYG{n}{glove\PYGZus{}vectors} \PYG{o}{=} \PYG{n}{api}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{glove\PYGZhy{}wiki\PYGZhy{}gigaword\PYGZhy{}50}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Get word vectors (embeddings)}
\PYG{n}{word1} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{king}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{word2} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{queen}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{vector1} \PYG{o}{=} \PYG{n}{glove\PYGZus{}vectors}\PYG{p}{[}\PYG{n}{word1}\PYG{p}{]}
\PYG{n}{vector2} \PYG{o}{=} \PYG{n}{glove\PYGZus{}vectors}\PYG{p}{[}\PYG{n}{word2}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} Compute cosine similarity between the two word vectors}
\PYG{n}{similarity} \PYG{o}{=} \PYG{n}{glove\PYGZus{}vectors}\PYG{o}{.}\PYG{n}{similarity}\PYG{p}{(}\PYG{n}{word1}\PYG{p}{,} \PYG{n}{word2}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Word vectors for }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{vector1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Word vectors for }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word2}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{vector2}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cosine similarity between }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{word2}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{similarity}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{p}{]} \PYG{l+m+mf}{100.0}\PYG{o}{\PYGZpc{}} \PYG{l+m+mf}{66.0}\PYG{o}{/}\PYG{l+m+mf}{66.0}\PYG{n}{MB} \PYG{n}{downloaded}
\PYG{n}{Word} \PYG{n}{vectors} \PYG{k}{for} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{king}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[} \PYG{l+m+mf}{0.50451}   \PYG{l+m+mf}{0.68607}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.59517}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.022801}  \PYG{l+m+mf}{0.60046}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.13498}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.08813}
\PYG{l+m+mf}{0.47377}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.61798}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.31012}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.076666}  \PYG{l+m+mf}{1.493}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.034189} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.98173}
\PYG{l+m+mf}{0.68229}   \PYG{l+m+mf}{0.81722}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.51874}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.31503}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.55809}   \PYG{l+m+mf}{0.66421}   \PYG{l+m+mf}{0.1961}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.13495}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11476}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.30344}   \PYG{l+m+mf}{0.41177}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{2.223}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0756}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0783}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.34354}   \PYG{l+m+mf}{0.33505}   \PYG{l+m+mf}{1.9927}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.04234}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.64319}   \PYG{l+m+mf}{0.71125}   \PYG{l+m+mf}{0.49159}
\PYG{l+m+mf}{0.16754}   \PYG{l+m+mf}{0.34344}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.25663}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.8523}    \PYG{l+m+mf}{0.1661}    \PYG{l+m+mf}{0.40102}   \PYG{l+m+mf}{1.1685}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0137}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.21585}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.15155}   \PYG{l+m+mf}{0.78321}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.91241}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.6106}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.64426}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.51042} \PYG{p}{]}
\PYG{n}{Word} \PYG{n}{vectors} \PYG{k}{for} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{queen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[} \PYG{l+m+mf}{0.37854}    \PYG{l+m+mf}{1.8233}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.2648}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1043}     \PYG{l+m+mf}{0.35829}    \PYG{l+m+mf}{0.60029}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.17538}    \PYG{l+m+mf}{0.83767}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.056798}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.75795}    \PYG{l+m+mf}{0.22681}    \PYG{l+m+mf}{0.98587}
\PYG{l+m+mf}{0.60587}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.31419}    \PYG{l+m+mf}{0.28877}    \PYG{l+m+mf}{0.56013}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.77456}    \PYG{l+m+mf}{0.071421}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5741}     \PYG{l+m+mf}{0.21342}    \PYG{l+m+mf}{0.57674}    \PYG{l+m+mf}{0.3868}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.12574}    \PYG{l+m+mf}{0.28012}
\PYG{l+m+mf}{0.28135}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.8053}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0421}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.19255}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.55375}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.054526}
\PYG{l+m+mf}{1.5574}     \PYG{l+m+mf}{0.39296}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2475}     \PYG{l+m+mf}{0.34251}    \PYG{l+m+mf}{0.45365}    \PYG{l+m+mf}{0.16237}
\PYG{l+m+mf}{0.52464}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.070272}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.83744}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0326}     \PYG{l+m+mf}{0.45946}    \PYG{l+m+mf}{0.25302}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.17837}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.73398}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.20025}    \PYG{l+m+mf}{0.2347}    \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.56095}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{2.2839}
\PYG{l+m+mf}{0.0092753} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.60284}  \PYG{p}{]}
\PYG{n}{Cosine} \PYG{n}{similarity} \PYG{n}{between} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{king}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o+ow}{and} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{queen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.7839043140411377}
\end{sphinxVerbatim}


\subsection{Fast Text}
\label{\detokenize{embedding:fast-text}}
\sphinxAtStartPar
Fast Text incorporates subword information (useful for handling rare or unseen words)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{gensim}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{FastText}

\PYG{k+kn}{import} \PYG{n+nn}{gensim}
\PYG{k+kn}{from} \PYG{n+nn}{gensim}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Word2Vec}

\PYG{c+c1}{\PYGZsh{} sample corpus}
\PYG{n}{corpus} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}


\PYG{k}{def} \PYG{n+nf}{tokenize\PYGZus{}gensim}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}\PYG{p}{:}

   \PYG{n}{tokens} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
   \PYG{c+c1}{\PYGZsh{} iterate through each sentence in the corpus}
   \PYG{k}{for} \PYG{n}{s} \PYG{o+ow}{in} \PYG{n}{corpus}\PYG{p}{:}

      \PYG{c+c1}{\PYGZsh{} tokenize the sentence into words}
      \PYG{n}{temp} \PYG{o}{=} \PYG{n}{gensim}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{tokenize}\PYG{p}{(}\PYG{n}{s}\PYG{p}{,} \PYG{n}{lowercase}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{deacc}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYGZbs{}
                                    \PYG{n}{errors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{strict}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{to\PYGZus{}lower}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYGZbs{}
                                    \PYG{n}{lower}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

      \PYG{n}{tokens}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{temp}\PYG{p}{)}\PYG{p}{)}

   \PYG{k}{return} \PYG{n}{tokens}

\PYG{n}{tokens} \PYG{o}{=} \PYG{n}{tokenize\PYGZus{}gensim}\PYG{p}{(}\PYG{n}{corpus}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} create FastText model}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{FastText}\PYG{p}{(}\PYG{n}{tokens}\PYG{p}{,} \PYG{n}{vector\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{window}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{min\PYGZus{}count}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{workers}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Train the model}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{train}\PYG{p}{(}\PYG{n}{tokens}\PYG{p}{,} \PYG{n}{total\PYGZus{}examples}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{tokens}\PYG{p}{)}\PYG{p}{,} \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Vocabulary}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{key\PYGZus{}to\PYGZus{}index}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{get\PYGZus{}normed\PYGZus{}vectors}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Print results}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cosine similarity between }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{gen}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+}
      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{and }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ai}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ \PYGZhy{} Word2Vec : }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
      \PYG{n}{model}\PYG{o}{.}\PYG{n}{wv}\PYG{o}{.}\PYG{n}{similarity}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{WARNING}\PYG{p}{:}\PYG{n}{gensim}\PYG{o}{.}\PYG{n}{models}\PYG{o}{.}\PYG{n}{word2vec}\PYG{p}{:}\PYG{n}{Effective} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{alpha}\PYG{l+s+s1}{\PYGZsq{}} \PYG{n}{higher} \PYG{n}{than} \PYG{n}{previous} \PYG{n}{training} \PYG{n}{cycles}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{5}\PYG{p}{\PYGZcb{}}
\PYG{p}{[}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01875759}  \PYG{l+m+mf}{0.086543}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.25080433}  \PYG{l+m+mf}{0.2824868}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.23755953} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11316587}
   \PYG{l+m+mf}{0.473383}    \PYG{l+m+mf}{0.39204055} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.30422893} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5566626} \PYG{p}{]}
\PYG{p}{[} \PYG{l+m+mf}{0.5088161}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.3323528}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.128698}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.11877266} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.38699347}  \PYG{l+m+mf}{0.20977001}
   \PYG{l+m+mf}{0.05947014} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05622245} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.36257952} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5177341} \PYG{p}{]}
\PYG{p}{[} \PYG{l+m+mf}{0.18038039}  \PYG{l+m+mf}{0.51484865}  \PYG{l+m+mf}{0.40694886}  \PYG{l+m+mf}{0.05965518} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05985437} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.10832689}
   \PYG{l+m+mf}{0.37992737}  \PYG{l+m+mf}{0.5992712}   \PYG{l+m+mf}{0.01503773}  \PYG{l+m+mf}{0.1192203} \PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5694013}   \PYG{l+m+mf}{0.23560704}  \PYG{l+m+mf}{0.0265804}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.41392225} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00285366} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.3076269}
   \PYG{l+m+mf}{0.2076883}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.425648}    \PYG{l+m+mf}{0.29903153}  \PYG{l+m+mf}{0.19965051}\PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.23892775}  \PYG{l+m+mf}{0.10744874} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.03730153} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.23521401}  \PYG{l+m+mf}{0.32083488}  \PYG{l+m+mf}{0.21598674}
\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.29570717} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.03044808}  \PYG{l+m+mf}{0.75250715}  \PYG{l+m+mf}{0.26538488}\PYG{p}{]}
\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.31881964} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.06544963} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.44274488}  \PYG{l+m+mf}{0.15485793}  \PYG{l+m+mf}{0.39120612} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05415314}
   \PYG{l+m+mf}{0.15772066} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.05987714} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.6986104}   \PYG{l+m+mf}{0.03967094}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{Cosine} \PYG{n}{similarity} \PYG{n}{between} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gen}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o+ow}{and} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ai}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o}{\PYGZhy{}} \PYG{n}{Word2Vec} \PYG{p}{:}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.21662527}
\end{sphinxVerbatim}


\section{Contextual word embeddings}
\label{\detokenize{embedding:contextual-word-embeddings}}
\sphinxAtStartPar
Contextual word embeddings are word representations where the embedding of a word
changes depending on its context in a sentence or document. These embeddings capture
the meaning of a word as influenced by its surrounding words, addressing the limitations
of static embeddings by incorporating contextual nuances.


\subsection{BERT}
\label{\detokenize{embedding:bert}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{transformers} \PYG{k+kn}{import} \PYG{n}{BertTokenizer}\PYG{p}{,} \PYG{n}{BertModel}
\PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{BertTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bert\PYGZhy{}base\PYGZhy{}uncased}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{BertModel}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bert\PYGZhy{}base\PYGZhy{}uncased}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}


\PYG{n}{text} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Gen AI is awesome}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{encoded\PYGZus{}input} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{embeddings} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{encoded\PYGZus{}input}\PYG{p}{)}\PYG{o}{.}\PYG{n}{last\PYGZus{}hidden\PYGZus{}state}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{encoded\PYGZus{}input}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{n}{x} \PYG{p}{:} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{+} \PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}\PYG{o}{+} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[EOS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{embeddings}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{embeddings}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{t}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,}  \PYG{l+m+mi}{8991}\PYG{p}{,}  \PYG{l+m+mi}{9932}\PYG{p}{,}  \PYG{l+m+mi}{2003}\PYG{p}{,} \PYG{l+m+mi}{12476}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{token\PYGZus{}type\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{attention\PYGZus{}mask}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[CLS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{101}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{8991}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AI}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{9932}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{is}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{2003}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{12476}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[EOS]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{1031}\PYG{p}{,} \PYG{l+m+mi}{1041}\PYG{p}{,} \PYG{l+m+mi}{2891}\PYG{p}{,} \PYG{l+m+mi}{1033}\PYG{p}{]}\PYG{p}{\PYGZcb{}}


\PYG{n}{torch}\PYG{o}{.}\PYG{n}{Size}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{768}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1129}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1477}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0056}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1335}\PYG{p}{,}  \PYG{l+m+mf}{0.2605}\PYG{p}{,}  \PYG{l+m+mf}{0.2113}\PYG{p}{]}\PYG{p}{,}
         \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.6841}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.1196}\PYG{p}{,}  \PYG{l+m+mf}{0.3349}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5958}\PYG{p}{,}  \PYG{l+m+mf}{0.1657}\PYG{p}{,}  \PYG{l+m+mf}{0.6988}\PYG{p}{]}\PYG{p}{,}
         \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5385}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2649}\PYG{p}{,}  \PYG{l+m+mf}{0.2639}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1544}\PYG{p}{,}  \PYG{l+m+mf}{0.2532}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1363}\PYG{p}{]}\PYG{p}{,}
         \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1794}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.6086}\PYG{p}{,}  \PYG{l+m+mf}{0.1292}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1620}\PYG{p}{,}  \PYG{l+m+mf}{0.1721}\PYG{p}{,}  \PYG{l+m+mf}{0.4356}\PYG{p}{]}\PYG{p}{,}
         \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0187}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.7320}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.3420}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.4028}\PYG{p}{,}  \PYG{l+m+mf}{0.1425}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2014}\PYG{p}{]}\PYG{p}{,}
         \PYG{p}{[} \PYG{l+m+mf}{0.5493}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1029}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1571}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.3503}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.7601}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1398}\PYG{p}{]}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{grad\PYGZus{}fn}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{NativeLayerNormBackward0}\PYG{o}{\PYGZgt{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{gte\sphinxhyphen{}large\sphinxhyphen{}en\sphinxhyphen{}v1.5}
\label{\detokenize{embedding:gte-large-en-v1-5}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{gte\sphinxhyphen{}large\sphinxhyphen{}en\sphinxhyphen{}v1.5}} is a state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art text embedding model developed
by Alibaba’s Institute for Intelligent Computing. It’s designed for natural
language processing tasks and excels in generating dense vector representations
(embeddings) of text for applications such as text retrieval, classification,
clustering, and reranking.

\sphinxAtStartPar
It can handle up to 8192 tokens, making it suitable for long\sphinxhyphen{}context tasks. More
details can be found at: \sphinxurl{https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5} .

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Requires transformers\PYGZgt{}=4.36.0}

\PYG{k+kn}{import} \PYG{n+nn}{torch}\PYG{n+nn}{.}\PYG{n+nn}{nn}\PYG{n+nn}{.}\PYG{n+nn}{functional} \PYG{k}{as} \PYG{n+nn}{F}
\PYG{k+kn}{from} \PYG{n+nn}{transformers} \PYG{k+kn}{import} \PYG{n}{AutoModel}\PYG{p}{,} \PYG{n}{AutoTokenizer}

\PYG{n}{input\PYGZus{}texts} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}

\PYG{n}{model\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Alibaba\PYGZhy{}NLP/gte\PYGZhy{}large\PYGZhy{}en\PYGZhy{}v1.5}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{AutoTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{model\PYGZus{}path}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{AutoModel}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{model\PYGZus{}path}\PYG{p}{,} \PYG{n}{trust\PYGZus{}remote\PYGZus{}code}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Tokenize the input texts}
\PYG{n}{batch\PYGZus{}dict} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{input\PYGZus{}texts}\PYG{p}{,} \PYG{n}{max\PYGZus{}length}\PYG{o}{=}\PYG{l+m+mi}{8192}\PYG{p}{,} \PYG{n}{padding}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYGZbs{}
                     \PYG{n}{truncation}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{batch\PYGZus{}dict}\PYG{p}{)}


\PYG{n}{outputs} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{batch\PYGZus{}dict}\PYG{p}{)}
\PYG{n}{embeddings} \PYG{o}{=} \PYG{n}{outputs}\PYG{o}{.}\PYG{n}{last\PYGZus{}hidden\PYGZus{}state}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} (Optionally) normalize embeddings}
\PYG{n}{embeddings} \PYG{o}{=} \PYG{n}{F}\PYG{o}{.}\PYG{n}{normalize}\PYG{p}{(}\PYG{n}{embeddings}\PYG{p}{,} \PYG{n}{p}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dim}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{scores} \PYG{o}{=} \PYG{p}{(}\PYG{n}{embeddings}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{@} \PYG{n}{embeddings}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{:}\PYG{p}{]}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{100}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{embeddings}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{scores}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,}  \PYG{l+m+mi}{8991}\PYG{p}{,}  \PYG{l+m+mi}{9932}\PYG{p}{,}  \PYG{l+m+mi}{2003}\PYG{p}{,} \PYG{l+m+mi}{12476}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,}  \PYG{l+m+mi}{8991}\PYG{p}{,}  \PYG{l+m+mi}{9932}\PYG{p}{,}  \PYG{l+m+mi}{2003}\PYG{p}{,}  \PYG{l+m+mi}{4569}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,}  \PYG{l+m+mi}{8991}\PYG{p}{,}  \PYG{l+m+mi}{9932}\PYG{p}{,}  \PYG{l+m+mi}{2003}\PYG{p}{,}  \PYG{l+m+mi}{2980}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{token\PYGZus{}type\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{attention\PYGZus{}mask}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{\PYGZcb{}}

\PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[} \PYG{l+m+mf}{0.0079}\PYG{p}{,}  \PYG{l+m+mf}{0.0008}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0001}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.0418}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0138}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0236}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[} \PYG{l+m+mf}{0.0079}\PYG{p}{,}  \PYG{l+m+mf}{0.0218}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0171}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.0412}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0230}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0237}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[} \PYG{l+m+mf}{0.0073}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0106}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0194}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.0711}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0204}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0036}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,}
      \PYG{n}{grad\PYGZus{}fn}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n}{DivBackward0}\PYG{o}{\PYGZgt{}}\PYG{p}{)}
\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{92.85284423828125}\PYG{p}{,} \PYG{l+m+mf}{92.81655883789062}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}


\subsection{bge\sphinxhyphen{}base\sphinxhyphen{}en\sphinxhyphen{}v1.5}
\label{\detokenize{embedding:bge-base-en-v1-5}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{bge\sphinxhyphen{}base\sphinxhyphen{}en\sphinxhyphen{}v1.5}} model is a general\sphinxhyphen{}purpose text embedding model developed
by the Beijing Academy of Artificial Intelligence (BAAI). It transforms input text
into 768\sphinxhyphen{}dimensional vector embeddings, making it useful for tasks like semantic
search, text similarity, and clustering. This model is fine\sphinxhyphen{}tuned using contrastive
learning, which helps improve its ability to distinguish between similar and
dissimilar sentences effectively. More details can be found
at: \sphinxurl{https://huggingface.co/BAAI/bge-base-en-v1.5} .

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{transformers} \PYG{k+kn}{import} \PYG{n}{AutoTokenizer}\PYG{p}{,} \PYG{n}{AutoModel}
\PYG{k+kn}{import} \PYG{n+nn}{torch}

\PYG{c+c1}{\PYGZsh{} Sentences we want sentence embeddings for}
\PYG{n}{sentences} \PYG{o}{=} \PYG{p}{[}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is awesome}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is fun}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gen AI is hot}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} Load model from HuggingFace Hub}
\PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{AutoTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BAAI/bge\PYGZhy{}large\PYGZhy{}zh\PYGZhy{}v1.5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{AutoModel}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BAAI/bge\PYGZhy{}large\PYGZhy{}zh\PYGZhy{}v1.5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{eval}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Tokenize sentences}
\PYG{n}{encoded\PYGZus{}input} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{sentences}\PYG{p}{,} \PYG{n}{padding}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{truncation}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{encoded\PYGZus{}input}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute token embeddings}
\PYG{k}{with} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{no\PYGZus{}grad}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
   \PYG{n}{model\PYGZus{}output} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{encoded\PYGZus{}input}\PYG{p}{)}
   \PYG{c+c1}{\PYGZsh{} Perform pooling. In this case, cls pooling.}
   \PYG{n}{sentence\PYGZus{}embeddings} \PYG{o}{=} \PYG{n}{model\PYGZus{}output}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} normalize embeddings}
\PYG{n}{sentence\PYGZus{}embeddings} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{nn}\PYG{o}{.}\PYG{n}{functional}\PYG{o}{.}\PYG{n}{normalize}\PYG{p}{(}\PYG{n}{sentence\PYGZus{}embeddings}\PYG{p}{,} \PYG{n}{p}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dim}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Sentence embeddings:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sentence\PYGZus{}embeddings}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,} \PYG{l+m+mi}{10234}\PYG{p}{,}  \PYG{l+m+mi}{8171}\PYG{p}{,}  \PYG{l+m+mi}{8578}\PYG{p}{,}  \PYG{l+m+mi}{8310}\PYG{p}{,}   \PYG{l+m+mi}{143}\PYG{p}{,} \PYG{l+m+mi}{11722}\PYG{p}{,}  \PYG{l+m+mi}{9974}\PYG{p}{,}  \PYG{l+m+mi}{8505}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,} \PYG{l+m+mi}{10234}\PYG{p}{,}  \PYG{l+m+mi}{8171}\PYG{p}{,}  \PYG{l+m+mi}{8578}\PYG{p}{,}  \PYG{l+m+mi}{8310}\PYG{p}{,}  \PYG{l+m+mi}{9575}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{,}     \PYG{l+m+mi}{0}\PYG{p}{,}     \PYG{l+m+mi}{0}\PYG{p}{,}     \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}  \PYG{l+m+mi}{101}\PYG{p}{,} \PYG{l+m+mi}{10234}\PYG{p}{,}  \PYG{l+m+mi}{8171}\PYG{p}{,}  \PYG{l+m+mi}{8578}\PYG{p}{,}  \PYG{l+m+mi}{8310}\PYG{p}{,}  \PYG{l+m+mi}{9286}\PYG{p}{,}   \PYG{l+m+mi}{102}\PYG{p}{,}     \PYG{l+m+mi}{0}\PYG{p}{,}     \PYG{l+m+mi}{0}\PYG{p}{,}     \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{token\PYGZus{}type\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{attention\PYGZus{}mask}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{\PYGZcb{}}

\PYG{n}{Sentence} \PYG{n}{embeddings}\PYG{p}{:} \PYG{n}{tensor}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[} \PYG{l+m+mf}{0.0700}\PYG{p}{,}  \PYG{l+m+mf}{0.0119}\PYG{p}{,}  \PYG{l+m+mf}{0.0049}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.0428}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0475}\PYG{p}{,}  \PYG{l+m+mf}{0.0242}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[} \PYG{l+m+mf}{0.0800}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0065}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0519}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.0057}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0770}\PYG{p}{,}  \PYG{l+m+mf}{0.0119}\PYG{p}{]}\PYG{p}{,}
      \PYG{p}{[} \PYG{l+m+mf}{0.0740}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0185}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0369}\PYG{p}{,}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}  \PYG{l+m+mf}{0.0083}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.0026}\PYG{p}{,}  \PYG{l+m+mf}{0.0016}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{embedding2d}.png}
\caption{t\sphinxhyphen{}SNE embeddings 2D}\label{\detokenize{embedding:id3}}\label{\detokenize{embedding:fig-embedding2d}}\end{figure}

\sphinxstepscope


\chapter{Prompt Engineering}
\label{\detokenize{prompt:prompt-engineering}}\label{\detokenize{prompt:prompt}}\label{\detokenize{prompt::doc}}
\begin{sphinxadmonition}{note}{Proverb}

\sphinxAtStartPar
Our master knows how to guide people skillfully and methodically.
He broadens my mind with culture and restrains me with ritual. \textendash{} \sphinxhref{https://brownbeat.medium.com/analects-of-confucius-book-9-new-english-translation-c7244d159591}{Zi Han}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Colab Notebook for This Chapter}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Prompt Engineering with Local LLM: \sphinxhref{https://colab.research.google.com/drive/19BnLVTnN5T3SIfFRaKUTGSviRwHlpDWf?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Prompt Engineering with OpenAI API: \sphinxhref{https://colab.research.google.com/drive/1x2EV8xwiM0z71Mx3dZki1z-VmjwGFLvL?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\end{sphinxadmonition}


\section{Prompt}
\label{\detokenize{prompt:id1}}
\sphinxAtStartPar
A prompt is the input or query given to an LLM to elicit a specific response.
It acts as the user’s way of “programming” the model without code, simply by
phrasing questions or tasks appropriately.


\section{Prompt Engineering}
\label{\detokenize{prompt:id2}}

\subsection{What’s Prompt Engineering}
\label{\detokenize{prompt:what-s-prompt-engineering}}
\sphinxAtStartPar
Prompt engineering is the practice of designing and refining input prompts to
guide LLMs to produce desired outputs effectively and consistently.
It involves crafting queries, commands, or instructions that align with
the model’s capabilities and the task’s requirements.


\subsection{Key Elements of a Prompt}
\label{\detokenize{prompt:key-elements-of-a-prompt}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Clarity: A clear and unambiguous prompt ensures the model understands the task.

\item {} 
\sphinxAtStartPar
Specificity: Including details like tone, format, length, or audience helps tailor the response.

\item {} 
\sphinxAtStartPar
Context:Providing background information ensures the model generates relevant outputs.

\end{itemize}


\section{Advanced Prompt Engineering}
\label{\detokenize{prompt:advanced-prompt-engineering}}

\subsection{Role Assignment}
\label{\detokenize{prompt:role-assignment}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Assign a specific role or persona to the AI to shape its style and expertise.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{“You are a professional data scientist. Explain how to build a machine learning model to a beginner.”}
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} You are a professional data scientist. Explain how to build a machine}
\PYG{c+c1}{\PYGZsh{} learning model to a beginner.}
\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{Role: you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{Answer:}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model} \PYG{o}{|} \PYG{n}{output\PYGZus{}parser}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data scientist}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{task}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Explain how to build a machine }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                            learning model to a beginner}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYG{p}{\PYGZob{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{role}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{assistant}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{content}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{To build a machine learning model, let}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s follow these steps as a beginner: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{1. **Define the Problem**: Understand what problem you are trying to solve. This could be anything from predicting house prices, recognizing images, or even recommending products. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{2. **Collect and Prepare Data**: Gather relevant data for your problem. This might involve web scraping, APIs, or using existing datasets. Once you have the data, clean it by handling missing values, outliers, and errors. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{3. **Explore and Visualize Data**: Understand the structure of your data, its distribution, and relationships between variables. This can help in identifying patterns and making informed decisions about the next steps. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{4. **Feature Engineering**: Create new features that might be useful for the model to make accurate predictions. This could involve creating interactions between existing features or using techniques like one\PYGZhy{}hot encoding. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{5. **Split Data**: Split your data into training, validation, and testing sets. The training set is used to train the model, the validation set is used to tune hyperparameters, and the testing set is used to evaluate the final performance of the model. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{6. **Choose a Model**: Select a machine learning algorithm that suits your problem. Some common algorithms include linear regression for regression problems, logistic regression for binary classification problems, decision trees, random forests, support vector machines (SVM), and neural networks for more complex tasks. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{7. **Train the Model**: Use your training data to train the chosen model. This involves feeding the data into the model and adjusting its parameters based on the error it makes. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{8. **Tune Hyperparameters**: Adjust the hyperparameters of the model to improve its performance. This could involve changing learning rates, number of layers in a neural network, or the complexity of a decision tree. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{9. **Evaluate the Model**: Use your testing data to evaluate the performance of the model. Common metrics include accuracy for classification problems, mean squared error for regression problems, and precision, recall, and F1 score for imbalanced datasets. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{10. **Deploy the Model**: Once you are satisfied with the performance of your model, deploy it to a production environment where it can make predictions on new data.}\PYG{l+s+s2}{\PYGZdq{}}
 \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Contextual Setup}
\label{\detokenize{prompt:contextual-setup}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Provide sufficient background or context for the AI to understand the task.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{“I am planing to write a book about GenAI best practice, help me draft the contents for the book.”}
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Contextual Setup}

\PYG{c+c1}{\PYGZsh{} I am planing to write a book about GenAI best practice, help me draft the}
\PYG{c+c1}{\PYGZsh{} contents for the book.}
\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{Role: you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{Answer:}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model} \PYG{o}{|} \PYG{n}{output\PYGZus{}parser}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{book writer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{task}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{I am planing to write a book about }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                        GenAI best practice, help me draft the }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                        contents for the book.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1. Introduction}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Introduction to General Artificial Intelligence (GenAI) and its significance in today}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s world.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2. Chapter 1 \PYGZhy{} Understanding AI}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Exploring the basics of Artificial Intelligence, its history, and evolution.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{3. Chapter 2 \PYGZhy{} Types of AI}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Detailed discussion on various types of AI such as Narrow AI, General AI, and Superintelligent AI.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{4. Chapter 3 \PYGZhy{} GenAI Architecture}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Exploring the architecture of General AI systems, including neural networks, deep learning, and reinforcement learning.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{5. Chapter 4 \PYGZhy{} Ethics in AI Development}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Discussing the ethical considerations involved in developing GenAI, such as privacy, bias, and accountability.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{6. Chapter 5 \PYGZhy{} Data Collection and Management}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Understanding the importance of data in AI development, best practices for data collection, and responsible data management.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{7. Chapter 6 \PYGZhy{} Model Training and Optimization}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Exploring techniques for training AI models effectively, including hyperparameter tuning, regularization, and optimization strategies.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{8. Chapter 7 \PYGZhy{} Testing and Validation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Discussing the importance of testing and validation in ensuring the reliability and accuracy of GenAI systems.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{9. Chapter 8 \PYGZhy{} Deployment and Maintenance}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Exploring best practices for deploying AI models into production environments, as well as ongoing maintenance and updates.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{10. Case Studies}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Real\PYGZhy{}world examples of successful GenAI implementations across various industries, highlighting key takeaways and lessons learned.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{11. Future Trends in GenAI}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Exploring emerging trends in the field of General AI, such as quantum computing, explainable AI, and human\PYGZhy{}AI collaboration.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{12. Conclusion}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Summarizing the key points discussed in the book and looking forward to the future of General AI.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Explicit Instructions}
\label{\detokenize{prompt:explicit-instructions}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Clearly specify the format, tone, style, or structure you want in the response.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{“Explain the concept of word embeddings in 100 words, using simple language suitable for a high school student.”}
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Explicit Instructions}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{ChatPromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{CommaSeparatedListOutputParser}


\PYG{c+c1}{\PYGZsh{} Explain the concept of word embeddings in 100 words, using simple}
\PYG{c+c1}{\PYGZsh{} language suitable for a high school student}

\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{instruction: }\PYG{l+s+si}{\PYGZob{}instruction\PYGZcb{}}
\PYG{l+s+s2}{Answer: Let}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s think step by step.}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AI engineer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{task}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Explain the concept of word embeddings in }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                100 words}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{instruction}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{using simple }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                language suitable for a high school student}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{assistant}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{message}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Word Embeddings are like giving words a special address in a big library. Each word gets its own unique location, and words that are used in similar ways get placed close together. This helps the computer understand the meaning of words better when it}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s reading text. For example, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{king}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ might be near }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{queen}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{, because they are both types of royalty. And }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{apple}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ might be near }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{fruit}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{, because they are related concepts.}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Chain of Thought (CoT) Prompting}
\label{\detokenize{prompt:chain-of-thought-cot-prompting}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Encourage step\sphinxhyphen{}by\sphinxhyphen{}step reasoning for complex problems.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{“Solve this math problem step by step: A train travels 60 miles in 1.5 hours. What is its average speed?”}
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} CoT}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{ChatPromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{CommaSeparatedListOutputParser}


\PYG{c+c1}{\PYGZsh{} Solve this math problem step by step: A train travels 60 miles in 1.5 hours.}
\PYG{c+c1}{\PYGZsh{} What is its average speed?}

\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}
\PYG{l+s+s2}{Answer: Let}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s think step by step.}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{math student}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{task}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Solve this math problem step by step: }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                A train travels 60 miles in 1.5 hours.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{question}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is its average speed per minute?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYG{p}{\PYGZob{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Solution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}
   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Step 1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{First, let}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s find the average speed of the train per hour.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Step 2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The train travels 60 miles in 1.5 hours. So, its speed per hour is 60 miles / 1.5 hours = 40 miles/hour.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Step 3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Now, let}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s find the average speed of the train per minute. Since there are 60 minutes in an hour, the speed per minute would be the speed per hour multiplied by the number of minutes in an hour divided by 60.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Step 4}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{So, the average speed of the train per minute is (40 miles/hour * (1 hour / 60)) = (40/60) miles/minute = 2/3 miles/minute.}\PYG{l+s+s2}{\PYGZdq{}}
             \PYG{p}{\PYGZcb{}}
 \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Few\sphinxhyphen{}Shot Prompting}
\label{\detokenize{prompt:few-shot-prompting}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Provide examples to guide the AI on how to respond.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
“Here are examples of loan application decision:
‘example’: \{‘input’: \{‘fico’:800, ‘income’:100000,’loan\_amount’: 10000\}
‘decision’: “accept”
Now Help me to make a decision to accpet or reject the loan application and
give the reason.
‘input’: “\{‘fico’:820, ‘income’:100000, ‘loan\_amount’: 1,000\}” “*

\end{itemize}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Few\PYGZhy{}Shot Prompting}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{ChatPromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{CommaSeparatedListOutputParser}


\PYG{c+c1}{\PYGZsh{} Here are examples of loan application decision:}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}example\PYGZsq{}: \PYGZob{}\PYGZsq{}input\PYGZsq{}: \PYGZob{}\PYGZsq{}fico\PYGZsq{}:800, \PYGZsq{}income\PYGZsq{}:100000,\PYGZsq{}loan\PYGZus{}amount\PYGZsq{}: 10000\PYGZcb{}}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}decision\PYGZsq{}: \PYGZdq{}accept\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{} Now Help me to make a decision to accpet or reject the loan application and}
\PYG{c+c1}{\PYGZsh{} give the reason.}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}input\PYGZsq{}: \PYGZdq{}\PYGZob{}\PYGZsq{}fico\PYGZsq{}:820, \PYGZsq{}income\PYGZsq{}:100000, \PYGZsq{}loan\PYGZus{}amount\PYGZsq{}: 1,000\PYGZcb{}\PYGZdq{}}

\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{examples: }\PYG{l+s+si}{\PYGZob{}example\PYGZcb{}}
\PYG{l+s+s2}{input: }\PYG{l+s+si}{\PYGZob{}input\PYGZcb{}}
\PYG{l+s+s2}{decision:}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{banker}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{task}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Help me to make a decision to accpet or }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                reject the loan application }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{example}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fico}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{800}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{income}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{100000}\PYG{p}{,}\PYGZbs{}
                                            \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{loan\PYGZus{}amount}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{10000}\PYG{p}{\PYGZcb{}}\PYG{p}{,}\PYGZbs{}
                                    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{decision}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accept}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fico}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{820}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{income}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{100000}\PYG{p}{,} \PYGZbs{}
                                    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{loan\PYGZus{}amount}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1000}\PYG{p}{\PYGZcb{}}
                        \PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{decision}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accept}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Iterative Prompting}
\label{\detokenize{prompt:iterative-prompting}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Build on the AI’s response by asking follow\sphinxhyphen{}up questions or refining the output.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{Initial Prompt:} “ Help me to make a decision to accpet or reject the loan application.”

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{Follow\sphinxhyphen{}Up:} “give me the reason”

\end{itemize}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Few\PYGZhy{}Shot Prompting}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{ChatPromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{CommaSeparatedListOutputParser}


\PYG{c+c1}{\PYGZsh{} Here are examples of loan application decision:}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}example\PYGZsq{}: \PYGZob{}\PYGZsq{}input\PYGZsq{}: \PYGZob{}\PYGZsq{}fico\PYGZsq{}:800, \PYGZsq{}income\PYGZsq{}:100000,\PYGZsq{}loan\PYGZus{}amount\PYGZsq{}: 10000\PYGZcb{}}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}decision\PYGZsq{}: \PYGZdq{}accept\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{} Now Help me to make a decision to accpet or reject the loan application and}
\PYG{c+c1}{\PYGZsh{} give the reason.}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}input\PYGZsq{}: \PYGZdq{}\PYGZob{}\PYGZsq{}fico\PYGZsq{}:820, \PYGZsq{}income\PYGZsq{}:100000, \PYGZsq{}loan\PYGZus{}amount\PYGZsq{}: 1,000\PYGZcb{}\PYGZdq{}}

\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{examples: }\PYG{l+s+si}{\PYGZob{}example\PYGZcb{}}
\PYG{l+s+s2}{input: }\PYG{l+s+si}{\PYGZob{}input\PYGZcb{}}
\PYG{l+s+s2}{decision:}
\PYG{l+s+s2}{reason:}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{banker}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{task}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Help me to make a decision to accpet or }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                reject the loan application and }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                give the reason.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{example}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fico}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{800}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{income}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{100000}\PYG{p}{,}\PYGZbs{}
                                            \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{loan\PYGZus{}amount}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{10000}\PYG{p}{\PYGZcb{}}\PYG{p}{,}\PYGZbs{}
                                    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{decision}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accept}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fico}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{820}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{income}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{100000}\PYG{p}{,} \PYGZbs{}
                                    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{loan\PYGZus{}amount}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{1000}\PYG{p}{\PYGZcb{}}
                        \PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{decision}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accept}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reason}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The applicant has a high credit score (FICO 820), a stable income of \PYGZdl{}100,000, and is requesting a relatively small loan amount (\PYGZdl{}1000). These factors indicate a low risk for the bank.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Instructional Chaining}
\label{\detokenize{prompt:instructional-chaining}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Break down a task into a sequence of smaller prompts.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
step 1: check the fico score

\item {} 
\sphinxAtStartPar
step 2: check the income,

\item {} 
\sphinxAtStartPar
step 3: check the loan amount,

\item {} 
\sphinxAtStartPar
step 4: make a decision,

\item {} 
\sphinxAtStartPar
step 5: give the reason.

\end{itemize}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Instructional Chaining}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{ChatPromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{CommaSeparatedListOutputParser}


\PYG{c+c1}{\PYGZsh{} Now Help me to make a decision to accpet or reject the loan application and}
\PYG{c+c1}{\PYGZsh{} give the reason.}
\PYG{c+c1}{\PYGZsh{} \PYGZsq{}\PYGZsq{}input\PYGZsq{}: \PYGZob{}\PYGZsq{}fico\PYGZsq{}:320, \PYGZsq{}income\PYGZsq{}:10000, \PYGZsq{}loan\PYGZus{}amount\PYGZsq{}: 100000\PYGZcb{}}

\PYG{n}{template} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{you are a }\PYG{l+s+si}{\PYGZob{}role\PYGZcb{}}
\PYG{l+s+s2}{task: }\PYG{l+s+si}{\PYGZob{}task\PYGZcb{}}
\PYG{l+s+s2}{instruction: }\PYG{l+s+si}{\PYGZob{}instruction\PYGZcb{}}
\PYG{l+s+s2}{input: }\PYG{l+s+si}{\PYGZob{}input\PYGZcb{}}
\PYG{l+s+s2}{decision:}
\PYG{l+s+s2}{reason:}
\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{ChatPromptTemplate}\PYG{o}{.}\PYG{n}{from\PYGZus{}template}\PYG{p}{(}\PYG{n}{template}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{n}{MODEL}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{output\PYGZus{}parser} \PYG{o}{=} \PYG{n}{CommaSeparatedListOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{model}

\PYG{n}{response} \PYG{o}{=} \PYG{n}{chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{role}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{banker}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{task}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Help me to make a decision to accpet or }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                reject the loan application and }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                give the reason.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{instruction}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step 1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{check the fico score}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step 2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{check the income}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step 3}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{check the loan amount}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step 4}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{make a decision}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYGZbs{}
                                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{step 5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{give the reason}\PYG{l+s+s2}{\PYGZdq{}}
                                        \PYG{p}{\PYGZcb{}}\PYG{p}{,}
                        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fico}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{320}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{income}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{10000}\PYG{p}{,} \PYGZbs{}
                                    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{loan\PYGZus{}amount}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{100000}\PYG{p}{\PYGZcb{}}
                        \PYG{p}{\PYGZcb{}}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{response}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{decision}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reject}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reason}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Based on the provided information, the applicant}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s FICO score is 320 which falls below our minimum acceptable credit score. Additionally, the proposed loan amount of \PYGZdl{}100,000 exceeds the income level of \PYGZdl{}10,000 per year, making it difficult for the borrower to repay the loan.}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Use Constraints}
\label{\detokenize{prompt:use-constraints}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Impose constraints to keep responses concise and on\sphinxhyphen{}topic.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}

\sphinxAtStartPar
\sphinxstyleemphasis{“List 5 key trends in AI in bullet points, each under 15 words.”}

\end{itemize}


\subsection{Creative Prompting}
\label{\detokenize{prompt:creative-prompting}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Encourage unique or unconventional ideas by framing the task creatively.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}

\sphinxAtStartPar
\sphinxstyleemphasis{“Pretend you are a time traveler from the year 2124. How would you describe AI advancements to someone today?”}

\end{itemize}


\subsection{Feedback Incorporation}
\label{\detokenize{prompt:feedback-incorporation}}\begin{itemize}
\item {} 
\sphinxAtStartPar
If the response isn’t perfect, guide the AI to refine or retry.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}

\sphinxAtStartPar
\sphinxstyleemphasis{“This is too general. Could you provide more specific examples for the education industry?”}

\end{itemize}


\subsection{Scenario\sphinxhyphen{}Based Prompts}
\label{\detokenize{prompt:scenario-based-prompts}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Frame the query within a scenario for a contextual response.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}

\sphinxAtStartPar
\sphinxstyleemphasis{“Imagine you’re a teacher explaining ChatGPT to students. How would you introduce its uses and limitations?”}

\end{itemize}


\subsection{Multimodal Prompting}
\label{\detokenize{prompt:multimodal-prompting}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Use prompts designed for mixed text/image inputs (or outputs if using models like DALL·E).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Example:}

\sphinxAtStartPar
\sphinxstyleemphasis{“Generate an image prompt for a futuristic cityscape, vibrant, with flying cars and greenery.”}

\end{itemize}

\sphinxstepscope


\chapter{Retrieval\sphinxhyphen{}Augmented Generation}
\label{\detokenize{rag:retrieval-augmented-generation}}\label{\detokenize{rag:rag}}\label{\detokenize{rag::doc}}
\begin{sphinxadmonition}{note}{Colab Notebook for This Chapter}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Naive Chunking: \sphinxhref{https://colab.research.google.com/drive/1r89QGmEDAS-ZJcfgYv6GKRrNDs4s\_lir?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Late Chunking: \sphinxhref{https://colab.research.google.com/drive/1ZqxmK1YuvPcpJap1psscMTih2jnQVINT?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Reciprocal Rank Fusion: \sphinxhref{https://colab.research.google.com/drive/1Vg7C5Z3Y7OlilnfQlQqkKyNrcnUR6Xry?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
RAG in colab: \sphinxhref{https://colab.research.google.com/drive/1jTkoER5eYQqBZs8RgOiCmTl8\_WDt67go?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Langchain Google Web Search \sphinxhref{https://colab.research.google.com/drive/17vLeVzcESb-jkY9NdOP1fRaO6I16Yfuz?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Langchain SQL Query \sphinxhref{https://colab.research.google.com/drive/1H\_EeFxWxXxX1KD8JupSsSMf1N-zfU8qR?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Self\sphinxhyphen{}RAG: \sphinxhref{https://colab.research.google.com/drive/1KbC4Wu-JUj6zbVuFkSNvtz3oVzWhEAZG?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Corrective RAG: \sphinxhref{https://colab.research.google.com/drive/1Sb7w1cTRZGkFs2LeF3F6gL8WNhjCdWyR?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Adaptive RAG: \sphinxhref{https://colab.research.google.com/drive/1tzihPk9Ln96RYcwn6WaHHQjlMdFvCviS?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
Agentic RAG: \sphinxhref{https://colab.research.google.com/drive/1-eZ61ux0QSCNx2jUDq\_vL-6OKLW8Hdr4?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{RAG_diagram}.png}
\caption{Retrieval\sphinxhyphen{}Augmented Generation Diagram}\label{\detokenize{rag:id38}}\label{\detokenize{rag:fig-rag}}\end{figure}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The naive chunking strategy was used in the diagram above. More advanced strategies,
such as Late Chunking \sphinxcite{reference:latechunking} (or Chunked Pooling), are discussed later in this chapter.
\end{sphinxadmonition}


\section{Overview}
\label{\detokenize{rag:overview}}
\sphinxAtStartPar
Retrieval\sphinxhyphen{}Augmented Generation (RAG) is a framework that enhances large language models (LLMs)
by combining their generative capabilities with external knowledge retrieval. The goal of RAG
is to improve accuracy, relevance, and factuality by providing the LLM with specific, up\sphinxhyphen{}to\sphinxhyphen{}date,
or domain\sphinxhyphen{}specific context from a knowledge base or database during the generation process.

\sphinxAtStartPar
As you can see in {\hyperref[\detokenize{rag:fig-rag}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Retrieval\sphinxhyphen{}Augmented Generation Diagram}}}}}, the RAG has there main  components
\begin{itemize}
\item {} 
\sphinxAtStartPar
Indexer: The indexer processes raw text or other forms of unstructured data and creates an
efficient structure (called an index) that allows for fast and accurate retrieval
by the retriever when a query is made.

\item {} 
\sphinxAtStartPar
Retriever: Responsible for finding relevant information from an external knowledge source,
such as a document database, a vector database, or the web.

\item {} 
\sphinxAtStartPar
Generator: An LLM (like GPT\sphinxhyphen{}4, T5, or similar) that uses the retrieved context to generate a response.
The model is “augmented” with the retrieved information, which reduces hallucination and enhances factual accuracy.

\end{itemize}


\section{Naive RAG}
\label{\detokenize{rag:naive-rag}}

\subsection{Indexing}
\label{\detokenize{rag:indexing}}
\sphinxAtStartPar
The indexing processes raw text or other forms of unstructured data and creates an efficient structure
(called an index) that allows for fast and accurate retrieval by the retriever when a query is made.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{indexer}.png}
\end{figure}


\subsubsection{Naive Chunking}
\label{\detokenize{rag:naive-chunking}}
\sphinxAtStartPar
Chunking in Retrieval\sphinxhyphen{}Augmented Generation (RAG) involves splitting documents or knowledge bases
into smaller, manageable pieces (chunks) that can be efficiently retrieved and used by a language model (LLM).

\sphinxAtStartPar
Below are the common chunking strategies used in RAG workflows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Fixed\sphinxhyphen{}Length Chunking}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Chunks are created with a predefined, fixed length (e.g., 200 words or 512 tokens).

\item {} 
\sphinxAtStartPar
Simple and easy to implement but might split content mid\sphinxhyphen{}sentence or lose semantic coherence.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{fixed\PYGZus{}length\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{200}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{words} \PYG{o}{=} \PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{[}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{words}\PYG{p}{[}\PYG{n}{i}\PYG{p}{:}\PYG{n}{i} \PYG{o}{+} \PYG{n}{chunk\PYGZus{}size}\PYG{p}{]}\PYG{p}{)}
        \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{words}\PYG{p}{)}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}size}\PYG{p}{)}
    \PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Example Usage}
\PYG{n}{document} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{This is a sample document with multiple sentences to demonstrate fixed\PYGZhy{}length chunking.}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{chunks} \PYG{o}{=} \PYG{n}{fixed\PYGZus{}length\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{document}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{chunk} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Chunk }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{idx}\PYG{+w}{ }\PYG{o}{+}\PYG{+w}{ }\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{chunk}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Output}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Chunk 1: This is a sample document with multiple sentences to demonstrate

\item {} 
\sphinxAtStartPar
Chunk 2: fixed\sphinxhyphen{}length chunking.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Sliding Window Chunking}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Creates overlapping chunks to preserve context across splits.

\item {} 
\sphinxAtStartPar
Ensures important information in overlapping regions is retained.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{sliding\PYGZus{}window\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{overlap\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{words} \PYG{o}{=} \PYG{n}{text}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{chunks} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{words}\PYG{p}{)}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}size} \PYG{o}{\PYGZhy{}} \PYG{n}{overlap\PYGZus{}size}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{chunk} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{words}\PYG{p}{[}\PYG{n}{i}\PYG{p}{:}\PYG{n}{i} \PYG{o}{+} \PYG{n}{chunk\PYGZus{}size}\PYG{p}{]}\PYG{p}{)}
        \PYG{n}{chunks}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{chunk}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{chunks}

\PYG{c+c1}{\PYGZsh{} Example Usage}
\PYG{n}{document} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{This is a sample document with multiple sentences to demonstrate sliding window chunking.}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{chunks} \PYG{o}{=} \PYG{n}{sliding\PYGZus{}window\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{document}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{overlap\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{chunk} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Chunk }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{idx}\PYG{+w}{ }\PYG{o}{+}\PYG{+w}{ }\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{chunk}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{description}
\sphinxlineitem{\sphinxstylestrong{Output}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Chunk 1: This is a sample document with multiple sentences to demonstrate

\item {} 
\sphinxAtStartPar
Chunk 2: with multiple sentences to demonstrate sliding window chunking.

\item {} 
\sphinxAtStartPar
Chunk 3: sliding window chunking.

\end{itemize}

\end{description}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Semantic Chunking}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Splits text based on natural language boundaries such as paragraphs, sentences, or specific delimiters (e.g., headings).

\item {} 
\sphinxAtStartPar
Retains semantic coherence, ideal for better retrieval and generation accuracy.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{nltk}
\PYG{n}{nltk}\PYG{o}{.}\PYG{n}{download}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{punkt\PYGZus{}tab}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{k}{def} \PYG{n+nf}{semantic\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{sentence\PYGZus{}len}\PYG{o}{=}\PYG{l+m+mi}{50}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{sentences} \PYG{o}{=} \PYG{n}{nltk}\PYG{o}{.}\PYG{n}{sent\PYGZus{}tokenize}\PYG{p}{(}\PYG{n}{text}\PYG{p}{)}

    \PYG{n}{chunks} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{chunk} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{for} \PYG{n}{sentence} \PYG{o+ow}{in} \PYG{n}{sentences}\PYG{p}{:}
        \PYG{k}{if} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{chunk}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)} \PYG{o}{+} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{sentence}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n}{sentence\PYGZus{}len}\PYG{p}{:}
            \PYG{n}{chunk} \PYG{o}{+}\PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{+} \PYG{n}{sentence}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n}{chunks}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{chunk}\PYG{o}{.}\PYG{n}{strip}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
            \PYG{n}{chunk} \PYG{o}{=} \PYG{n}{sentence}
    \PYG{k}{if} \PYG{n}{chunk}\PYG{p}{:}
        \PYG{n}{chunks}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{chunk}\PYG{o}{.}\PYG{n}{strip}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{chunks}

\PYG{c+c1}{\PYGZsh{} Example Usage}
\PYG{n}{document} \PYG{o}{=} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{This is a sample document. It is split based on semantic boundaries. }\PYG{l+s+s2}{\PYGZdq{}}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Each chunk will have coherent meaning for better retrieval.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{chunks} \PYG{o}{=} \PYG{n}{semantic\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{document}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{chunk} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Chunk }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{idx}\PYG{+w}{ }\PYG{o}{+}\PYG{+w}{ }\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{chunk}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Output}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Chunk 1: This is a sample document.

\item {} 
\sphinxAtStartPar
Chunk 2: It is split based on semantic boundaries.

\item {} 
\sphinxAtStartPar
Chunk 3: Each chunk will have coherent meaning for better retrieval.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dynamic Chunking}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Adapts chunk sizes based on content properties such as token count, content density, or specific criteria.

\item {} 
\sphinxAtStartPar
Useful when handling diverse document types with varying information density.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Example}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{transformers} \PYG{k+kn}{import} \PYG{n}{AutoTokenizer}

\PYG{k}{def} \PYG{n+nf}{dynamic\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{max\PYGZus{}tokens}\PYG{o}{=}\PYG{l+m+mi}{200}\PYG{p}{,} \PYG{n}{tokenizer\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bert\PYGZhy{}base\PYGZhy{}uncased}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{AutoTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{tokenizer\PYGZus{}name}\PYG{p}{)}
    \PYG{n}{tokens} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
    \PYG{n}{chunks} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{tokens}\PYG{p}{)}\PYG{p}{,} \PYG{n}{max\PYGZus{}tokens}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{chunk} \PYG{o}{=} \PYG{n}{tokens}\PYG{p}{[}\PYG{n}{i}\PYG{p}{:}\PYG{n}{i} \PYG{o}{+} \PYG{n}{max\PYGZus{}tokens}\PYG{p}{]}
        \PYG{n}{chunks}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{decode}\PYG{p}{(}\PYG{n}{chunk}\PYG{p}{)}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{chunks}

\PYG{c+c1}{\PYGZsh{} Example Usage}
\PYG{n}{document} \PYG{o}{=} \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{This is a sample document to demonstrate dynamic chunking. }\PYG{l+s+s2}{\PYGZdq{}}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The tokenizer adapts the chunks based on token limits.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{chunks} \PYG{o}{=} \PYG{n}{dynamic\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{document}\PYG{p}{,} \PYG{n}{max\PYGZus{}tokens}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{idx}\PYG{p}{,} \PYG{n}{chunk} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Chunk }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{idx}\PYG{+w}{ }\PYG{o}{+}\PYG{+w}{ }\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{chunk}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{description}
\sphinxlineitem{\sphinxstylestrong{Output}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Chunk 1: this is a sample document to demonstrate dynamic chunking

\item {} 
\sphinxAtStartPar
Chunk 2: . the tokenizer adapts the chunks based on

\item {} 
\sphinxAtStartPar
Chunk 3: token limits.

\end{itemize}

\end{description}

\end{enumerate}

\sphinxAtStartPar
Comparison of Strategies


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Strategy
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Pros
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Cons
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
Fixed\sphinxhyphen{}Length Chunking
&
\sphinxAtStartPar
Simple, fast
&
\sphinxAtStartPar
May split text mid\sphinxhyphen{}sentence
or lose coherence.
\\
\sphinxhline
\sphinxAtStartPar
Sliding Window Chunking
&
\sphinxAtStartPar
Preserves context
&
\sphinxAtStartPar
Overlapping increases redundancy.
\\
\sphinxhline
\sphinxAtStartPar
Semantic Chunking
&
\sphinxAtStartPar
Coherent chunks
&
\sphinxAtStartPar
Requires NLP preprocessing.
\\
\sphinxhline
\sphinxAtStartPar
Dynamic Chunking
&
\sphinxAtStartPar
Adapts to content
&
\sphinxAtStartPar
Computationally intensive.
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Each strategy has its strengths and weaknesses. Select based on the task requirements, context, and available computational resources.

\sphinxAtStartPar
The optimal chunk length depends on the type of content being processed and the intended use case.
Below are recommendations for chunk lengths based on different context types, along with their rationale:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Context Type
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Chunk Length (Tokens)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Rationale
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
FAQs or Short Texts
&
\sphinxAtStartPar
100\sphinxhyphen{}200
&
\sphinxAtStartPar
Short enough to handle specific queries.
\\
\sphinxhline
\sphinxAtStartPar
Articles or Blog Posts
&
\sphinxAtStartPar
300\sphinxhyphen{}500
&
\sphinxAtStartPar
Covers logical sections while fitting multiple
chunks in the LLM context.
\\
\sphinxhline
\sphinxAtStartPar
Research Papers or Reports
&
\sphinxAtStartPar
500\sphinxhyphen{}700
&
\sphinxAtStartPar
Captures detailed sections like methodology
or results.
\\
\sphinxhline
\sphinxAtStartPar
Legal or Technical Texts
&
\sphinxAtStartPar
200\sphinxhyphen{}300
&
\sphinxAtStartPar
Maintains precision due to dense information.
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
The valuating Chunking Strategies for Retrieval can be found at: \sphinxurl{https://research.trychroma.com/evaluating-chunking}


\subsubsection{Late Chunking}
\label{\detokenize{rag:late-chunking}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{late_chunking}.png}
\caption{An illustration of the naive chunking strategy (left) and the late chunking strategy (right). (Souce \sphinxhref{https://jina.ai/news/late-chunking-in-long-context-embedding-models/}{Jina AI})}\label{\detokenize{rag:id39}}\label{\detokenize{rag:fig-late-chunk}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Late Chunking} refers to a strategy in Retrieval\sphinxhyphen{}Augmented Generation (RAG) where chunking of
data is \sphinxstylestrong{deferred until query time}. Unlike pre\sphinxhyphen{}chunking, where documents are split into chunks
during preprocessing, late chunking dynamically extracts relevant content when a query is made.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Key Concepts of Late Chunking
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dynamic Chunk Creation}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Full documents or large sections are stored in the vector database.

\item {} 
\sphinxAtStartPar
Relevant chunks are dynamically extracted at query time based on the query and similarity match.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Query\sphinxhyphen{}Time Optimization}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The system identifies relevant content using similarity search or semantic analysis.

\item {} 
\sphinxAtStartPar
Only the most relevant content is chunked and passed to the language model.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Reduced Preprocessing Time}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Eliminates extensive preprocessing and fixed chunking during data ingestion.

\item {} 
\sphinxAtStartPar
Higher computational cost occurs during query\sphinxhyphen{}time retrieval.

\end{itemize}

\end{itemize}

\end{itemize}

\sphinxAtStartPar
The folloing implementations are from \sphinxhref{https://jina.ai/news/late-chunking-in-long-context-embedding-models/}{Jina AI}, and the copyright belongs to the original author.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{chunk\PYGZus{}by\PYGZus{}sentences}\PYG{p}{(}\PYG{n}{input\PYGZus{}text}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{p}{:} \PYG{n+nb}{callable}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Split the input text into sentences using the tokenizer}
\PYG{l+s+sd}{    :param input\PYGZus{}text: The text snippet to split into sentences}
\PYG{l+s+sd}{    :param tokenizer: The tokenizer to use}
\PYG{l+s+sd}{    :return: A tuple containing the list of text chunks and their corresponding token spans}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{inputs} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{input\PYGZus{}text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{return\PYGZus{}offsets\PYGZus{}mapping}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
    \PYG{n}{punctuation\PYGZus{}mark\PYGZus{}id} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{convert\PYGZus{}tokens\PYGZus{}to\PYGZus{}ids}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{sep\PYGZus{}id} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{convert\PYGZus{}tokens\PYGZus{}to\PYGZus{}ids}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[SEP]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{token\PYGZus{}offsets} \PYG{o}{=} \PYG{n}{inputs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{offset\PYGZus{}mapping}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{token\PYGZus{}ids} \PYG{o}{=} \PYG{n}{inputs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{input\PYGZus{}ids}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{chunk\PYGZus{}positions} \PYG{o}{=} \PYG{p}{[}
        \PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n+nb}{int}\PYG{p}{(}\PYG{n}{start} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
        \PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{p}{(}\PYG{n}{token\PYGZus{}id}\PYG{p}{,} \PYG{p}{(}\PYG{n}{start}\PYG{p}{,} \PYG{n}{end}\PYG{p}{)}\PYG{p}{)} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{token\PYGZus{}ids}\PYG{p}{,} \PYG{n}{token\PYGZus{}offsets}\PYG{p}{)}\PYG{p}{)}
        \PYG{k}{if} \PYG{n}{token\PYGZus{}id} \PYG{o}{==} \PYG{n}{punctuation\PYGZus{}mark\PYGZus{}id}
        \PYG{o+ow}{and} \PYG{p}{(}
            \PYG{n}{token\PYGZus{}offsets}\PYG{p}{[}\PYG{n}{i} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{\PYGZhy{}} \PYG{n}{token\PYGZus{}offsets}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{\PYGZgt{}} \PYG{l+m+mi}{0}
            \PYG{o+ow}{or} \PYG{n}{token\PYGZus{}ids}\PYG{p}{[}\PYG{n}{i} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{==} \PYG{n}{sep\PYGZus{}id}
        \PYG{p}{)}
    \PYG{p}{]}
    \PYG{n}{chunks} \PYG{o}{=} \PYG{p}{[}
        \PYG{n}{input\PYGZus{}text}\PYG{p}{[}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{p}{:} \PYG{n}{y}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}
        \PYG{k}{for} \PYG{n}{x}\PYG{p}{,} \PYG{n}{y} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{p}{[}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{]} \PYG{o}{+} \PYG{n}{chunk\PYGZus{}positions}\PYG{p}{[}\PYG{p}{:}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}positions}\PYG{p}{)}
    \PYG{p}{]}
    \PYG{n}{span\PYGZus{}annotations} \PYG{o}{=} \PYG{p}{[}
        \PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{y}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)} \PYG{k}{for} \PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{p}{[}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{]} \PYG{o}{+} \PYG{n}{chunk\PYGZus{}positions}\PYG{p}{[}\PYG{p}{:}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}positions}\PYG{p}{)}
    \PYG{p}{]}
    \PYG{k}{return} \PYG{n}{chunks}\PYG{p}{,} \PYG{n}{span\PYGZus{}annotations}

\PYG{k}{def} \PYG{n+nf}{late\PYGZus{}chunking}\PYG{p}{(}
    \PYG{n}{model\PYGZus{}output}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BatchEncoding}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{span\PYGZus{}annotation}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{,} \PYG{n}{max\PYGZus{}length}\PYG{o}{=}\PYG{k+kc}{None}
\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{token\PYGZus{}embeddings} \PYG{o}{=} \PYG{n}{model\PYGZus{}output}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{n}{outputs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{embeddings}\PYG{p}{,} \PYG{n}{annotations} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{token\PYGZus{}embeddings}\PYG{p}{,} \PYG{n}{span\PYGZus{}annotation}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{if} \PYG{p}{(}
            \PYG{n}{max\PYGZus{}length} \PYG{o+ow}{is} \PYG{o+ow}{not} \PYG{k+kc}{None}
        \PYG{p}{)}\PYG{p}{:}  \PYG{c+c1}{\PYGZsh{} remove annotations which go bejond the max\PYGZhy{}length of the model}
            \PYG{n}{annotations} \PYG{o}{=} \PYG{p}{[}
                \PYG{p}{(}\PYG{n}{start}\PYG{p}{,} \PYG{n+nb}{min}\PYG{p}{(}\PYG{n}{end}\PYG{p}{,} \PYG{n}{max\PYGZus{}length} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}
                \PYG{k}{for} \PYG{p}{(}\PYG{n}{start}\PYG{p}{,} \PYG{n}{end}\PYG{p}{)} \PYG{o+ow}{in} \PYG{n}{annotations}
                \PYG{k}{if} \PYG{n}{start} \PYG{o}{\PYGZlt{}} \PYG{p}{(}\PYG{n}{max\PYGZus{}length} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{1}\PYG{p}{)}
            \PYG{p}{]}
        \PYG{n}{pooled\PYGZus{}embeddings} \PYG{o}{=} \PYG{p}{[}
            \PYG{n}{embeddings}\PYG{p}{[}\PYG{n}{start}\PYG{p}{:}\PYG{n}{end}\PYG{p}{]}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{n}{dim}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{n}{end} \PYG{o}{\PYGZhy{}} \PYG{n}{start}\PYG{p}{)}
            \PYG{k}{for} \PYG{n}{start}\PYG{p}{,} \PYG{n}{end} \PYG{o+ow}{in} \PYG{n}{annotations}
            \PYG{k}{if} \PYG{p}{(}\PYG{n}{end} \PYG{o}{\PYGZhy{}} \PYG{n}{start}\PYG{p}{)} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{l+m+mi}{1}
        \PYG{p}{]}
        \PYG{n}{pooled\PYGZus{}embeddings} \PYG{o}{=} \PYG{p}{[}
            \PYG{n}{embedding}\PYG{o}{.}\PYG{n}{detach}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{cpu}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{numpy}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{embedding} \PYG{o+ow}{in} \PYG{n}{pooled\PYGZus{}embeddings}
        \PYG{p}{]}
        \PYG{n}{outputs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{pooled\PYGZus{}embeddings}\PYG{p}{)}

    \PYG{k}{return} \PYG{n}{outputs}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{input\PYGZus{}text} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Berlin is the capital and largest city of Germany, both by area and by population. Its more than 3.85 million inhabitants make it the European Union}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s most populous city, as measured by population within city limits. The city is also one of the states of Germany, and is the third smallest state in the country in terms of area.}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} determine chunks}
\PYG{n}{chunks}\PYG{p}{,} \PYG{n}{span\PYGZus{}annotations} \PYG{o}{=} \PYG{n}{chunk\PYGZus{}by\PYGZus{}sentences}\PYG{p}{(}\PYG{n}{input\PYGZus{}text}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Chunks:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{} }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o}{+} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{} }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{)} \PYG{o}{+} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} chunk before}
\PYG{n}{embeddings\PYGZus{}traditional\PYGZus{}chunking} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} chunk afterwards (context\PYGZhy{}sensitive chunked pooling)}
\PYG{n}{inputs} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{p}{(}\PYG{n}{input\PYGZus{}text}\PYG{p}{,} \PYG{n}{return\PYGZus{}tensors}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{model\PYGZus{}output} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{inputs}\PYG{p}{)}
\PYG{n}{embeddings} \PYG{o}{=} \PYG{n}{late\PYGZus{}chunking}\PYG{p}{(}\PYG{n}{model\PYGZus{}output}\PYG{p}{,} \PYG{p}{[}\PYG{n}{span\PYGZus{}annotations}\PYG{p}{]}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{n}{cos\PYGZus{}sim} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{norm}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{berlin\PYGZus{}embedding} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Berlin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{chunk}\PYG{p}{,} \PYG{n}{new\PYGZus{}embedding}\PYG{p}{,} \PYG{n}{trad\PYGZus{}embeddings} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{chunks}\PYG{p}{,} \PYG{n}{embeddings}\PYG{p}{,} \PYG{n}{embeddings\PYGZus{}traditional\PYGZus{}chunking}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{similarity\PYGZus{}new(}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Berlin}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{, }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{chunk}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{):}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cos\PYGZus{}sim}\PYG{p}{(}\PYG{n}{berlin\PYGZus{}embedding}\PYG{p}{,} \PYG{n}{new\PYGZus{}embedding}\PYG{p}{)}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{similarity\PYGZus{}trad(}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Berlin}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{, }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{chunk}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{):}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cos\PYGZus{}sim}\PYG{p}{(}\PYG{n}{berlin\PYGZus{}embedding}\PYG{p}{,} \PYG{n}{trad\PYGZus{}embeddings}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTT}
\sphinxtoprule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
Query
&
\sphinxAtStartPar
Chunk
&
\sphinxAtStartPar
\sphinxstylestrong{similarity\_new}
&
\sphinxAtStartPar
\sphinxstylestrong{similarity\_trad}
\\
\sphinxhline
\sphinxAtStartPar
Berlin
&
\sphinxAtStartPar
Berlin is the capital and largest city of Germany, both by area and by population.
&
\sphinxAtStartPar
0.849546
&
\sphinxAtStartPar
0.8486219
\\
\sphinxhline
\sphinxAtStartPar
Berlin
&
\sphinxAtStartPar
Its more than 3.85 million inhabitants make it the European Union’s most populous city,
as measured by population within city limits.”
&
\sphinxAtStartPar
0.82489026
&
\sphinxAtStartPar
0.70843387
\\
\sphinxhline
\sphinxAtStartPar
Berlin
&
\sphinxAtStartPar
The city is also one of the states of Germany, and is the third smallest state in the
country in terms of area.”
&
\sphinxAtStartPar
0.8498009
&
\sphinxAtStartPar
0.75345534
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\subsubsection{Types of Indexing}
\label{\detokenize{rag:types-of-indexing}}
\sphinxAtStartPar
The embedding methods we introduced in Chapter {\hyperref[\detokenize{embedding:embedding}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Word and Sentence Embedding}}}}} can be applied here to convert each chunk
into embeddings and create indexing. These indexings(embeddings) will be used to retrieve relevant documents or information.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Sparse Indexing:

\sphinxAtStartPar
Uses traditional keyword\sphinxhyphen{}based methods (e.g., TF\sphinxhyphen{}IDF, BM25).
Index stores the frequency of terms and their associations with documents.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Advantages:Easy to understand and deploy and works well for exact matches or keyword\sphinxhyphen{}heavy queries.

\item {} 
\sphinxAtStartPar
Disadvantages: Struggles with semantic understanding or paraphrased queries.

\end{itemize}

\item {} 
\sphinxAtStartPar
Dense Indexing:

\sphinxAtStartPar
Uses vector embeddings to capture semantic meaning. Documents are represented as vectors in a
high\sphinxhyphen{}dimensional space, enabling similarity search.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Advantages: Excellent for semantic search, handling synonyms, and paraphrasing.

\item {} 
\sphinxAtStartPar
Disadvantages: Requires more computational resources for storage and retrieval.

\end{itemize}

\item {} 
\sphinxAtStartPar
Hybrid Indexing:

\sphinxAtStartPar
Combines sparse and dense indexing for more robust search capabilities. For example, Elasticsearch
can integrate BM25 with vector search.

\end{itemize}


\subsubsection{Vector Database}
\label{\detokenize{rag:vector-database}}
\sphinxAtStartPar
Vector databases are essential for Retrieval\sphinxhyphen{}Augmented Generation (RAG) systems, enabling
efficient similarity search on dense vector embeddings. Below is a comprehensive overview
of popular vector databases for RAG workflows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{FAISS (Facebook AI Similarity Search)}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} An open\sphinxhyphen{}source library developed by Facebook AI for efficient similarity search and clustering of dense vectors.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} High performance and scalability.
\sphinxhyphen{} Supports various indexing methods like \sphinxcode{\sphinxupquote{Flat}}, \sphinxcode{\sphinxupquote{IVF}}, and \sphinxcode{\sphinxupquote{HNSW}}.
\sphinxhyphen{} GPU acceleration for faster searches.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Research and prototyping.
\sphinxhyphen{} Scenarios requiring custom implementations.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Limitations}:
\sphinxhyphen{} File\sphinxhyphen{}based storage; lacks a built\sphinxhyphen{}in distributed or managed cloud solution.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://github.com/facebookresearch/faiss}{FAISS GitHub}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Pinecone}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} A fully managed vector database designed for production\sphinxhyphen{}scale workloads.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Scalable and serverless architecture.
\sphinxhyphen{} Automatic scaling and optimization of indexes.
\sphinxhyphen{} Hybrid search (combining vector and keyword search).
\sphinxhyphen{} Integrates with popular frameworks like LangChain and OpenAI.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Enterprise\sphinxhyphen{}grade applications.
\sphinxhyphen{} Handling large datasets with minimal operational overhead.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://www.pinecone.io/}{Pinecone}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Weaviate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} An open\sphinxhyphen{}source vector search engine with a strong focus on modularity and customization.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Supports hybrid search and symbolic reasoning.
\sphinxhyphen{} Schema\sphinxhyphen{}based data organization.
\sphinxhyphen{} Plugin support for pre\sphinxhyphen{}built and custom vectorization modules.
\sphinxhyphen{} Cloud\sphinxhyphen{}managed and self\sphinxhyphen{}hosted options.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Applications requiring hybrid search capabilities.
\sphinxhyphen{} Knowledge graphs and semantically rich data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://weaviate.io/}{Weaviate}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Milvus}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} An open\sphinxhyphen{}source, high\sphinxhyphen{}performance vector database designed for similarity search on large datasets.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Distributed and scalable architecture.
\sphinxhyphen{} Integration with FAISS, Annoy, and HNSW indexing techniques.
\sphinxhyphen{} Built\sphinxhyphen{}in support for time travel queries (searching historical data).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Video, audio, and image search applications.
\sphinxhyphen{} Large\sphinxhyphen{}scale datasets requiring real\sphinxhyphen{}time indexing and retrieval.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://milvus.io/}{Milvus}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Qdrant}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} An open\sphinxhyphen{}source, lightweight vector database focused on ease of use and modern developer needs.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Supports HNSW for efficient vector search.
\sphinxhyphen{} Advanced filtering capabilities for combining metadata with vector queries.
\sphinxhyphen{} REST and gRPC APIs for integration.
\sphinxhyphen{} Docker\sphinxhyphen{}ready deployment.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Scenarios requiring metadata\sphinxhyphen{}rich search.
\sphinxhyphen{} Lightweight deployments with simplicity in mind.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://qdrant.tech/}{Qdrant}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Redis (with Vector Similarity Search Module)}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} A popular in\sphinxhyphen{}memory database with a module for vector similarity search.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Combines vector search with traditional key\sphinxhyphen{}value storage.
\sphinxhyphen{} Supports hybrid search and metadata filtering.
\sphinxhyphen{} High throughput and low latency due to in\sphinxhyphen{}memory architecture.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Applications requiring real\sphinxhyphen{}time, low\sphinxhyphen{}latency search.
\sphinxhyphen{} Integrating vector search with existing Redis\sphinxhyphen{}based systems.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://redis.io/docs/stack/search/}{Redis Vector Search}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Zilliz}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} A cloud\sphinxhyphen{}native vector database built on Milvus for scalable and managed vector storage.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Fully managed service for vector data.
\sphinxhyphen{} Seamless scaling and distributed indexing.
\sphinxhyphen{} Integration with machine learning pipelines.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Large\sphinxhyphen{}scale enterprise deployments.
\sphinxhyphen{} Cloud\sphinxhyphen{}native solutions with minimal infrastructure management.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://zilliz.com/}{Zilliz}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Vespa}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} A real\sphinxhyphen{}time serving engine supporting vector and hybrid search.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Combines vector search with advanced ranking and filtering.
\sphinxhyphen{} Scales to large datasets with support for distributed clusters.
\sphinxhyphen{} Powerful query configuration options.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} E\sphinxhyphen{}commerce and recommendation systems.
\sphinxhyphen{} Applications with complex ranking requirements.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://vespa.ai/}{Vespa}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Chroma}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
\sphinxhyphen{} An open\sphinxhyphen{}source, user\sphinxhyphen{}friendly vector database built for LLMs and embedding\sphinxhyphen{}based applications.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Features}:
\sphinxhyphen{} Designed specifically for RAG workflows.
\sphinxhyphen{} Simple Python API for seamless integration with AI models.
\sphinxhyphen{} Efficient and customizable vector storage for embedding data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Use Cases}:
\sphinxhyphen{} Prototyping and experimentation for LLM\sphinxhyphen{}based applications.
\sphinxhyphen{} Lightweight deployments for small to medium\sphinxhyphen{}scale RAG systems.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Official Website}: \sphinxhref{https://www.trychroma.com/}{Chroma}

\end{itemize}

\end{enumerate}

\sphinxAtStartPar
Comparison of Vector Databases:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Database}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Open Source}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Managed Service}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Key Features}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Best For}
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
FAISS
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
High performance, GPU acceleration
&
\sphinxAtStartPar
Research, prototyping
\\
\sphinxhline
\sphinxAtStartPar
Pinecone
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
Serverless, automatic scaling
&
\sphinxAtStartPar
Enterprise\sphinxhyphen{}scale applications
\\
\sphinxhline
\sphinxAtStartPar
Weaviate
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
Hybrid search, modularity
&
\sphinxAtStartPar
Knowledge graphs
\\
\sphinxhline
\sphinxAtStartPar
Milvus
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Distributed, high performance
&
\sphinxAtStartPar
Large\sphinxhyphen{}scale datasets
\\
\sphinxhline
\sphinxAtStartPar
Qdrant
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Lightweight, metadata filtering
&
\sphinxAtStartPar
Small to medium\sphinxhyphen{}scale apps
\\
\sphinxhline
\sphinxAtStartPar
Redis
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
In\sphinxhyphen{}memory performance, hybrid search
&
\sphinxAtStartPar
Real\sphinxhyphen{}time apps
\\
\sphinxhline
\sphinxAtStartPar
Zilliz
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
Fully managed Milvus
&
\sphinxAtStartPar
Enterprise cloud solutions
\\
\sphinxhline
\sphinxAtStartPar
Vespa
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Hybrid search, real\sphinxhyphen{}time ranking
&
\sphinxAtStartPar
E\sphinxhyphen{}commerce, recommendations
\\
\sphinxhline
\sphinxAtStartPar
Chroma
&
\sphinxAtStartPar
Yes
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
LLM\sphinxhyphen{}focused, simple API
&
\sphinxAtStartPar
Prototyping, lightweight apps
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Choosing a Vector Database
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{For Research or Small Projects}: FAISS, Qdrant, Milvus, or Chroma.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{For Enterprise or Cloud\sphinxhyphen{}Native Workflows}: Pinecone, Zilliz, or Weaviate.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{For Real\sphinxhyphen{}Time Use Cases}: Redis or Vespa.

\end{itemize}

\sphinxAtStartPar
Each database has unique strengths and is suited for specific RAG use cases. The choice depends on scalability, integration needs, and budget.


\subsection{Retrieval}
\label{\detokenize{rag:retrieval}}
\sphinxAtStartPar
The retriever selects “chunks” of text (e.g., paragraphs or sections) relevant to the user’s query.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{retriever}.png}
\caption{Reciprocal Rank Fusion}\label{\detokenize{rag:id40}}\label{\detokenize{rag:fig-retriever}}\end{figure}


\subsubsection{Common retrieval methods}
\label{\detokenize{rag:common-retrieval-methods}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Sparse Vector Search}: Traditional keyword\sphinxhyphen{}based retrieval (e.g., TF\sphinxhyphen{}IDF, BM25).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dense Vector Search}: Vector\sphinxhyphen{}based search using embeddings e.g.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Approximate Nearest Neighbor (ANN) Search}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
HNSW (Hierarchical Navigable Small World): Graph\sphinxhyphen{}based approach

\item {} 
\sphinxAtStartPar
IVF (Inverted File Index): Clusters embeddings into groups and searches within relevant clusters.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Exact Nearest Neighbor Search}: Computes similarities exhaustively for all vectors in the corpus

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Hybrid Search} (Fig {\hyperref[\detokenize{rag:fig-retriever}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Reciprocal Rank Fusion}}}}}): the combination of Sparse and Dense vector search.

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
BM25 (Best Matching 25) is a popular ranking function used by search engines
and information retrieval systems to rank documents based on their relevance
to a given query. It belongs to the family of \sphinxstylestrong{bag\sphinxhyphen{}of\sphinxhyphen{}words retrieval models}
and is an enhancement of the \sphinxstylestrong{TF\sphinxhyphen{}IDF (Term Frequency\sphinxhyphen{}Inverse Document Frequency)} approach.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Key Features of BM25}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Relevance Scoring}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
BM25 scores documents by measuring how well the query terms match the terms in the document.

\item {} 
\sphinxAtStartPar
It incorporates term frequency, inverse document frequency, and document length normalization.

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Formula}:

\end{enumerate}
\begin{quote}

\sphinxAtStartPar
The BM25 score for a document \sphinxcode{\sphinxupquote{D}} given a query \sphinxcode{\sphinxupquote{Q}} is calculated as:
\begin{equation*}
\begin{split}\text{BM25}(D, Q) = \sum_{t \in Q} \text{IDF}(t) \cdot \frac{\text{f}(t, D) \cdot (k_1 + 1)}{\text{f}(t, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})}\end{split}
\end{equation*}
\sphinxAtStartPar
Where:
\sphinxhyphen{} \sphinxcode{\sphinxupquote{t}}: Query term.
\sphinxhyphen{} \sphinxcode{\sphinxupquote{f(t, D)}}: Frequency of term \sphinxcode{\sphinxupquote{t}} in document \sphinxcode{\sphinxupquote{D}}.
\sphinxhyphen{} \sphinxcode{\sphinxupquote{|D|}}: Length of document \sphinxcode{\sphinxupquote{D}} (number of terms).
\sphinxhyphen{} \sphinxcode{\sphinxupquote{avgdl}}: Average document length in the corpus.
\sphinxhyphen{} \sphinxcode{\sphinxupquote{k1}}: Tuning parameter that controls term frequency saturation (usually set between 1.2 and 2.0).
\sphinxhyphen{} \sphinxcode{\sphinxupquote{b}}: Tuning parameter that controls length normalization (usually set to 0.75).
\sphinxhyphen{} \sphinxcode{\sphinxupquote{IDF(t)}}: Inverse Document Frequency of term \sphinxcode{\sphinxupquote{t}}, calculated as:
\begin{equation*}
\begin{split}\text{IDF}(t) = \log \frac{N - n_t + 0.5}{n_t + 0.5}\end{split}
\end{equation*}
\sphinxAtStartPar
Where \sphinxcode{\sphinxupquote{N}} is the total number of documents in the corpus, and \sphinxcode{\sphinxupquote{n\_t}} is the number of documents containing \sphinxcode{\sphinxupquote{t}}.
\end{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Improvements Over TF\sphinxhyphen{}IDF}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Document Length Normalization: BM25 adjusts for the length of documents, addressing the bias of TF\sphinxhyphen{}IDF toward longer documents.

\item {} 
\sphinxAtStartPar
Saturation of Term Frequency: BM25 avoids the overemphasis of excessively high term frequencies by using a non\sphinxhyphen{}linear saturation function controlled by \sphinxcode{\sphinxupquote{k1}}.

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Applications}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Information Retrieval}: Ranking search results by relevance.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Question Answering}: Identifying relevant documents or passages for a query.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Document Matching}: Comparing similarities between textual content.

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Limitations}:

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
BM25 does not consider semantic meanings or relationships between words, relying solely on exact term matches.

\item {} 
\sphinxAtStartPar
It may struggle with queries or documents that require contextual understanding.

\end{itemize}

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Summary of Common Algorithms:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Metric/Algorithm}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Purpose}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Common Use}
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
\sphinxstylestrong{TF\sphinxhyphen{}IDF}
&
\sphinxAtStartPar
Keyword matching with term weighting.
&
\sphinxAtStartPar
Effective for small\sphinxhyphen{}scale or structured corpora.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{BM25}
&
\sphinxAtStartPar
Advanced keyword matching with term frequency
saturation and document length normalization.
&
\sphinxAtStartPar
Widely used in sparse search; default in tools like
Elasticsearch and Solr.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Cosine Similarity}
&
\sphinxAtStartPar
Measures orientation (ignores magnitude).
&
\sphinxAtStartPar
Widely used; works well with normalized vectors.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Dot Product Similarity}
&
\sphinxAtStartPar
Measures magnitude and direction.
&
\sphinxAtStartPar
Preferred in embeddings like OpenAI’s models.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Euclidean Distance}
&
\sphinxAtStartPar
Measures absolute distance between vectors.
&
\sphinxAtStartPar
Less common but used in some specific cases.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{HNSW (ANN)}
&
\sphinxAtStartPar
Fast and scalable nearest neighbor search.
&
\sphinxAtStartPar
Default for large\sphinxhyphen{}scale systems (e.g., FAISS).
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{IVF (ANN)}
&
\sphinxAtStartPar
Efficient clustering\sphinxhyphen{}based search.
&
\sphinxAtStartPar
Often combined with product quantization.
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\subsubsection{Reciprocal Rank Fusion}
\label{\detokenize{rag:reciprocal-rank-fusion}}
\sphinxAtStartPar
Reciprocal Rank Fusion (RRF) is a ranking technique commonly used in information retrieval
and ensemble learning. Although it is not specific to large language models (LLMs), it can
be applied to scenarios where multiple ranking systems (or scoring mechanisms) produce
different rankings, and you want to combine them into a single, unified ranking.
\begin{description}
\sphinxlineitem{The reciprocal rank of an item in a ranked list is calculated as \(\frac{1}{k+r}\), where}\begin{itemize}
\item {} 
\sphinxAtStartPar
r is the rank of the item (1 for the top rank, 2 for the second rank, etc.).

\item {} 
\sphinxAtStartPar
k is a small constant (often set to 60 or another fixed value) to control how much weight is given to higher ranks.

\end{itemize}

\end{description}

\sphinxAtStartPar
Example:

\sphinxAtStartPar
Suppose two retrieval models give ranked lists for query responses:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Model 1 ranks documents as: {[}A,B,C,D{]}

\item {} 
\sphinxAtStartPar
Model 2 ranks documents as: {[}B,A,D,C{]}

\end{itemize}

\sphinxAtStartPar
RRF combines these rankings by assigning each document a combined score:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Document A: \(\frac{1}{60+1} +\frac{1}{60+2}=0.03252247488101534\)

\item {} 
\sphinxAtStartPar
Document B: \(\frac{1}{60+2} +\frac{1}{60+1}=0.03252247488101534\)

\item {} 
\sphinxAtStartPar
Document C: \(\frac{1}{60+3} +\frac{1}{60+4}=0.03149801587301587\)

\item {} 
\sphinxAtStartPar
Document D: \(\frac{1}{60+4} +\frac{1}{60+3}=0.03149801587301587\)

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{collections} \PYG{k+kn}{import} \PYG{n}{defaultdict}

\PYG{k}{def} \PYG{n+nf}{reciprocal\PYGZus{}rank\PYGZus{}fusion}\PYG{p}{(}\PYG{n}{ranked\PYGZus{}results}\PYG{p}{:} \PYG{n+nb}{list}\PYG{p}{[}\PYG{n+nb}{list}\PYG{p}{]}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{60}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Fuse rank from multiple retrieval systems using Reciprocal Rank Fusion.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{    ranked\PYGZus{}results: Ranked results from different retrieval system.}
\PYG{l+s+sd}{    k (int): A constant used in the RRF formula (default is 60).}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{    Tuple of list of sorted documents by score and sorted documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{c+c1}{\PYGZsh{} Dictionary to store RRF mapping}
    \PYG{n}{rrf\PYGZus{}map} \PYG{o}{=} \PYG{n}{defaultdict}\PYG{p}{(}\PYG{n+nb}{float}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Calculate RRF score for each result in each list}
    \PYG{k}{for} \PYG{n}{rank\PYGZus{}list} \PYG{o+ow}{in} \PYG{n}{ranked\PYGZus{}results}\PYG{p}{:}
        \PYG{k}{for} \PYG{n}{rank}\PYG{p}{,} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{rank\PYGZus{}list}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{:}
            \PYG{n}{rrf\PYGZus{}map}\PYG{p}{[}\PYG{n}{item}\PYG{p}{]} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1} \PYG{o}{/} \PYG{p}{(}\PYG{n}{rank} \PYG{o}{+} \PYG{n}{k}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Sort items based on their RRF scores in descending order}
    \PYG{n}{sorted\PYGZus{}items} \PYG{o}{=} \PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{rrf\PYGZus{}map}\PYG{o}{.}\PYG{n}{items}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{key}\PYG{o}{=}\PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{reverse}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Return tuple of list of sorted documents by score and sorted documents}
    \PYG{k}{return} \PYG{n}{sorted\PYGZus{}items}\PYG{p}{,} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{item}\PYG{p}{,} \PYG{n}{score} \PYG{o+ow}{in} \PYG{n}{sorted\PYGZus{}items}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Example ranked lists from different sources}
\PYG{n}{ranked\PYGZus{}a} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{B}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\PYG{n}{ranked\PYGZus{}b} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{B}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}


\PYG{c+c1}{\PYGZsh{} Combine the lists using RRF}
\PYG{n}{combined\PYGZus{}list} \PYG{o}{=} \PYG{n}{reciprocal\PYGZus{}rank\PYGZus{}fusion}\PYG{p}{(}\PYG{p}{[}\PYG{n}{ranked\PYGZus{}a}\PYG{p}{,} \PYG{n}{ranked\PYGZus{}b}\PYG{p}{]}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{combined\PYGZus{}list}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{(}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.03252247488101534}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{B}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.03252247488101534}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.03149801587301587}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.03149801587301587}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{B}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Generation}
\label{\detokenize{rag:generation}}
\sphinxAtStartPar
Finally, the retrieved relevant information will be feed back into the LLMs to generate responses.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{generator}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
In the remainder of this implementation, we will use the following components:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Vector database: \sphinxcode{\sphinxupquote{Chroma}}

\item {} 
\sphinxAtStartPar
Embedding model: \sphinxcode{\sphinxupquote{BAAI/bge\sphinxhyphen{}m3}}

\item {} 
\sphinxAtStartPar
LLM: \sphinxcode{\sphinxupquote{mistral}}

\item {} 
\sphinxAtStartPar
Web search engine: \sphinxcode{\sphinxupquote{Google}}

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Load models}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} embedding model}
\PYG{n}{embedding} \PYG{o}{=} \PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} LLM}
\PYG{n}{llm} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Indexing}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{text\PYGZus{}splitter} \PYG{k+kn}{import} \PYG{n}{RecursiveCharacterTextSplitter}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{document\PYGZus{}loaders} \PYG{k+kn}{import} \PYG{n}{WebBaseLoader}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{vectorstores} \PYG{k+kn}{import} \PYG{n}{Chroma}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}  \PYG{c+c1}{\PYGZsh{} Import OllamaEmbeddings instead}


\PYG{n}{urls} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://python.langchain.com/v0.1/docs/get\PYGZus{}started/introduction/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{]}

\PYG{n}{docs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{WebBaseLoader}\PYG{p}{(}\PYG{n}{url}\PYG{p}{)}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{url} \PYG{o+ow}{in} \PYG{n}{urls}\PYG{p}{]}
\PYG{n}{docs\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{sublist} \PYG{o+ow}{in} \PYG{n}{docs} \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{sublist}\PYG{p}{]}

\PYG{n}{text\PYGZus{}splitter} \PYG{o}{=} \PYG{n}{RecursiveCharacterTextSplitter}\PYG{o}{.}\PYG{n}{from\PYGZus{}tiktoken\PYGZus{}encoder}\PYG{p}{(}
    \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}overlap}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{doc\PYGZus{}splits} \PYG{o}{=} \PYG{n}{text\PYGZus{}splitter}\PYG{o}{.}\PYG{n}{split\PYGZus{}documents}\PYG{p}{(}\PYG{n}{docs\PYGZus{}list}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add to vectorDB}
\PYG{n}{vectorstore} \PYG{o}{=} \PYG{n}{Chroma}\PYG{o}{.}\PYG{n}{from\PYGZus{}documents}\PYG{p}{(}
    \PYG{n}{documents}\PYG{o}{=}\PYG{n}{doc\PYGZus{}splits}\PYG{p}{,}
    \PYG{n}{collection\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rag\PYGZhy{}chroma}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{embedding}\PYG{o}{=}\PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Retriever}
\PYG{n}{retriever} \PYG{o}{=} \PYG{n}{vectorstore}\PYG{o}{.}\PYG{n}{as\PYGZus{}retriever}\PYG{p}{(}\PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Generation}
\PYG{n}{questions} \PYG{o}{=} \PYG{p}{[}
  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{what is LangChain?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
  \PYG{p}{]}

\PYG{k}{for} \PYG{n}{question} \PYG{o+ow}{in} \PYG{n}{questions}\PYG{p}{:}
    \PYG{n}{retrieved\PYGZus{}context} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
    \PYG{n}{formatted\PYGZus{}prompt} \PYG{o}{=} \PYG{n}{prompt}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{context}\PYG{o}{=}\PYG{n}{retrieved\PYGZus{}context}\PYG{p}{,} \PYG{n}{question}\PYG{o}{=}\PYG{n}{question}\PYG{p}{)}
    \PYG{n}{response\PYGZus{}from\PYGZus{}model} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{formatted\PYGZus{}prompt}\PYG{p}{)}
    \PYG{n}{parsed\PYGZus{}response} \PYG{o}{=} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{parse}\PYG{p}{(}\PYG{n}{response\PYGZus{}from\PYGZus{}model}\PYG{p}{)}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Question: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{question}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Answer: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{parsed\PYGZus{}response}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Answer}\PYG{p}{:} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{answer}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LangChain refers to chains, agents, and retrieval strategies that make up an application}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s cognitive architecture.}\PYG{l+s+s2}{\PYGZdq{}}
  \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\section{Self\sphinxhyphen{}RAG}
\label{\detokenize{rag:self-rag}}\label{\detokenize{rag:ch-self-rag}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{self_rag_paper}.png}
\caption{Overview of SELF\sphinxhyphen{}RAG. (Source \sphinxcite{reference:selfrag})}\label{\detokenize{rag:id41}}\label{\detokenize{rag:fig-self-rag-paper}}\end{figure}

\sphinxAtStartPar
In the paper \sphinxcite{reference:selfrag}, Four types decisions are made:
\begin{quote}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Should I retrieve from retriever, R}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Input}:
\sphinxhyphen{} \sphinxtitleref{x} (question)
\sphinxhyphen{} OR \sphinxtitleref{x} (question), \sphinxtitleref{y} (generation)

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
Decides when to retrieve \sphinxtitleref{D} chunks with \sphinxtitleref{R}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Output}:
\sphinxhyphen{} \sphinxtitleref{yes}
\sphinxhyphen{} \sphinxtitleref{no}
\sphinxhyphen{} \sphinxtitleref{continue}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Are the retrieved passages D relevant to the question x}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Input}:
\sphinxhyphen{} (\sphinxtitleref{x} (question), \sphinxtitleref{d} (chunk)) for \sphinxtitleref{d} in \sphinxtitleref{D}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
Determines if \sphinxtitleref{d} provides useful information to solve \sphinxtitleref{x}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Output}:
\sphinxhyphen{} \sphinxtitleref{relevant}
\sphinxhyphen{} \sphinxtitleref{irrelevant}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Are the LLM generations from each chunk in D relevant to the chunk (hallucinations, etc.)}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Input}:
\sphinxhyphen{} \sphinxtitleref{x} (question), \sphinxtitleref{d} (chunk), \sphinxtitleref{y} (generation) for \sphinxtitleref{d} in \sphinxtitleref{D}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
Verifies if all statements in \sphinxtitleref{y} (generation) are supported by \sphinxtitleref{d}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Output}:
\sphinxhyphen{} \sphinxtitleref{fully supported}
\sphinxhyphen{} \sphinxtitleref{partially supported}
\sphinxhyphen{} \sphinxtitleref{no support}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Is the LLM generation from each chunk in D a useful response to x (question)}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Input}:
\sphinxhyphen{} \sphinxtitleref{x} (question), \sphinxtitleref{y} (generation) for \sphinxtitleref{d} in \sphinxtitleref{D}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Description}:
Assesses if \sphinxtitleref{y} (generation) is a useful response to \sphinxtitleref{x} (question).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Output}:
\sphinxhyphen{} \sphinxtitleref{\{5, 4, 3, 2, 1\}}

\end{itemize}
\end{quote}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{self_rag}.png}
\caption{Self\sphinxhyphen{}RAG langgraph diagram (source \sphinxhref{https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph\_self\_rag\_local/}{Langgraph self\sphinxhyphen{}rag})}\label{\detokenize{rag:id42}}\label{\detokenize{rag:fig-self-rag}}\end{figure}


\subsection{Load Models}
\label{\detokenize{rag:load-models}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}

\PYG{c+c1}{\PYGZsh{} embedding model}
\PYG{n}{embedding} \PYG{o}{=} \PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} LLM}
\PYG{n}{llm} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
You need to specify \sphinxcode{\sphinxupquote{format=\textquotesingle{}json\textquotesingle{}}} when Initializing \sphinxcode{\sphinxupquote{OllamaLLM}}. otherwise
you will get error:
\begin{quote}

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{gemini}.png}
\end{figure}
\end{quote}
\end{sphinxadmonition}


\subsection{Create Index}
\label{\detokenize{rag:create-index}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{text\PYGZus{}splitter} \PYG{k+kn}{import} \PYG{n}{RecursiveCharacterTextSplitter}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{document\PYGZus{}loaders} \PYG{k+kn}{import} \PYG{n}{WebBaseLoader}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{vectorstores} \PYG{k+kn}{import} \PYG{n}{Chroma}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}  \PYG{c+c1}{\PYGZsh{} Import OllamaEmbeddings instead}


\PYG{n}{urls} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}10\PYGZhy{}25\PYGZhy{}adv\PYGZhy{}attack\PYGZhy{}llm/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{]}

\PYG{n}{docs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{WebBaseLoader}\PYG{p}{(}\PYG{n}{url}\PYG{p}{)}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{url} \PYG{o+ow}{in} \PYG{n}{urls}\PYG{p}{]}
\PYG{n}{docs\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{sublist} \PYG{o+ow}{in} \PYG{n}{docs} \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{sublist}\PYG{p}{]}

\PYG{n}{text\PYGZus{}splitter} \PYG{o}{=} \PYG{n}{RecursiveCharacterTextSplitter}\PYG{o}{.}\PYG{n}{from\PYGZus{}tiktoken\PYGZus{}encoder}\PYG{p}{(}
    \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}overlap}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{doc\PYGZus{}splits} \PYG{o}{=} \PYG{n}{text\PYGZus{}splitter}\PYG{o}{.}\PYG{n}{split\PYGZus{}documents}\PYG{p}{(}\PYG{n}{docs\PYGZus{}list}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add to vectorDB}
\PYG{n}{vectorstore} \PYG{o}{=} \PYG{n}{Chroma}\PYG{o}{.}\PYG{n}{from\PYGZus{}documents}\PYG{p}{(}
    \PYG{n}{documents}\PYG{o}{=}\PYG{n}{doc\PYGZus{}splits}\PYG{p}{,}
    \PYG{n}{collection\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rag\PYGZhy{}chroma}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{embedding}\PYG{o}{=}\PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{retriever} \PYG{o}{=} \PYG{n}{vectorstore}\PYG{o}{.}\PYG{n}{as\PYGZus{}retriever}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Retrieval Grader}
\label{\detokenize{rag:retrieval-grader}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Retrieval Grader}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{chat\PYGZus{}models} \PYG{k+kn}{import} \PYG{n}{ChatOllama}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{JsonOutputParser}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{pydantic\PYGZus{}v1} \PYG{k+kn}{import} \PYG{n}{BaseModel}\PYG{p}{,} \PYG{n}{Field}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{PydanticOutputParser}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeDocuments}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeDocuments}\PYG{p}{)}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing relevance of a retrieved}
\PYG{l+s+s2}{    document to a user question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the retrieved document: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}document\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the user question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    If the document contains keywords related to the user question,}
\PYG{l+s+s2}{    grade it as relevant. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    It does not need to be a stringent test. The goal is to filter out}
\PYG{l+s+s2}{    erroneous retrievals. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether the document}
\PYG{l+s+s2}{    is relevant to the question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no}
\PYG{l+s+s2}{    premable or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{retrieval\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{question} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent memory}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{docs} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
\PYG{n}{doc\PYGZus{}txt} \PYG{o}{=} \PYG{n}{docs}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}
\PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{doc\PYGZus{}txt}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeDocuments}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{OllamaLLM}} does not have \sphinxcode{\sphinxupquote{with\_structured\_output(GradeDocuments)}}. You need to use
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{PydanticOutputParser(pydantic\_object=GradeDocuments)}}

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{partial\_variables=\{"format\_instructions": parser.get\_format\_instructions()\}}}

\end{itemize}

\sphinxAtStartPar
to format the structured output.
\end{sphinxadmonition}


\subsection{Generate}
\label{\detokenize{rag:generate}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Generate}

\PYG{k+kn}{from} \PYG{n+nn}{langchain} \PYG{k+kn}{import} \PYG{n}{hub}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{StrOutputParser}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{hub}\PYG{o}{.}\PYG{n}{pull}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rlm/rag\PYGZhy{}prompt}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} LLM}
\PYG{n}{llm} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} Post\PYGZhy{}processing}
\PYG{k}{def} \PYG{n+nf}{format\PYGZus{}docs}\PYG{p}{(}\PYG{n}{docs}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{doc}\PYG{o}{.}\PYG{n}{page\PYGZus{}content} \PYG{k}{for} \PYG{n}{doc} \PYG{o+ow}{in} \PYG{n}{docs}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} Chain}
\PYG{n}{rag\PYGZus{}chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run}
\PYG{n}{generation} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{generation}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Component Two: Memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
      \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Types of Memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
            \PYG{p}{\PYGZob{}}
              \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Sensory Memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).}\PYG{l+s+s2}{\PYGZdq{}}
              \PYG{p}{]}\PYG{p}{,}
              \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Short\PYGZhy{}term Memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Short\PYGZhy{}term memory as learning embedding representations for raw inputs, including text, image or other modalities;}\PYG{l+s+s2}{\PYGZdq{}}
                  \PYG{p}{,}
                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Short\PYGZhy{}term memory as in\PYGZhy{}context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.}\PYG{l+s+s2}{\PYGZdq{}}
              \PYG{p}{]}\PYG{p}{,}
              \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Long\PYGZhy{}term Memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Long\PYGZhy{}term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.}\PYG{l+s+s2}{\PYGZdq{}}
              \PYG{p}{]}
            \PYG{p}{\PYGZcb{}}\PYG{p}{,}
            \PYG{p}{\PYGZob{}}
              \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Maximum Inner Product Search (MIPS)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The external memory can alleviate the restriction of finite attention span. A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner\PYGZhy{}product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)}\PYG{l+s+se}{\PYGZbs{}u200b}\PYG{l+s+s2}{ algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.}\PYG{l+s+s2}{\PYGZdq{}}
                  \PYG{p}{,}
                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{A couple common choices of ANN algorithms for fast MIPS:}\PYG{l+s+s2}{\PYGZdq{}}
              \PYG{p}{]}
            \PYG{p}{\PYGZcb{}}
        \PYG{p}{]}
      \PYG{p}{\PYGZcb{}}
  \PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Hallucination Grader}
\label{\detokenize{rag:hallucination-grader}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Hallucination Grader}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeHallucinations}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeHallucinations}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing whether an answer is grounded in /}
\PYG{l+s+s2}{                supported by a set of facts. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here are the facts:}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                }\PYG{l+s+si}{\PYGZob{}documents\PYGZcb{}}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the answer: }\PYG{l+s+si}{\PYGZob{}generation\PYGZcb{}}
\PYG{l+s+s2}{                Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether}
\PYG{l+s+s2}{                the answer is grounded in / supported by a set of facts. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}
\PYG{l+s+s2}{                and no preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{hallucination\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{hallucination\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeHallucinations}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Answer Grader}
\label{\detokenize{rag:answer-grader}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Answer Grader}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeAnswer}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeAnswer}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing whether an answer is useful to}
\PYG{l+s+s2}{                resolve a question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the answer:}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                }\PYG{l+s+si}{\PYGZob{}generation\PYGZcb{}}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}
\PYG{l+s+s2}{                Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ to indicate whether}
\PYG{l+s+s2}{                the answer is useful to resolve a question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Provide the binary score as a JSON with a single key}
\PYG{l+s+s2}{                }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{answer\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{answer\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeAnswer}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Question Re\sphinxhyphen{}writer}
\label{\detokenize{rag:question-re-writer}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Question Re\PYGZhy{}writer}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{re\PYGZus{}write\PYGZus{}prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You a question re\PYGZhy{}writer that converts an input question}
\PYG{l+s+s2}{                to a better version that is optimized }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ for vectorstore}
\PYG{l+s+s2}{                retrieval. Look at the input and try to reason about the}
\PYG{l+s+s2}{                underlying semantic intent / meaning. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the initial question: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{.}
\PYG{l+s+s2}{                Formulate an improved question.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{question\PYGZus{}rewriter} \PYG{o}{=} \PYG{n}{re\PYGZus{}write\PYGZus{}prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{question\PYGZus{}rewriter}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is the function or purpose of an agent}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s memory in a given context?}\PYG{l+s+s2}{\PYGZdq{}} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Create the Graph}
\label{\detokenize{rag:create-the-graph}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{typing} \PYG{k+kn}{import} \PYG{n}{List}

\PYG{k+kn}{from} \PYG{n+nn}{typing\PYGZus{}extensions} \PYG{k+kn}{import} \PYG{n}{TypedDict}


\PYG{k}{class} \PYG{n+nc}{GraphState}\PYG{p}{(}\PYG{n}{TypedDict}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Represents the state of our graph.}

\PYG{l+s+sd}{    Attributes:}
\PYG{l+s+sd}{        question: question}
\PYG{l+s+sd}{        generation: LLM generation}
\PYG{l+s+sd}{        documents: list of documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{generation}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{documents}\PYG{p}{:} \PYG{n}{List}\PYG{p}{[}\PYG{n+nb}{str}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Nodes}


\PYG{k}{def} \PYG{n+nf}{retrieve}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Retrieve documents}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): New key added to state, documents, that contains retrieved documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}RETRIEVE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Retrieval}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Generate answer}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): New key added to state, generation, that contains LLM generation}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GENERATE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} RAG generation}
    \PYG{n}{generation} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{grade\PYGZus{}documents}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether the retrieved documents are relevant to the question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates documents key with only filtered relevant documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}CHECK DOCUMENT RELEVANCE TO QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Score each doc}
    \PYG{n}{filtered\PYGZus{}docs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n}{documents}\PYG{p}{:}
        \PYG{n}{score} \PYG{o}{=} \PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}
            \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}\PYG{p}{\PYGZcb{}}
        \PYG{p}{)}
        \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{o}{.}\PYG{n}{score}
        \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{or} \PYG{n}{grade}\PYG{o}{==}\PYG{l+m+mi}{1}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE: DOCUMENT RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{n}{filtered\PYGZus{}docs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE: DOCUMENT NOT RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{continue}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{filtered\PYGZus{}docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{transform\PYGZus{}query}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Transform the query to produce a better question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates question key with a re\PYGZhy{}phrased question}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}TRANSFORM QUERY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Re\PYGZhy{}write question}
    \PYG{n}{better\PYGZus{}question} \PYG{o}{=} \PYG{n}{question\PYGZus{}rewriter}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{better\PYGZus{}question}\PYG{p}{\PYGZcb{}}


\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Edges}


\PYG{k}{def} \PYG{n+nf}{decide\PYGZus{}to\PYGZus{}generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether to generate an answer, or re\PYGZhy{}generate a question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: Binary decision for next node to call}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}ASSESS GRADED DOCUMENTS\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{filtered\PYGZus{}documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{filtered\PYGZus{}documents}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} All documents have been filtered check\PYGZus{}relevance}
        \PYG{c+c1}{\PYGZsh{} We will re\PYGZhy{}generate a new query}
        \PYG{n+nb}{print}\PYG{p}{(}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} We have relevant documents, so generate answer}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}


\PYG{k}{def} \PYG{n+nf}{grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether the generation is grounded in the document and answers question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: Decision for next node to call}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}CHECK HALLUCINATIONS\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{generation} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{n}{score} \PYG{o}{=} \PYG{n}{hallucination\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}
        \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}
    \PYG{p}{)}
    \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{o}{.}\PYG{n}{score}

    \PYG{c+c1}{\PYGZsh{} Check hallucination}
    \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION IS GROUNDED IN DOCUMENTS\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{c+c1}{\PYGZsh{} Check question\PYGZhy{}answering}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE GENERATION vs QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n}{score} \PYG{o}{=} \PYG{n}{answer\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
        \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{o}{.}\PYG{n}{score}
        \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION ADDRESSES QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{useful}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION DOES NOT ADDRESS QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not useful}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE\PYGZhy{}TRY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not supported}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Compile Graph}
\label{\detokenize{rag:compile-graph}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph} \PYG{k+kn}{import} \PYG{n}{END}\PYG{p}{,} \PYG{n}{StateGraph}\PYG{p}{,} \PYG{n}{START}

\PYG{n}{workflow} \PYG{o}{=} \PYG{n}{StateGraph}\PYG{p}{(}\PYG{n}{GraphState}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Define the nodes}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{retrieve}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} retrieve}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{grade\PYGZus{}documents}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} grade documents}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{generate}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} generatae}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{transform\PYGZus{}query}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} transform\PYGZus{}query}

\PYG{c+c1}{\PYGZsh{} Build graph}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{n}{START}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{decide\PYGZus{}to\PYGZus{}generate}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{out of context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not supported}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{END}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{useful}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{END}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not useful}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compile}
\PYG{n}{app} \PYG{o}{=} \PYG{n}{workflow}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Graph visualization}
\label{\detokenize{rag:graph-visualization}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}\PYG{p}{,} \PYG{n}{display}

\PYG{k}{try}\PYG{p}{:}
    \PYG{n}{display}\PYG{p}{(}\PYG{n}{Image}\PYG{p}{(}\PYG{n}{app}\PYG{o}{.}\PYG{n}{get\PYGZus{}graph}\PYG{p}{(}\PYG{n}{xray}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{draw\PYGZus{}mermaid\PYGZus{}png}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{except}\PYG{p}{:}
    \PYG{k}{pass}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{self_rag_graph}.png}
\caption{Self\sphinxhyphen{}RAG Graph}\label{\detokenize{rag:id43}}\label{\detokenize{rag:fig-self-rag-graph}}\end{figure}


\subsection{Test}
\label{\detokenize{rag:test}}

\subsubsection{Relevant retrieval}
\label{\detokenize{rag:relevant-retrieval}}\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pprint} \PYG{k+kn}{import} \PYG{n}{pprint}

\PYG{c+c1}{\PYGZsh{} Run}
\PYG{n}{inputs} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is prompt engineering?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\PYG{k}{for} \PYG{n}{output} \PYG{o+ow}{in} \PYG{n}{app}\PYG{o}{.}\PYG{n}{stream}\PYG{p}{(}\PYG{n}{inputs}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{for} \PYG{n}{key}\PYG{p}{,} \PYG{n}{value} \PYG{o+ow}{in} \PYG{n}{output}\PYG{o}{.}\PYG{n}{items}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} Node}
        \PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{key}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{c+c1}{\PYGZsh{} Optional: print full state at each node}
        \PYG{c+c1}{\PYGZsh{} pprint.pprint(value[\PYGZdq{}keys\PYGZdq{}], indent=2, width=80, depth=None)}
    \PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Final generation}
\PYG{n}{pprint}\PYG{p}{(}\PYG{n}{value}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{HALLUCINATIONS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{IS} \PYG{n}{GROUNDED} \PYG{n}{IN} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE} \PYG{n}{GENERATION} \PYG{n}{vs} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{ADDRESSES} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Prompt Engineering}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{ : }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{A method for communicating with language models }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{(LLMs) to steer their behavior towards desired outcomes without updating }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{model weights. It involves alignment and model steerability, and requires }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{heavy experimentation and heuristics.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\end{quote}


\subsubsection{Irrelevant retrieval}
\label{\detokenize{rag:irrelevant-retrieval}}\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pprint} \PYG{k+kn}{import} \PYG{n}{pprint}

\PYG{c+c1}{\PYGZsh{} Run}
\PYG{n}{inputs} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{SegRNN?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\PYG{k}{for} \PYG{n}{output} \PYG{o+ow}{in} \PYG{n}{app}\PYG{o}{.}\PYG{n}{stream}\PYG{p}{(}\PYG{n}{inputs}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{for} \PYG{n}{key}\PYG{p}{,} \PYG{n}{value} \PYG{o+ow}{in} \PYG{n}{output}\PYG{o}{.}\PYG{n}{items}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} Node}
        \PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{key}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{c+c1}{\PYGZsh{} Optional: print full state at each node}
        \PYG{c+c1}{\PYGZsh{} pprint.pprint(value[\PYGZdq{}keys\PYGZdq{}], indent=2, width=80, depth=None)}
    \PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Final generation}
\PYG{n}{pprint}\PYG{p}{(}\PYG{n}{value}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{ALL} \PYG{n}{DOCUMENTS} \PYG{n}{ARE} \PYG{n}{NOT} \PYG{n}{RELEVANT} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{p}{,} \PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{ALL} \PYG{n}{DOCUMENTS} \PYG{n}{ARE} \PYG{n}{NOT} \PYG{n}{RELEVANT} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{p}{,} \PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{ALL} \PYG{n}{DOCUMENTS} \PYG{n}{ARE} \PYG{n}{NOT} \PYG{n}{RELEVANT} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{p}{,} \PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{ALL} \PYG{n}{DOCUMENTS} \PYG{n}{ARE} \PYG{n}{NOT} \PYG{n}{RELEVANT} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{p}{,} \PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{TRANSFORM} \PYG{n}{QUERY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{HALLUCINATIONS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{IS} \PYG{n}{NOT} \PYG{n}{GROUNDED} \PYG{n}{IN} \PYG{n}{DOCUMENTS}\PYG{p}{,} \PYG{n}{RE}\PYG{o}{\PYGZhy{}}\PYG{n}{TRY}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{      }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Question}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Define and provide an explanation for a Sequential }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Recurrent Neural Network (SegRNN)}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{      }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Answer}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{A Sequential Recurrent Neural Network (SegRNN) is a type of }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{artificial neural network used in machine learning. It processes input data }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sequentially, allowing it to maintain internal state over time and use this }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{context when processing new data points. This makes SegRNNs particularly }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{useful for tasks such as speech recognition, language modeling, and time }\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{series analysis.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{   \PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}
\end{quote}


\section{Corrective RAG}
\label{\detokenize{rag:corrective-rag}}\label{\detokenize{rag:ch-c-rag}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{corrective_rag}.png}
\caption{Corrective\sphinxhyphen{}RAG langgraph diagram (source \sphinxhref{https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph\_crag\_local/}{Langgraph c\sphinxhyphen{}rag})}\label{\detokenize{rag:id44}}\label{\detokenize{rag:fig-c-rag}}\end{figure}


\subsection{Load Models}
\label{\detokenize{rag:id4}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}

\PYG{c+c1}{\PYGZsh{} embedding model}
\PYG{n}{embedding} \PYG{o}{=} \PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} LLM}
\PYG{n}{llm} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
You need to specify \sphinxcode{\sphinxupquote{format=\textquotesingle{}json\textquotesingle{}}} when Initializing \sphinxcode{\sphinxupquote{OllamaLLM}}. otherwise
you will get error:
\begin{quote}

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{gemini}.png}
\end{figure}
\end{quote}
\end{sphinxadmonition}


\subsection{Create Index}
\label{\detokenize{rag:id5}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{text\PYGZus{}splitter} \PYG{k+kn}{import} \PYG{n}{RecursiveCharacterTextSplitter}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{document\PYGZus{}loaders} \PYG{k+kn}{import} \PYG{n}{WebBaseLoader}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{vectorstores} \PYG{k+kn}{import} \PYG{n}{Chroma}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}  \PYG{c+c1}{\PYGZsh{} Import OllamaEmbeddings instead}


\PYG{n}{urls} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}10\PYGZhy{}25\PYGZhy{}adv\PYGZhy{}attack\PYGZhy{}llm/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{]}

\PYG{n}{docs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{WebBaseLoader}\PYG{p}{(}\PYG{n}{url}\PYG{p}{)}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{url} \PYG{o+ow}{in} \PYG{n}{urls}\PYG{p}{]}
\PYG{n}{docs\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{sublist} \PYG{o+ow}{in} \PYG{n}{docs} \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{sublist}\PYG{p}{]}

\PYG{n}{text\PYGZus{}splitter} \PYG{o}{=} \PYG{n}{RecursiveCharacterTextSplitter}\PYG{o}{.}\PYG{n}{from\PYGZus{}tiktoken\PYGZus{}encoder}\PYG{p}{(}
    \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}overlap}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{doc\PYGZus{}splits} \PYG{o}{=} \PYG{n}{text\PYGZus{}splitter}\PYG{o}{.}\PYG{n}{split\PYGZus{}documents}\PYG{p}{(}\PYG{n}{docs\PYGZus{}list}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add to vectorDB}
\PYG{n}{vectorstore} \PYG{o}{=} \PYG{n}{Chroma}\PYG{o}{.}\PYG{n}{from\PYGZus{}documents}\PYG{p}{(}
    \PYG{n}{documents}\PYG{o}{=}\PYG{n}{doc\PYGZus{}splits}\PYG{p}{,}
    \PYG{n}{collection\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rag\PYGZhy{}chroma}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{embedding}\PYG{o}{=}\PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{retriever} \PYG{o}{=} \PYG{n}{vectorstore}\PYG{o}{.}\PYG{n}{as\PYGZus{}retriever}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Retrieval Grader}
\label{\detokenize{rag:id6}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Retrieval Grader}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{chat\PYGZus{}models} \PYG{k+kn}{import} \PYG{n}{ChatOllama}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{JsonOutputParser}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{pydantic\PYGZus{}v1} \PYG{k+kn}{import} \PYG{n}{BaseModel}\PYG{p}{,} \PYG{n}{Field}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{PydanticOutputParser}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeDocuments}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeDocuments}\PYG{p}{)}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing relevance of a retrieved}
\PYG{l+s+s2}{    document to a user question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the retrieved document: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}document\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the user question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    If the document contains keywords related to the user question,}
\PYG{l+s+s2}{    grade it as relevant. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    It does not need to be a stringent test. The goal is to filter out}
\PYG{l+s+s2}{    erroneous retrievals. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether the document}
\PYG{l+s+s2}{    is relevant to the question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no}
\PYG{l+s+s2}{    premable or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{retrieval\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{question} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent memory}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{docs} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
\PYG{n}{doc\PYGZus{}txt} \PYG{o}{=} \PYG{n}{docs}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}
\PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{doc\PYGZus{}txt}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeDocuments}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
The output from LangChain Official tutorials (\sphinxhref{https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph\_crag\_local/}{Langgraph c\sphinxhyphen{}rag}) is
\sphinxcode{\sphinxupquote{\{\textquotesingle{}score\textquotesingle{}: 1\}}}. If you use that implementation, you need to add
the \sphinxcode{\sphinxupquote{or grade == 1}} in \sphinxcode{\sphinxupquote{grade\_documents}}. Otherwise, it will always
use web search.
\end{sphinxadmonition}


\subsection{Generate}
\label{\detokenize{rag:id7}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Generate}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{StrOutputParser}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are an assistant for question\PYGZhy{}answering tasks.}

\PYG{l+s+s2}{    Use the following documents to answer the question.}

\PYG{l+s+s2}{    If you don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t know the answer, just say that you don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t know.}

\PYG{l+s+s2}{    Use three sentences maximum and keep the answer concise:}
\PYG{l+s+s2}{    Question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}
\PYG{l+s+s2}{    Documents: }\PYG{l+s+si}{\PYGZob{}documents\PYGZcb{}}
\PYG{l+s+s2}{    Answer:}
\PYG{l+s+s2}{    }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Chain}
\PYG{n}{rag\PYGZus{}chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run}
\PYG{n}{generation} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{generation}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{short\PYGZus{}term\PYGZus{}memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{They discussed the risks, especially with illicit drugs and bioweapons.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{They developed a test set containing a list of known chemical weapon agents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{4 out of 11 requests (36}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{) were accepted to obtain a synthesis solution}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The agent attempted to consult documentation to execute the procedure}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{7 out of 11 were rejected}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{5 happened after a Web search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{2 were rejected based on prompt only}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Generative Agents Simulation\PYGZsh{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{long\PYGZus{}term\PYGZus{}memory}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The memory stream: is a long\PYGZhy{}term memory module (external database) that records a comprehensive list of agents’ experience in natural language}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Router}
\label{\detokenize{rag:router}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Router}

\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{chat\PYGZus{}models} \PYG{k+kn}{import} \PYG{n}{ChatOllama}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{JsonOutputParser}


\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are an expert at routing a}
\PYG{l+s+s2}{    user question to a vectorstore or web search. Use the vectorstore for}
\PYG{l+s+s2}{    questions on LLM agents, prompt engineering, prompting, and adversarial}
\PYG{l+s+s2}{    attacks. You can also use words that are similar to those,}
\PYG{l+s+s2}{    no need to have exactly those words. Otherwise, use web\PYGZhy{}search.}

\PYG{l+s+s2}{    Give a binary choice }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ based on the question.}
\PYG{l+s+s2}{    Return the a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and}
\PYG{l+s+s2}{    no preamble or explanation.}

\PYG{l+s+s2}{    Examples:}
\PYG{l+s+s2}{    Question: When will the Euro of Football take place?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question: What are the types of agent memory?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question: What are the basic approaches for prompt engineering?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question: What is prompt engineering?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question to route:}
\PYG{l+s+s2}{    }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}


\PYG{n}{question\PYGZus{}router} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{JsonOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{When will the Euro of Football }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                          take place?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the types of agent }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                          memory?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Index}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the basic approaches for }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                          prompt engineering?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Index}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{datasource}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{web\PYGZus{}search}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{datasource}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{vectorstore}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{datasource}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{vectorstore}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Hallucination Grader}
\label{\detokenize{rag:id8}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Hallucination Grader}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeHallucinations}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeHallucinations}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing whether an answer is grounded in /}
\PYG{l+s+s2}{                supported by a set of facts. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here are the facts:}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                }\PYG{l+s+si}{\PYGZob{}documents\PYGZcb{}}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the answer: }\PYG{l+s+si}{\PYGZob{}generation\PYGZcb{}}
\PYG{l+s+s2}{                Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether}
\PYG{l+s+s2}{                the answer is grounded in / supported by a set of facts. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}
\PYG{l+s+s2}{                and no preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{hallucination\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{hallucination\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeHallucinations}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Answer Grader}
\label{\detokenize{rag:id9}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Answer Grader}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeAnswer}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeAnswer}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing whether an answer is useful to}
\PYG{l+s+s2}{                resolve a question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the answer:}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                }\PYG{l+s+si}{\PYGZob{}generation\PYGZcb{}}
\PYG{l+s+s2}{                }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}
\PYG{l+s+s2}{                Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ to indicate whether}
\PYG{l+s+s2}{                the answer is useful to resolve a question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Provide the binary score as a JSON with a single key}
\PYG{l+s+s2}{                }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{answer\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{answer\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeAnswer}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Question Re\sphinxhyphen{}writer}
\label{\detokenize{rag:id10}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Question Re\PYGZhy{}writer}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{re\PYGZus{}write\PYGZus{}prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You a question re\PYGZhy{}writer that converts an input question}
\PYG{l+s+s2}{                to a better version that is optimized }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ for vectorstore}
\PYG{l+s+s2}{                retrieval. Look at the input and try to reason about the}
\PYG{l+s+s2}{                underlying semantic intent / meaning. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the initial question: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{.}
\PYG{l+s+s2}{                Formulate an improved question.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{question\PYGZus{}rewriter} \PYG{o}{=} \PYG{n}{re\PYGZus{}write\PYGZus{}prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{question\PYGZus{}rewriter}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is the function or purpose of an agent}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s memory in a given context?}\PYG{l+s+s2}{\PYGZdq{}} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Web Search Tool (Google)}
\label{\detokenize{rag:web-search-tool-google}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}google\PYGZus{}community} \PYG{k+kn}{import} \PYG{n}{GoogleSearchAPIWrapper}\PYG{p}{,} \PYG{n}{GoogleSearchResults}

\PYG{k+kn}{from} \PYG{n+nn}{google}\PYG{n+nn}{.}\PYG{n+nn}{colab} \PYG{k+kn}{import} \PYG{n}{userdata}
\PYG{n}{api\PYGZus{}key} \PYG{o}{=} \PYG{n}{userdata}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GOOGLE\PYGZus{}API\PYGZus{}KEY}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{cx} \PYG{o}{=}  \PYG{n}{userdata}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GOOGLE\PYGZus{}CSE\PYGZus{}ID}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Replace with your actual API key and CX ID}

\PYG{c+c1}{\PYGZsh{} Create an instance of the GoogleSearchAPIWrapper}
\PYG{n}{google\PYGZus{}search\PYGZus{}wrapper} \PYG{o}{=} \PYG{n}{GoogleSearchAPIWrapper}\PYG{p}{(}\PYG{n}{google\PYGZus{}api\PYGZus{}key}\PYG{o}{=}\PYG{n}{api\PYGZus{}key}\PYG{p}{,} \PYG{n}{google\PYGZus{}cse\PYGZus{}id}\PYG{o}{=}\PYG{n}{cx}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Pass the api\PYGZus{}wrapper to GoogleSearchResults}
\PYG{n}{web\PYGZus{}search\PYGZus{}tool} \PYG{o}{=} \PYG{n}{GoogleSearchResults}\PYG{p}{(}\PYG{n}{api\PYGZus{}wrapper}\PYG{o}{=}\PYG{n}{google\PYGZus{}search\PYGZus{}wrapper}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} web\PYGZus{}results = web\PYGZus{}search\PYGZus{}tool.invoke(\PYGZob{}\PYGZdq{}query\PYGZdq{}: question\PYGZcb{})}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
The reults from \sphinxcode{\sphinxupquote{GoogleSearchResults}} are not in \sphinxcode{\sphinxupquote{json}} format.  You will
need to use \sphinxcode{\sphinxupquote{eval(results)}} within the \sphinxcode{\sphinxupquote{web\_search}} function. e.g

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{n}{Document}\PYG{p}{(}\PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{snippet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{url}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{link}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
 \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n+nb}{eval}\PYG{p}{(}\PYG{n}{web\PYGZus{}results}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\subsection{Create the Graph}
\label{\detokenize{rag:id11}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{typing} \PYG{k+kn}{import} \PYG{n}{List}
\PYG{k+kn}{from} \PYG{n+nn}{typing\PYGZus{}extensions} \PYG{k+kn}{import} \PYG{n}{TypedDict}
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}\PYG{p}{,} \PYG{n}{display}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{schema} \PYG{k+kn}{import} \PYG{n}{Document}
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph} \PYG{k+kn}{import} \PYG{n}{START}\PYG{p}{,} \PYG{n}{END}\PYG{p}{,} \PYG{n}{StateGraph}


\PYG{k}{class} \PYG{n+nc}{GraphState}\PYG{p}{(}\PYG{n}{TypedDict}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Represents the state of our graph.}

\PYG{l+s+sd}{    Attributes:}
\PYG{l+s+sd}{        question: question}
\PYG{l+s+sd}{        generation: LLM generation}
\PYG{l+s+sd}{        search: whether to add search}
\PYG{l+s+sd}{        documents: list of documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{generation}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{search}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{documents}\PYG{p}{:} \PYG{n}{List}\PYG{p}{[}\PYG{n+nb}{str}\PYG{p}{]}
    \PYG{n}{steps}\PYG{p}{:} \PYG{n}{List}\PYG{p}{[}\PYG{n+nb}{str}\PYG{p}{]}


\PYG{k}{def} \PYG{n+nf}{retrieve}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Retrieve documents}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): New key added to state, documents, that contains retrieved documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
    \PYG{n}{steps} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{steps}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{steps}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Generate answer}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): New key added to state, generation, that contains LLM generation}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{generation} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{n}{steps} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{steps}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate\PYGZus{}answer}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{steps}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{grade\PYGZus{}documents}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether the retrieved documents are relevant to the question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates documents key with only filtered relevant documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{steps} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{steps}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}document\PYGZus{}retrieval}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{filtered\PYGZus{}docs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{search} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{No}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{documents}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{score} \PYG{o}{=} \PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}
            \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}\PYG{p}{\PYGZcb{}}
        \PYG{p}{)}
        \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

        \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{or} \PYG{n}{grade} \PYG{o}{==} \PYG{l+m+mi}{1}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE: DOCUMENT }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{i}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{n}{filtered\PYGZus{}docs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE: DOCUMENT }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{i}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ ISN}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{T RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{n}{search} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Yes}\PYG{l+s+s2}{\PYGZdq{}}
            \PYG{k}{continue}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{filtered\PYGZus{}docs}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{search}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{steps}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{web\PYGZus{}search}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Web search based on the re\PYGZhy{}phrased question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates documents key with appended web results}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{steps} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{steps}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{web\PYGZus{}results} \PYG{o}{=} \PYG{n}{web\PYGZus{}search\PYGZus{}tool}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{n}{documents}\PYG{o}{.}\PYG{n}{extend}\PYG{p}{(}
        \PYG{p}{[}
            \PYG{n}{Document}\PYG{p}{(}\PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{snippet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{url}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{link}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
            \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n+nb}{eval}\PYG{p}{(}\PYG{n}{web\PYGZus{}results}\PYG{p}{)}
        \PYG{p}{]}
    \PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{steps}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{decide\PYGZus{}to\PYGZus{}generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether to generate an answer, or re\PYGZhy{}generate a question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: Binary decision for next node to call}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{search} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{k}{if} \PYG{n}{search} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{search}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Compile Graph}
\label{\detokenize{rag:id12}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph} \PYG{k+kn}{import} \PYG{n}{START}\PYG{p}{,} \PYG{n}{END}\PYG{p}{,} \PYG{n}{StateGraph}


\PYG{n}{workflow} \PYG{o}{=} \PYG{n}{StateGraph}\PYG{p}{(}\PYG{n}{GraphState}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Define the nodes}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{retrieve}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} retrieve}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{grade\PYGZus{}documents}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} grade documents}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{generate}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} generatae}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{web\PYGZus{}search}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} web search}

\PYG{c+c1}{\PYGZsh{} Build graph}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{n}{START}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{decide\PYGZus{}to\PYGZus{}generate}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{END}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compile}
\PYG{n}{app} \PYG{o}{=} \PYG{n}{workflow}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Graph visualization}
\label{\detokenize{rag:id13}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}\PYG{p}{,} \PYG{n}{display}

\PYG{k}{try}\PYG{p}{:}
    \PYG{n}{display}\PYG{p}{(}\PYG{n}{Image}\PYG{p}{(}\PYG{n}{app}\PYG{o}{.}\PYG{n}{get\PYGZus{}graph}\PYG{p}{(}\PYG{n}{xray}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{draw\PYGZus{}mermaid\PYGZus{}png}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{except}\PYG{p}{:}
    \PYG{k}{pass}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{c_rag_graph}.png}
\caption{Corrective\sphinxhyphen{}RAG Graph}\label{\detokenize{rag:id45}}\label{\detokenize{rag:fig-c-rag-graph}}\end{figure}


\subsection{Test}
\label{\detokenize{rag:id14}}

\subsubsection{Relevant retrieval}
\label{\detokenize{rag:id15}}\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{uuid}

\PYG{n}{config} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{configurable}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{thread\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{uuid}\PYG{o}{.}\PYG{n}{uuid4}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{example} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the basic approaches for }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                    prompt engineering?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}

\PYG{n}{state\PYGZus{}dict} \PYG{o}{=} \PYG{n}{app}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{example}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{config}\PYG{p}{)}
\PYG{n}{state\PYGZus{}dict}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{0} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{1} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{2} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{3} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{question}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{What are the basic approaches for                      prompt engineering?}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{generation}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{       }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Basic Prompting}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{ : }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{A basic approach for prompt engineering is to provide clear and concise instructions to the language model, guiding it towards the desired output.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{search}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{No}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{documents}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Prompt Engineering | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy\PYGZhy{}to\PYGZhy{}use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non\PYGZhy{}trivial to align the whole research community to adopt it.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Basic Prompting\PYGZsh{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Prompt Engineering | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy\PYGZhy{}to\PYGZhy{}use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non\PYGZhy{}trivial to align the whole research community to adopt it.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Basic Prompting\PYGZsh{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Prompt Engineering | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy\PYGZhy{}to\PYGZhy{}use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non\PYGZhy{}trivial to align the whole research community to adopt it.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Basic Prompting\PYGZsh{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Prompt Engineering, also known as In\PYGZhy{}Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Prompt Engineering | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Prompt Engineering | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{|}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Posts}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Archive}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Search}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Tags}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{FAQ}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{emojisearch.app}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{      Prompt Engineering}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Date: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Table of Contents}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Basic Prompting}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Zero\PYGZhy{}Shot}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Few\PYGZhy{}shot}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Tips for Example Selection}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Tips for Example Ordering}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Instruction Prompting}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Self\PYGZhy{}Consistency Sampling}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Chain\PYGZhy{}of\PYGZhy{}Thought (CoT)}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Types of CoT prompts}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Tips and Extensions}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Automatic Prompt Design}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Augmented Language Models}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Retrieval}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Programming Language}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{External APIs}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Citation}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Useful Resources}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{References}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{steps}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{retrieve\PYGZus{}documents}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{grade\PYGZus{}document\PYGZus{}retrieval}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{generate\PYGZus{}answer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\end{quote}


\subsubsection{Irrelevant retrieval}
\label{\detokenize{rag:id16}}\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{example} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is the capital of China?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{config} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{configurable}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{thread\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{uuid}\PYG{o}{.}\PYG{n}{uuid4}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{state\PYGZus{}dict} \PYG{o}{=} \PYG{n}{app}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{example}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{config}\PYG{p}{)}
\PYG{n}{state\PYGZus{}dict}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{0} \PYG{n}{ISN}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{1} \PYG{n}{ISN}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{2} \PYG{n}{ISN}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{l+m+mi}{3} \PYG{n}{ISN}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{question}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{What is the capital of China?}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{generation}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{      }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{answer}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Beijing is the capital of China.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{search}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{documents}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://clintonwhitehouse3.archives.gov/WH/New/China/beijing.html}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The modern day capital of China is Beijing (literally }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Northern Capital}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{), which first served as China}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{s capital city in 1261, when the Mongol ruler Kublai}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s1}{...}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://en.wikipedia.org/wiki/Beijing}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Beijing, previously romanized as Peking, is the capital city of China. With more than 22 million residents, it is the world}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s most populous national capital}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s2}{...}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://pubmed.ncbi.nlm.nih.gov/38294063/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Supercritical and homogenous transmission of monkeypox in the capital of China. J Med Virol. 2024 Feb;96(2):e29442. doi: 10.1002/jmv.29442. Authors. Yunjun}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s1}{...}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://www.sciencedirect.com/science/article/pii/S0304387820301358}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{This paper investigates the impacts of fires on cognitive performance. We find that a one\PYGZhy{}standard\PYGZhy{}deviation increase in the difference between upwind and}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s1}{...}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{steps}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{retrieve\PYGZus{}documents}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{grade\PYGZus{}document\PYGZus{}retrieval}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{web\PYGZus{}search}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{generate\PYGZus{}answer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\end{quote}


\section{Adaptive RAG}
\label{\detokenize{rag:adaptive-rag}}\label{\detokenize{rag:ch-a-rag}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{adaptive_rag}.png}
\caption{Adaptive\sphinxhyphen{}RAG langgraph diagram (source \sphinxhref{https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph\_adaptive\_rag/}{Langgraph A\sphinxhyphen{}rag})}\label{\detokenize{rag:id46}}\label{\detokenize{rag:fig-a-rag}}\end{figure}


\subsection{Load Models}
\label{\detokenize{rag:id17}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}

\PYG{c+c1}{\PYGZsh{} embedding model}
\PYG{n}{embedding} \PYG{o}{=} \PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} LLM}
\PYG{n}{llm} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
You need to specify \sphinxcode{\sphinxupquote{format=\textquotesingle{}json\textquotesingle{}}} when Initializing \sphinxcode{\sphinxupquote{OllamaLLM}}. otherwise
you will get error:
\begin{quote}

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{gemini}.png}
\end{figure}
\end{quote}
\end{sphinxadmonition}


\subsection{Create Index}
\label{\detokenize{rag:id18}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{text\PYGZus{}splitter} \PYG{k+kn}{import} \PYG{n}{RecursiveCharacterTextSplitter}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{document\PYGZus{}loaders} \PYG{k+kn}{import} \PYG{n}{WebBaseLoader}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{vectorstores} \PYG{k+kn}{import} \PYG{n}{Chroma}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}  \PYG{c+c1}{\PYGZsh{} Import OllamaEmbeddings instead}


\PYG{n}{urls} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}10\PYGZhy{}25\PYGZhy{}adv\PYGZhy{}attack\PYGZhy{}llm/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{]}

\PYG{n}{docs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{WebBaseLoader}\PYG{p}{(}\PYG{n}{url}\PYG{p}{)}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{url} \PYG{o+ow}{in} \PYG{n}{urls}\PYG{p}{]}
\PYG{n}{docs\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{sublist} \PYG{o+ow}{in} \PYG{n}{docs} \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{sublist}\PYG{p}{]}

\PYG{n}{text\PYGZus{}splitter} \PYG{o}{=} \PYG{n}{RecursiveCharacterTextSplitter}\PYG{o}{.}\PYG{n}{from\PYGZus{}tiktoken\PYGZus{}encoder}\PYG{p}{(}
    \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}overlap}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{doc\PYGZus{}splits} \PYG{o}{=} \PYG{n}{text\PYGZus{}splitter}\PYG{o}{.}\PYG{n}{split\PYGZus{}documents}\PYG{p}{(}\PYG{n}{docs\PYGZus{}list}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add to vectorDB}
\PYG{n}{vectorstore} \PYG{o}{=} \PYG{n}{Chroma}\PYG{o}{.}\PYG{n}{from\PYGZus{}documents}\PYG{p}{(}
    \PYG{n}{documents}\PYG{o}{=}\PYG{n}{doc\PYGZus{}splits}\PYG{p}{,}
    \PYG{n}{collection\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rag\PYGZhy{}chroma}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{embedding}\PYG{o}{=}\PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{retriever} \PYG{o}{=} \PYG{n}{vectorstore}\PYG{o}{.}\PYG{n}{as\PYGZus{}retriever}\PYG{p}{(}\PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Router}
\label{\detokenize{rag:id19}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Router}

\PYG{k+kn}{from} \PYG{n+nn}{typing} \PYG{k+kn}{import} \PYG{n}{Literal}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{chat\PYGZus{}models} \PYG{k+kn}{import} \PYG{n}{ChatOllama}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{JsonOutputParser}

\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{PydanticOutputParser}
\PYG{k+kn}{from} \PYG{n+nn}{pydantic} \PYG{k+kn}{import} \PYG{n}{BaseModel}\PYG{p}{,} \PYG{n}{Field}


\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{RouteQuery}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Route a user query to the most relevant datasource.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{datasource}\PYG{p}{:} \PYG{n}{Literal}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}
        \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Given a user question choose to route it }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                    to web search or a vectorstore.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} LLM with function call}
\PYG{n}{structured\PYGZus{}llm\PYGZus{}router} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{RouteQuery}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{route\PYGZus{}prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are an expert at routing a user question to a}
\PYG{l+s+s2}{                vectorstore or web search. The vectorstore contains}
\PYG{l+s+s2}{                documents related to agents, prompt engineering,}
\PYG{l+s+s2}{                and adversarial attacks.}
\PYG{l+s+s2}{                Use the vectorstore for questions on these topics.}
\PYG{l+s+s2}{                Otherwise, use web\PYGZhy{}search. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Here is the user question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{                Respond with a JSON object containing only the key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZsq{}}
\PYG{l+s+s2}{                and its value, which should be either }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{.}

\PYG{l+s+s2}{                Example:}
\PYG{l+s+s2}{                }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}
\PYG{l+s+s2}{            }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYGZbs{}
                      \PYG{n}{structured\PYGZus{}llm\PYGZus{}router}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{question\PYGZus{}router} \PYG{o}{=} \PYG{n}{route\PYGZus{}prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{structured\PYGZus{}llm\PYGZus{}router}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYGZbs{}
                        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Who will the Bears draft first in the NFL draft?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYGZbs{}
                              \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the types of agent memory?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{datasource}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{web\PYGZus{}search}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{datasource}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{vectorstore}\PYG{l+s+s1}{\PYGZsq{}}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
We introduced above new implementation with \sphinxcode{\sphinxupquote{pydantic}} Data Model for the
output parser. But, you can still use the similar one we implemented in {\hyperref[\detokenize{rag:ch-c-rag}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Corrective RAG}}}}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} OR}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Router}

\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{chat\PYGZus{}models} \PYG{k+kn}{import} \PYG{n}{ChatOllama}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{JsonOutputParser}


\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are an expert at routing a}
\PYG{l+s+s2}{    user question to a vectorstore or web search. Use the vectorstore for}
\PYG{l+s+s2}{    questions on LLM agents, prompt engineering, prompting, and adversarial}
\PYG{l+s+s2}{    attacks. You can also use words that are similar to those,}
\PYG{l+s+s2}{    no need to have exactly those words. Otherwise, use web\PYGZhy{}search.}

\PYG{l+s+s2}{    Give a binary choice }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ based on the question.}
\PYG{l+s+s2}{    Return the a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and}
\PYG{l+s+s2}{    no preamble or explanation.}

\PYG{l+s+s2}{    Examples:}
\PYG{l+s+s2}{    Question: When will the Euro of Football take place?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question: What are the types of agent memory?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question: What are the basic approaches for prompt engineering?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question: What is prompt engineering?}
\PYG{l+s+s2}{    Answer: }\PYG{l+s+s2}{\PYGZob{}\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{datasource}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZcb{}\PYGZcb{}}

\PYG{l+s+s2}{    Question to route:}
\PYG{l+s+s2}{    }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}


\PYG{n}{question\PYGZus{}router} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{JsonOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{When will the Euro of Football }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                          take place?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the types of agent }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                          memory?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Index}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the basic approaches for }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{                                          prompt engineering?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Index}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\subsection{Retrieval Grader}
\label{\detokenize{rag:id20}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Retrieval Grader}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{chat\PYGZus{}models} \PYG{k+kn}{import} \PYG{n}{ChatOllama}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{JsonOutputParser}

\PYG{c+c1}{\PYGZsh{} Import BaseModel and Field from langchain\PYGZus{}core.pydantic\PYGZus{}v1}
\PYG{c+c1}{\PYGZsh{} from langchain\PYGZus{}core.pydantic\PYGZus{}v1 import BaseModel, Field}
\PYG{k+kn}{from} \PYG{n+nn}{pydantic} \PYG{k+kn}{import} \PYG{n}{BaseModel}\PYG{p}{,} \PYG{n}{Field}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{PydanticOutputParser}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeDocuments}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeDocuments}\PYG{p}{)}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing relevance of a retrieved}
\PYG{l+s+s2}{    document to a user question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the retrieved document: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}document\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the user question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    If the document contains keywords related to the user question,}
\PYG{l+s+s2}{    grade it as relevant. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    It does not need to be a stringent test. The goal is to filter out}
\PYG{l+s+s2}{    erroneous retrievals. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether the document}
\PYG{l+s+s2}{    is relevant to the question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no}
\PYG{l+s+s2}{    preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{retrieval\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{question} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent memory}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{docs} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
\PYG{n}{doc\PYGZus{}txt} \PYG{o}{=} \PYG{n}{docs}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}
\PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{doc\PYGZus{}txt}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Generate}
\label{\detokenize{rag:id21}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Generate}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{StrOutputParser}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are an assistant for question\PYGZhy{}answering tasks.}

\PYG{l+s+s2}{    Use the following documents to answer the question.}

\PYG{l+s+s2}{    If you don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t know the answer, just say that you don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t know.}

\PYG{l+s+s2}{    Use three sentences maximum and keep the answer concise:}
\PYG{l+s+s2}{    Question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}
\PYG{l+s+s2}{    Documents: }\PYG{l+s+si}{\PYGZob{}documents\PYGZcb{}}
\PYG{l+s+s2}{    Answer:}
\PYG{l+s+s2}{    }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Chain}
\PYG{n}{rag\PYGZus{}chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run}
\PYG{n}{generation} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{generation}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{answer}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
        \PYG{p}{\PYGZob{}}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{role}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{assistant}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{content}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{In the context of an LLM (Large Language Model) powered autonomous agent, memory can be divided into three types: Sensory Memory, Short\PYGZhy{}term Memory, and Long\PYGZhy{}term Memory. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Sensory Memory is learning embedding representations for raw inputs, including text, image or other modalities. It}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s the earliest stage of memory, providing the ability to retain impressions of sensory information after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch). }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Short\PYGZhy{}term memory, also known as working memory, is short and finite, as it is restricted by the finite context window length of Transformer. It stores and manipulates the information that the agent currently needs to solve a task. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{Long\PYGZhy{}term memory is the external vector store that the agent can attend to at query time, accessible via fast retrieval. This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval methods such as Maximum Inner Product Search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN) algorithm to return approximately top k nearest neighbors, trading off a little accuracy lost for a huge speedup. A couple common choices of ANN algorithms for fast MIPS are HNSW (Hierarchical Navigable Small World) and Annoy (Approximate Nearest Neighbors Oh Yeah).}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{p}{\PYGZcb{}}
    \PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Hallucination Grader}
\label{\detokenize{rag:id22}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Hallucination Grader}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeHallucinations}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for hallucination present in generation answer.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Answer is grounded in the facts, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeHallucinations}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing whether an answer is grounded}
\PYG{l+s+s2}{    in / supported by a set of facts. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here are the facts:}
\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    }\PYG{l+s+si}{\PYGZob{}documents\PYGZcb{}}
\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the answer: }\PYG{l+s+si}{\PYGZob{}generation\PYGZcb{}}
\PYG{l+s+s2}{    Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether the answer}
\PYG{l+s+s2}{    is grounded in / supported by a set of facts. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no}
\PYG{l+s+s2}{    preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{hallucination\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{hallucination\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Answer Grader}
\label{\detokenize{rag:id23}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Answer Grader}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeAnswer}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score to assess answer addresses question.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Answer addresses the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} parser}
\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeAnswer}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing whether an answer is useful to}
\PYG{l+s+s2}{    resolve a question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the answer:}
\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    }\PYG{l+s+si}{\PYGZob{}generation\PYGZcb{}}
\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}
\PYG{l+s+s2}{    Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ to indicate whether the answer is}
\PYG{l+s+s2}{    useful to resolve a question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no}
\PYG{l+s+s2}{    preamble or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{answer\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{answer\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Question Re\sphinxhyphen{}writer}
\label{\detokenize{rag:id24}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Question Re\PYGZhy{}writer}

\PYG{c+c1}{\PYGZsh{} Prompt}
\PYG{n}{re\PYGZus{}write\PYGZus{}prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You a question re\PYGZhy{}writer that converts an input question to}
\PYG{l+s+s2}{    a better version that is optimized }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    for vectorstore retrieval. Look at the initial and formulate an improved}
\PYG{l+s+s2}{    question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the initial question: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{. Improved question}
\PYG{l+s+s2}{    with no preamble: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{question\PYGZus{}rewriter} \PYG{o}{=} \PYG{n}{re\PYGZus{}write\PYGZus{}prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{question\PYGZus{}rewriter}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Google Web Search}
\label{\detokenize{rag:google-web-search}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Google Web Search}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}google\PYGZus{}community} \PYG{k+kn}{import} \PYG{n}{GoogleSearchAPIWrapper}\PYG{p}{,} \PYG{n}{GoogleSearchResults}

\PYG{k+kn}{from} \PYG{n+nn}{google}\PYG{n+nn}{.}\PYG{n+nn}{colab} \PYG{k+kn}{import} \PYG{n}{userdata}
\PYG{n}{api\PYGZus{}key} \PYG{o}{=} \PYG{n}{userdata}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GOOGLE\PYGZus{}API\PYGZus{}KEY}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{cx} \PYG{o}{=}  \PYG{n}{userdata}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GOOGLE\PYGZus{}CSE\PYGZus{}ID}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Replace with your actual API key and CX ID}

\PYG{c+c1}{\PYGZsh{} Create an instance of the GoogleSearchAPIWrapper}
\PYG{n}{google\PYGZus{}search\PYGZus{}wrapper} \PYG{o}{=} \PYG{n}{GoogleSearchAPIWrapper}\PYG{p}{(}\PYG{n}{google\PYGZus{}api\PYGZus{}key}\PYG{o}{=}\PYG{n}{api\PYGZus{}key}\PYG{p}{,} \PYGZbs{}
                                              \PYG{n}{google\PYGZus{}cse\PYGZus{}id}\PYG{o}{=}\PYG{n}{cx}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Pass the api\PYGZus{}wrapper to GoogleSearchResults}
\PYG{n}{web\PYGZus{}search\PYGZus{}tool} \PYG{o}{=} \PYG{n}{GoogleSearchResults}\PYG{p}{(}\PYG{n}{api\PYGZus{}wrapper}\PYG{o}{=}\PYG{n}{google\PYGZus{}search\PYGZus{}wrapper}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
The reults from \sphinxcode{\sphinxupquote{GoogleSearchResults}} are not in \sphinxcode{\sphinxupquote{json}} format.  You will
need to use \sphinxcode{\sphinxupquote{eval(results)}} within the \sphinxcode{\sphinxupquote{web\_search}} function. e.g

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{n}{Document}\PYG{p}{(}\PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{snippet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{url}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{link}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
 \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n+nb}{eval}\PYG{p}{(}\PYG{n}{web\PYGZus{}results}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\subsection{Create the Graph}
\label{\detokenize{rag:id25}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{typing} \PYG{k+kn}{import} \PYG{n}{List}
\PYG{k+kn}{from} \PYG{n+nn}{typing\PYGZus{}extensions} \PYG{k+kn}{import} \PYG{n}{TypedDict}
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}\PYG{p}{,} \PYG{n}{display}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{schema} \PYG{k+kn}{import} \PYG{n}{Document}
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph} \PYG{k+kn}{import} \PYG{n}{START}\PYG{p}{,} \PYG{n}{END}\PYG{p}{,} \PYG{n}{StateGraph}


\PYG{k}{class} \PYG{n+nc}{GraphState}\PYG{p}{(}\PYG{n}{TypedDict}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Represents the state of our graph.}

\PYG{l+s+sd}{    Attributes:}
\PYG{l+s+sd}{        question: question}
\PYG{l+s+sd}{        generation: LLM generation}
\PYG{l+s+sd}{        documents: list of documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{generation}\PYG{p}{:} \PYG{n+nb}{str}
    \PYG{n}{documents}\PYG{p}{:} \PYG{n}{List}\PYG{p}{[}\PYG{n+nb}{str}\PYG{p}{]}


\PYG{k}{def} \PYG{n+nf}{retrieve}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Retrieve documents}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): New key added to state,}
\PYG{l+s+sd}{                      documents, that contains retrieved documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}RETRIEVE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Retrieval}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}

\PYG{k}{def} \PYG{n+nf}{generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Generate answer}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): New key added to state, generation,}
\PYG{l+s+sd}{        that contains LLM generation}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GENERATE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} RAG generation}
    \PYG{n}{generation} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYGZbs{}
                                  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYGZbs{}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,}\PYGZbs{}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{grade\PYGZus{}documents}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether the retrieved documents are relevant to the question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates documents key with only filtered relevant documents}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}CHECK DOCUMENT RELEVANCE TO QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Score each doc}
    \PYG{n}{filtered\PYGZus{}docs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n}{documents}\PYG{p}{:}
        \PYG{n}{score} \PYG{o}{=} \PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}
            \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{document}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}\PYG{p}{\PYGZcb{}}
        \PYG{p}{)}
        \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{o}{.}\PYG{n}{score}
        \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE: DOCUMENT RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{n}{filtered\PYGZus{}docs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE: DOCUMENT NOT RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{continue}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{filtered\PYGZus{}docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}

\PYG{k}{def} \PYG{n+nf}{transform\PYGZus{}query}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Transform the query to produce a better question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates question key with a re\PYGZhy{}phrased question}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}TRANSFORM QUERY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Re\PYGZhy{}write question}
    \PYG{n}{better\PYGZus{}question} \PYG{o}{=} \PYG{n}{question\PYGZus{}rewriter}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{better\PYGZus{}question}\PYG{p}{\PYGZcb{}}

\PYG{k}{def} \PYG{n+nf}{web\PYGZus{}search}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Web search based on the re\PYGZhy{}phrased question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        state (dict): Updates documents key with appended web results}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)}

    \PYG{n}{web\PYGZus{}results} \PYG{o}{=} \PYG{n}{web\PYGZus{}search\PYGZus{}tool}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{n}{documents}\PYG{o}{.}\PYG{n}{extend}\PYG{p}{(}
        \PYG{p}{[}
            \PYG{n}{Document}\PYG{p}{(}\PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{snippet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{url}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{d}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{link}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
            \PYG{k}{for} \PYG{n}{d} \PYG{o+ow}{in} \PYG{n+nb}{eval}\PYG{p}{(}\PYG{n}{web\PYGZus{}results}\PYG{p}{)}
        \PYG{p}{]}
    \PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYGZbs{}
            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question}\PYG{p}{\PYGZcb{}}


\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Edges \PYGZsh{}\PYGZsh{}\PYGZsh{}}


\PYG{k}{def} \PYG{n+nf}{route\PYGZus{}question}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Route question to web search or RAG.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: Next node to call}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}ROUTE QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{source} \PYG{o}{=} \PYG{n}{question\PYGZus{}router}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{source}\PYG{o}{.}\PYG{n}{datasource} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}ROUTE QUESTION TO WEB SEARCH\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{elif} \PYG{n}{source}\PYG{o}{.}\PYG{n}{datasource} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}ROUTE QUESTION TO RAG\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}


\PYG{k}{def} \PYG{n+nf}{decide\PYGZus{}to\PYGZus{}generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether to generate an answer, or re\PYGZhy{}generate a question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: Binary decision for next node to call}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}ASSESS GRADED DOCUMENTS\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{filtered\PYGZus{}documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{filtered\PYGZus{}documents}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} All documents have been filtered check\PYGZus{}relevance}
        \PYG{c+c1}{\PYGZsh{} We will re\PYGZhy{}generate a new query}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{              TRANSFORM QUERY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} We have relevant documents, so generate answer}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}


\PYG{k}{def} \PYG{n+nf}{grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether the generation is grounded in the document}
\PYG{l+s+sd}{    and answers question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (dict): The current graph state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: Decision for next node to call}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}CHECK HALLUCINATIONS\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{documents} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{generation} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{n}{score} \PYG{o}{=} \PYG{n}{hallucination\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}
        \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{documents}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}
    \PYG{p}{)}
    \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{o}{.}\PYG{n}{score}

    \PYG{c+c1}{\PYGZsh{} Check hallucination}
    \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION IS GROUNDED IN DOCUMENTS\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{c+c1}{\PYGZsh{} Check question\PYGZhy{}answering}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GRADE GENERATION vs QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n}{score} \PYG{o}{=} \PYG{n}{answer\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYGZbs{}
                                      \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{generation}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
        \PYG{n}{grade} \PYG{o}{=} \PYG{n}{score}\PYG{o}{.}\PYG{n}{score}
        \PYG{k}{if} \PYG{n}{grade} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION ADDRESSES QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{useful}\PYG{l+s+s2}{\PYGZdq{}}
        \PYG{k}{else}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION DOES NOT ADDRESS QUESTION\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not useful}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE\PYGZhy{}TRY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not supported}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Compile Graph}
\label{\detokenize{rag:id26}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph} \PYG{k+kn}{import} \PYG{n}{END}\PYG{p}{,} \PYG{n}{StateGraph}\PYG{p}{,} \PYG{n}{START}

\PYG{n}{workflow} \PYG{o}{=} \PYG{n}{StateGraph}\PYG{p}{(}\PYG{n}{GraphState}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Define the nodes}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{web\PYGZus{}search}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} web search}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{retrieve}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} retrieve}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{grade\PYGZus{}documents}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} grade documents}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{generate}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} generatae}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{transform\PYGZus{}query}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} transform\PYGZus{}query}

\PYG{c+c1}{\PYGZsh{} Build graph}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{n}{START}\PYG{p}{,}
    \PYG{n}{route\PYGZus{}question}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{vectorstore}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZus{}search}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{grade\PYGZus{}documents}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{decide\PYGZus{}to\PYGZus{}generate}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not supported}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{useful}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{END}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{not useful}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{transform\PYGZus{}query}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compile}
\PYG{n}{app} \PYG{o}{=} \PYG{n}{workflow}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Graph visualization}
\label{\detokenize{rag:id27}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}\PYG{p}{,} \PYG{n}{display}

\PYG{k}{try}\PYG{p}{:}
    \PYG{n}{display}\PYG{p}{(}\PYG{n}{Image}\PYG{p}{(}\PYG{n}{app}\PYG{o}{.}\PYG{n}{get\PYGZus{}graph}\PYG{p}{(}\PYG{n}{xray}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{draw\PYGZus{}mermaid\PYGZus{}png}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{except}\PYG{p}{:}
    \PYG{k}{pass}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{a_rag_graph}.png}
\caption{Adaptive\sphinxhyphen{}RAG Graph}\label{\detokenize{rag:id47}}\label{\detokenize{rag:fig-a-rag-graph}}\end{figure}


\subsection{Test}
\label{\detokenize{rag:id28}}

\subsubsection{Relevant retrieval}
\label{\detokenize{rag:id29}}\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{uuid}

\PYG{n}{example} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What is the capital of China?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{config} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{configurable}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{thread\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{uuid}\PYG{o}{.}\PYG{n}{uuid4}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{state\PYGZus{}dict} \PYG{o}{=} \PYG{n}{app}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{example}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{config}\PYG{p}{)}
\PYG{n}{state\PYGZus{}dict}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ROUTE} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ROUTE} \PYG{n}{QUESTION} \PYG{n}{TO} \PYG{n}{WEB} \PYG{n}{SEARCH}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{HALLUCINATIONS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{IS} \PYG{n}{GROUNDED} \PYG{n}{IN} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE} \PYG{n}{GENERATION} \PYG{n}{vs} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{ADDRESSES} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{question}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{o}{\PYGZlt{}}\PYG{n}{function} \PYG{n}{\PYGZus{}\PYGZus{}main\PYGZus{}\PYGZus{}}\PYG{o}{.}\PYG{n}{grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{o}{\PYGZgt{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{generation}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{      }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{question}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{\PYGZlt{}function grade\PYGZus{}generation\PYGZus{}v\PYGZus{}documents\PYGZus{}and\PYGZus{}question at 0x7c7eb21f8670\PYGZgt{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{      }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{answer}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The capital city of China is Beijing, as mentioned in three documents. The first document states that Beijing served as China}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{s capital city in 1261, the second document confirms it as the current capital with over 22 million residents, and the third document does not directly mention the capital but is related to a study conducted in China.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{documents}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://clintonwhitehouse3.archives.gov/WH/New/China/beijing.html}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The modern day capital of China is Beijing (literally }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Northern Capital}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{), which first served as China}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{s capital city in 1261, when the Mongol ruler Kublai}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s1}{...}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://en.wikipedia.org/wiki/Beijing}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Beijing, previously romanized as Peking, is the capital city of China. With more than 22 million residents, it is the world}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{s most populous national capital}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s2}{...}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://pubmed.ncbi.nlm.nih.gov/38294063/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Supercritical and homogenous transmission of monkeypox in the capital of China. J Med Virol. 2024 Feb;96(2):e29442. doi: 10.1002/jmv.29442. Authors. Yunjun}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s1}{...}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{url}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://www.sciencedirect.com/science/article/pii/S0304387820301358}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{This paper investigates the impacts of fires on cognitive performance. We find that a one\PYGZhy{}standard\PYGZhy{}deviation increase in the difference between upwind and}\PYG{l+s+se}{\PYGZbs{}xa0}\PYG{l+s+s1}{...}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\end{quote}


\subsubsection{Irrelevant retrieval}
\label{\detokenize{rag:id30}}\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{input} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What are the types of agent memory?}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{n}{example} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n+nb}{input}\PYG{p}{\PYGZcb{}}
\PYG{n}{config} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{configurable}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{thread\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{uuid}\PYG{o}{.}\PYG{n}{uuid4}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{state\PYGZus{}dict} \PYG{o}{=} \PYG{n}{app}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{example}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{steps}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{config}\PYG{p}{)}
\PYG{n}{state\PYGZus{}dict}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ROUTE} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ROUTE} \PYG{n}{QUESTION} \PYG{n}{TO} \PYG{n}{RAG}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{RETRIEVE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANCE} \PYG{n}{TO} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{NOT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE}\PYG{p}{:} \PYG{n}{DOCUMENT} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ASSESS} \PYG{n}{GRADED} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{HALLUCINATIONS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{IS} \PYG{n}{GROUNDED} \PYG{n}{IN} \PYG{n}{DOCUMENTS}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GRADE} \PYG{n}{GENERATION} \PYG{n}{vs} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{GENERATION} \PYG{n}{ADDRESSES} \PYG{n}{QUESTION}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{question}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{What are the types of agent memory?}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{generation}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{       }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Short\PYGZhy{}term memory}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{In\PYGZhy{}context learning, restricted by the finite context window length of Transformer}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{       }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Long\PYGZhy{}term memory}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{External vector store that the agent can attend to at query time, accessible via fast retrieval}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{documents}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Building agents with LLM (large language model) as its core controller is a cool concept. Several proof\PYGZhy{}of\PYGZhy{}concepts demos, such as AutoGPT, GPT\PYGZhy{}Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well\PYGZhy{}written copies, stories, essays and programs; it can be framed as a powerful general problem solver.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Agent System Overview}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{In a LLM\PYGZhy{}powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Planning}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Reflection and refinement: The agent can do self\PYGZhy{}criticism and self\PYGZhy{}reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Memory}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Short\PYGZhy{}term memory: I would consider all the in\PYGZhy{}context learning (See Prompt Engineering) as utilizing short\PYGZhy{}term memory of the model to learn.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Tool use}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre\PYGZhy{}training), including current information, code execution capability, access to proprietary information sources and more.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Fig. 1. Overview of a LLM\PYGZhy{}powered autonomous agent system.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Component One: Planning}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LLM Powered Autonomous Agents | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Fig. 7. Comparison of AD, ED, source policy and RL\PYGZca{}2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{dark}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{ environments and DQN for watermaze.(Image source: Laskin et al. 2023)}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Component Two: Memory\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Types of Memory\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Building agents with LLM (large language model) as its core controller is a cool concept. Several proof\PYGZhy{}of\PYGZhy{}concepts demos, such as AutoGPT, GPT\PYGZhy{}Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well\PYGZhy{}written copies, stories, essays and programs; it can be framed as a powerful general problem solver.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Agent System Overview}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{In a LLM\PYGZhy{}powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Planning}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Reflection and refinement: The agent can do self\PYGZhy{}criticism and self\PYGZhy{}reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Memory}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Short\PYGZhy{}term memory: I would consider all the in\PYGZhy{}context learning (See Prompt Engineering) as utilizing short\PYGZhy{}term memory of the model to learn.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Tool use}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre\PYGZhy{}training), including current information, code execution capability, access to proprietary information sources and more.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Fig. 1. Overview of a LLM\PYGZhy{}powered autonomous agent system.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Component One: Planning}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LLM Powered Autonomous Agents | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Short\PYGZhy{}term memory: I would consider all the in\PYGZhy{}context learning (See Prompt Engineering) as utilizing short\PYGZhy{}term memory of the model to learn.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Tool use}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre\PYGZhy{}training), including current information, code execution capability, access to proprietary information sources and more.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
  \PYG{n}{Document}\PYG{p}{(}\PYG{n}{metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{description}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Building agents with LLM (large language model) as its core controller is a cool concept. Several proof\PYGZhy{}of\PYGZhy{}concepts demos, such as AutoGPT, GPT\PYGZhy{}Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well\PYGZhy{}written copies, stories, essays and programs; it can be framed as a powerful general problem solver.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Agent System Overview}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{In a LLM\PYGZhy{}powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Planning}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Reflection and refinement: The agent can do self\PYGZhy{}criticism and self\PYGZhy{}reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Memory}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Short\PYGZhy{}term memory: I would consider all the in\PYGZhy{}context learning (See Prompt Engineering) as utilizing short\PYGZhy{}term memory of the model to learn.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Tool use}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre\PYGZhy{}training), including current information, code execution capability, access to proprietary information sources and more.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Fig. 1. Overview of a LLM\PYGZhy{}powered autonomous agent system.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Component One: Planning}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{language}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{en}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{source}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{title}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LLM Powered Autonomous Agents | Lil}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{Log}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{page\PYGZus{}content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Short\PYGZhy{}term memory as in\PYGZhy{}context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Maximum Inner Product Search (MIPS)\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner\PYGZhy{}product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)}\PYG{l+s+se}{\PYGZbs{}u200b}\PYG{l+s+s1}{ algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{A couple common choices of ANN algorithms for fast MIPS:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}
\end{quote}


\section{Agentic RAG}
\label{\detokenize{rag:agentic-rag}}\label{\detokenize{rag:ch-agentic-rag}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{agentic_rag}.png}
\caption{Agentic\sphinxhyphen{}RAG langgraph diagram (source \sphinxhref{https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph\_agentic\_rag/}{Langgraph Agentic\sphinxhyphen{}rag})}\label{\detokenize{rag:id48}}\label{\detokenize{rag:fig-agentic-rag}}\end{figure}


\subsection{Load Models}
\label{\detokenize{rag:id31}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}

\PYG{c+c1}{\PYGZsh{} embedding model}
\PYG{n}{embedding} \PYG{o}{=} \PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} LLM}
\PYG{n}{llm} \PYG{o}{=} \PYG{n}{OllamaLLM}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
You need to specify \sphinxcode{\sphinxupquote{format=\textquotesingle{}json\textquotesingle{}}} when Initializing \sphinxcode{\sphinxupquote{OllamaLLM}}. otherwise
you will get error:
\begin{quote}

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{gemini}.png}
\end{figure}
\end{quote}
\end{sphinxadmonition}


\subsection{Create Index}
\label{\detokenize{rag:id32}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{text\PYGZus{}splitter} \PYG{k+kn}{import} \PYG{n}{RecursiveCharacterTextSplitter}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{document\PYGZus{}loaders} \PYG{k+kn}{import} \PYG{n}{WebBaseLoader}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}community}\PYG{n+nn}{.}\PYG{n+nn}{vectorstores} \PYG{k+kn}{import} \PYG{n}{Chroma}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama} \PYG{k+kn}{import} \PYG{n}{OllamaEmbeddings}  \PYG{c+c1}{\PYGZsh{} Import OllamaEmbeddings instead}


\PYG{n}{urls} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}06\PYGZhy{}23\PYGZhy{}agent/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}03\PYGZhy{}15\PYGZhy{}prompt\PYGZhy{}engineering/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://lilianweng.github.io/posts/2023\PYGZhy{}10\PYGZhy{}25\PYGZhy{}adv\PYGZhy{}attack\PYGZhy{}llm/}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{]}

\PYG{n}{docs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{WebBaseLoader}\PYG{p}{(}\PYG{n}{url}\PYG{p}{)}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{url} \PYG{o+ow}{in} \PYG{n}{urls}\PYG{p}{]}
\PYG{n}{docs\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n}{item} \PYG{k}{for} \PYG{n}{sublist} \PYG{o+ow}{in} \PYG{n}{docs} \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{sublist}\PYG{p}{]}

\PYG{n}{text\PYGZus{}splitter} \PYG{o}{=} \PYG{n}{RecursiveCharacterTextSplitter}\PYG{o}{.}\PYG{n}{from\PYGZus{}tiktoken\PYGZus{}encoder}\PYG{p}{(}
    \PYG{n}{chunk\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} \PYG{n}{chunk\PYGZus{}overlap}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{doc\PYGZus{}splits} \PYG{o}{=} \PYG{n}{text\PYGZus{}splitter}\PYG{o}{.}\PYG{n}{split\PYGZus{}documents}\PYG{p}{(}\PYG{n}{docs\PYGZus{}list}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add to vectorDB}
\PYG{n}{vectorstore} \PYG{o}{=} \PYG{n}{Chroma}\PYG{o}{.}\PYG{n}{from\PYGZus{}documents}\PYG{p}{(}
    \PYG{n}{documents}\PYG{o}{=}\PYG{n}{doc\PYGZus{}splits}\PYG{p}{,}
    \PYG{n}{collection\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rag\PYGZhy{}chroma}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{embedding}\PYG{o}{=}\PYG{n}{OllamaEmbeddings}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}m3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{retriever} \PYG{o}{=} \PYG{n}{vectorstore}\PYG{o}{.}\PYG{n}{as\PYGZus{}retriever}\PYG{p}{(}\PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Define Tool}
\label{\detokenize{rag:define-tool}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{tools}\PYG{n+nn}{.}\PYG{n+nn}{retriever} \PYG{k+kn}{import} \PYG{n}{create\PYGZus{}retriever\PYGZus{}tool}

\PYG{n}{retriever\PYGZus{}tool} \PYG{o}{=} \PYG{n}{create\PYGZus{}retriever\PYGZus{}tool}\PYG{p}{(}
    \PYG{n}{retriever}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve\PYGZus{}blog\PYGZus{}posts}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Search and return information about Lilian Weng blog posts on }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{    LLM agents, prompt engineering, and adversarial attacks on LLMs.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{tools} \PYG{o}{=} \PYG{p}{[}\PYG{n}{retriever\PYGZus{}tool}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
If you need web search, you can add web search tool we implement in {\hyperref[\detokenize{rag:ch-c-rag}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Corrective RAG}}}}}
and {\hyperref[\detokenize{rag:ch-a-rag}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Adaptive RAG}}}}}. More details related to Langchian Agent can be found at
\sphinxhref{https://python.langchain.com/v0.1/docs/modules/agents/quick\_start/}{Langchain Agents} and \sphinxhref{https://python.langchain.com/v0.1/docs/integrations/tools/}{Langchain build\sphinxhyphen{}in tools}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} define tools}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}google\PYGZus{}community} \PYG{k+kn}{import} \PYG{n}{GoogleSearchAPIWrapper}\PYG{p}{,} \PYG{n}{GoogleSearchResults}

\PYG{k+kn}{from} \PYG{n+nn}{google}\PYG{n+nn}{.}\PYG{n+nn}{colab} \PYG{k+kn}{import} \PYG{n}{userdata}
\PYG{n}{api\PYGZus{}key} \PYG{o}{=} \PYG{n}{userdata}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GOOGLE\PYGZus{}API\PYGZus{}KEY}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{cx} \PYG{o}{=}  \PYG{n}{userdata}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{GOOGLE\PYGZus{}CSE\PYGZus{}ID}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Replace with your actual API key and CX ID}

\PYG{c+c1}{\PYGZsh{} Create an instance of the GoogleSearchAPIWrapper}
\PYG{n}{google\PYGZus{}search\PYGZus{}wrapper} \PYG{o}{=} \PYG{n}{GoogleSearchAPIWrapper}\PYG{p}{(}\PYG{n}{google\PYGZus{}api\PYGZus{}key}\PYG{o}{=}\PYG{n}{api\PYGZus{}key}\PYG{p}{,} \PYG{n}{google\PYGZus{}cse\PYGZus{}id}\PYG{o}{=}\PYG{n}{cx}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Pass the api\PYGZus{}wrapper to GoogleSearchResults}
\PYG{n}{web\PYGZus{}search\PYGZus{}tool} \PYG{o}{=} \PYG{n}{GoogleSearchResults}\PYG{p}{(}\PYG{n}{api\PYGZus{}wrapper}\PYG{o}{=}\PYG{n}{google\PYGZus{}search\PYGZus{}wrapper}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}

\PYG{n}{tools} \PYG{o}{=} \PYG{p}{[}\PYG{n}{retriever\PYGZus{}tool}\PYG{p}{,} \PYG{n}{web\PYGZus{}search\PYGZus{}tool}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} define prompt and agent}

\PYG{k+kn}{from} \PYG{n+nn}{langchain} \PYG{k+kn}{import} \PYG{n}{hub}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Get the prompt to use \PYGZhy{} you can modify this!}
\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{hub}\PYG{o}{.}\PYG{n}{pull}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{hwchase17/openai\PYGZhy{}functions\PYGZhy{}agent}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{prompt}\PYG{o}{.}\PYG{n}{messages}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} agent}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{agents} \PYG{k+kn}{import} \PYG{n}{create\PYGZus{}tool\PYGZus{}calling\PYGZus{}agent}

\PYG{n}{agent} \PYG{o}{=} \PYG{n}{create\PYGZus{}tool\PYGZus{}calling\PYGZus{}agent}\PYG{p}{(}\PYG{n}{llm}\PYG{p}{,} \PYG{n}{tools}\PYG{p}{,} \PYG{n}{prompt}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Agent executor}

\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{agents} \PYG{k+kn}{import} \PYG{n}{AgentExecutor}

\PYG{n}{agent\PYGZus{}executor} \PYG{o}{=} \PYG{n}{AgentExecutor}\PYG{p}{(}\PYG{n}{agent}\PYG{o}{=}\PYG{n}{agent}\PYG{p}{,} \PYG{n}{tools}\PYG{o}{=}\PYG{n}{tools}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{agent\PYGZus{}executor}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{input}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{whats the weather in sf?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\subsection{Retrieval Grader}
\label{\detokenize{rag:id33}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Retrieval Grader}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}ollama}\PYG{n+nn}{.}\PYG{n+nn}{llms} \PYG{k+kn}{import} \PYG{n}{OllamaLLM}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}

\PYG{c+c1}{\PYGZsh{} Import from pydantic directly instead of langchain\PYGZus{}core.pydantic\PYGZus{}v1}
\PYG{k+kn}{from} \PYG{n+nn}{pydantic} \PYG{k+kn}{import} \PYG{n}{BaseModel}\PYG{p}{,} \PYG{n}{Field}
\PYG{k+kn}{from} \PYG{n+nn}{langchain}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{PydanticOutputParser}

\PYG{c+c1}{\PYGZsh{} Data model}
\PYG{k}{class} \PYG{n+nc}{GradeDocuments}\PYG{p}{(}\PYG{n}{BaseModel}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Binary score for relevance check on retrieved documents.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{score}\PYG{p}{:} \PYG{n+nb}{str} \PYG{o}{=} \PYG{n}{Field}\PYG{p}{(}  \PYG{c+c1}{\PYGZsh{} Changed field name to \PYGZsq{}score\PYGZsq{}}
        \PYG{n}{description}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Documents are relevant to the question, }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{parser} \PYG{o}{=} \PYG{n}{PydanticOutputParser}\PYG{p}{(}\PYG{n}{pydantic\PYGZus{}object}\PYG{o}{=}\PYG{n}{GradeDocuments}\PYG{p}{)}

\PYG{n}{prompt} \PYG{o}{=} \PYG{n}{PromptTemplate}\PYG{p}{(}
    \PYG{n}{template}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{You are a grader assessing relevance of a retrieved}
\PYG{l+s+s2}{    document to a user question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the retrieved document: }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}context\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the user question: }\PYG{l+s+si}{\PYGZob{}question\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    If the document contains keywords related to the user question,}
\PYG{l+s+s2}{    grade it as relevant. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    It does not need to be a stringent test. The goal is to filter out}
\PYG{l+s+s2}{    erroneous retrievals. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Give a binary score }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ or }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{no}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ score to indicate whether the document}
\PYG{l+s+s2}{    is relevant to the question. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Provide the binary score as a JSON with a single key }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{score}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ and no}
\PYG{l+s+s2}{    premable or explanation.}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{input\PYGZus{}variables}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{partial\PYGZus{}variables}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format\PYGZus{}instructions}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{parser}\PYG{o}{.}\PYG{n}{get\PYGZus{}format\PYGZus{}instructions}\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{p}{)}

\PYG{n}{retrieval\PYGZus{}grader} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{parser}
\PYG{n}{question} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent memory}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{docs} \PYG{o}{=} \PYG{n}{retriever}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{question}\PYG{p}{)}
\PYG{n}{doc\PYGZus{}txt} \PYG{o}{=} \PYG{n}{docs}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{page\PYGZus{}content}
\PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{doc\PYGZus{}txt}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GradeDocuments}\PYG{p}{(}\PYG{n}{score}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Agent State}
\label{\detokenize{rag:agent-state}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{typing} \PYG{k+kn}{import} \PYG{n}{Annotated}\PYG{p}{,} \PYG{n}{Sequence}
\PYG{k+kn}{from} \PYG{n+nn}{typing\PYGZus{}extensions} \PYG{k+kn}{import} \PYG{n}{TypedDict}

\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{messages} \PYG{k+kn}{import} \PYG{n}{BaseMessage}

\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph}\PYG{n+nn}{.}\PYG{n+nn}{message} \PYG{k+kn}{import} \PYG{n}{add\PYGZus{}messages}


\PYG{k}{class} \PYG{n+nc}{AgentState}\PYG{p}{(}\PYG{n}{TypedDict}\PYG{p}{)}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} The add\PYGZus{}messages function defines how an update should be processed}
    \PYG{c+c1}{\PYGZsh{} Default is to replace. add\PYGZus{}messages says \PYGZdq{}append\PYGZdq{}}
    \PYG{n}{messages}\PYG{p}{:} \PYG{n}{Annotated}\PYG{p}{[}\PYG{n}{Sequence}\PYG{p}{[}\PYG{n}{BaseMessage}\PYG{p}{]}\PYG{p}{,} \PYG{n}{add\PYGZus{}messages}\PYG{p}{]}
\end{sphinxVerbatim}


\subsection{Create the Graph}
\label{\detokenize{rag:id34}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{typing} \PYG{k+kn}{import} \PYG{n}{Annotated}\PYG{p}{,} \PYG{n}{Literal}\PYG{p}{,} \PYG{n}{Sequence}
\PYG{k+kn}{from} \PYG{n+nn}{typing\PYGZus{}extensions} \PYG{k+kn}{import} \PYG{n}{TypedDict}

\PYG{k+kn}{from} \PYG{n+nn}{langchain} \PYG{k+kn}{import} \PYG{n}{hub}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{messages} \PYG{k+kn}{import} \PYG{n}{BaseMessage}\PYG{p}{,} \PYG{n}{HumanMessage}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{output\PYGZus{}parsers} \PYG{k+kn}{import} \PYG{n}{StrOutputParser}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}core}\PYG{n+nn}{.}\PYG{n+nn}{prompts} \PYG{k+kn}{import} \PYG{n}{PromptTemplate}


\PYG{k+kn}{from} \PYG{n+nn}{pydantic} \PYG{k+kn}{import} \PYG{n}{BaseModel}\PYG{p}{,} \PYG{n}{Field}
\PYG{k+kn}{from} \PYG{n+nn}{langchain\PYGZus{}experimental}\PYG{n+nn}{.}\PYG{n+nn}{llms}\PYG{n+nn}{.}\PYG{n+nn}{ollama\PYGZus{}functions} \PYG{k+kn}{import} \PYG{n}{OllamaFunctions}



\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{prebuilt} \PYG{k+kn}{import} \PYG{n}{tools\PYGZus{}condition}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Edges}


\PYG{k}{def} \PYG{n+nf}{grade\PYGZus{}documents}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}} \PYG{n}{Literal}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rewrite}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Determines whether the retrieved documents are relevant to the question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (messages): The current state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        str: A decision for whether the documents are relevant or not}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}CHECK RELEVANCE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

    \PYG{n}{messages} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{last\PYGZus{}message} \PYG{o}{=} \PYG{n}{messages}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}

    \PYG{n}{question} \PYG{o}{=} \PYG{n}{messages}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{content}
    \PYG{n}{docs} \PYG{o}{=} \PYG{n}{last\PYGZus{}message}\PYG{o}{.}\PYG{n}{content}

    \PYG{n}{scored\PYGZus{}result} \PYG{o}{=} \PYG{n}{retrieval\PYGZus{}grader}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{,} \PYGZbs{}
                                            \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{\PYGZcb{}}\PYG{p}{)}

    \PYG{n}{score} \PYG{o}{=} \PYG{n}{scored\PYGZus{}result}\PYG{o}{.}\PYG{n}{score}

    \PYG{k}{if} \PYG{n}{score} \PYG{o}{==} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{yes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: DOCS RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}

    \PYG{k}{else}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}DECISION: DOCS NOT RELEVANT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{score}\PYG{p}{)}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rewrite}\PYG{l+s+s2}{\PYGZdq{}}


\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Nodes}


\PYG{k}{def} \PYG{n+nf}{agent}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Invokes the agent model to generate a response based on the current state.}
\PYG{l+s+sd}{    Given the question, it will decide to retrieve using the retriever tool,}
\PYG{l+s+sd}{    or simply end.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (messages): The current state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        dict: The updated state with the agent response appended to messages}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}CALL AGENT\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{messages} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

    \PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaFunctions}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mistral}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{model} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{bind\PYGZus{}tools}\PYG{p}{(}\PYG{n}{tools}\PYG{p}{)}
    \PYG{n}{response} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{messages}\PYG{p}{)}
    \PYG{c+c1}{\PYGZsh{} We return a list, because this will get added to the existing list}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{response}\PYG{p}{]}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{rewrite}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Transform the query to produce a better question.}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (messages): The current state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        dict: The updated state with re\PYGZhy{}phrased question}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}TRANSFORM QUERY\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{messages} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{messages}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{content}

    \PYG{n}{msg} \PYG{o}{=} \PYG{p}{[}
        \PYG{n}{HumanMessage}\PYG{p}{(}
            \PYG{n}{content}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Look at the input and try to reason about the underlying semantic intent /}
\PYG{l+s+s2}{    meaning. }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Here is the initial question:}
\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{question}\PYG{l+s+si}{\PYGZcb{}}
\PYG{l+s+s2}{    }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{ \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} }\PYG{l+s+se}{\PYGZbs{}n}
\PYG{l+s+s2}{    Formulate an improved question: }\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}\PYG{p}{,}
        \PYG{p}{)}
    \PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Grader}
    \PYG{n}{response} \PYG{o}{=} \PYG{n}{llm}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{msg}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{response}\PYG{p}{]}\PYG{p}{\PYGZcb{}}


\PYG{k}{def} \PYG{n+nf}{generate}\PYG{p}{(}\PYG{n}{state}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Generate answer}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{        state (messages): The current state}

\PYG{l+s+sd}{    Returns:}
\PYG{l+s+sd}{        dict: The updated state with re\PYGZhy{}phrased question}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}GENERATE\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{messages} \PYG{o}{=} \PYG{n}{state}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{n}{question} \PYG{o}{=} \PYG{n}{messages}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{content}
    \PYG{n}{last\PYGZus{}message} \PYG{o}{=} \PYG{n}{messages}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}

    \PYG{n}{docs} \PYG{o}{=} \PYG{n}{last\PYGZus{}message}\PYG{o}{.}\PYG{n}{content}

    \PYG{c+c1}{\PYGZsh{} Prompt}
    \PYG{n}{prompt} \PYG{o}{=} \PYG{n}{hub}\PYG{o}{.}\PYG{n}{pull}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rlm/rag\PYGZhy{}prompt}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}


    \PYG{c+c1}{\PYGZsh{} Post\PYGZhy{}processing}
    \PYG{k}{def} \PYG{n+nf}{format\PYGZus{}docs}\PYG{p}{(}\PYG{n}{docs}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{doc}\PYG{o}{.}\PYG{n}{page\PYGZus{}content} \PYG{k}{for} \PYG{n}{doc} \PYG{o+ow}{in} \PYG{n}{docs}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Chain}
    \PYG{n}{rag\PYGZus{}chain} \PYG{o}{=} \PYG{n}{prompt} \PYG{o}{|} \PYG{n}{llm} \PYG{o}{|} \PYG{n}{StrOutputParser}\PYG{p}{(}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Run}
    \PYG{n}{response} \PYG{o}{=} \PYG{n}{rag\PYGZus{}chain}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{docs}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{question}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{n}{response}\PYG{p}{]}\PYG{p}{\PYGZcb{}}


\PYG{c+c1}{\PYGZsh{} print(\PYGZdq{}*\PYGZdq{} * 20 + \PYGZdq{}Prompt[rlm/rag\PYGZhy{}prompt]\PYGZdq{} + \PYGZdq{}*\PYGZdq{} * 20)}
\PYG{c+c1}{\PYGZsh{} \PYGZsh{} Show what the prompt looks like}
\PYG{c+c1}{\PYGZsh{} prompt = hub.pull(\PYGZdq{}rlm/rag\PYGZhy{}prompt\PYGZdq{}).pretty\PYGZus{}print()}
\end{sphinxVerbatim}


\subsection{Compile Graph}
\label{\detokenize{rag:id35}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{graph} \PYG{k+kn}{import} \PYG{n}{END}\PYG{p}{,} \PYG{n}{StateGraph}\PYG{p}{,} \PYG{n}{START}
\PYG{k+kn}{from} \PYG{n+nn}{langgraph}\PYG{n+nn}{.}\PYG{n+nn}{prebuilt} \PYG{k+kn}{import} \PYG{n}{ToolNode}

\PYG{c+c1}{\PYGZsh{} Define a new graph}
\PYG{n}{workflow} \PYG{o}{=} \PYG{n}{StateGraph}\PYG{p}{(}\PYG{n}{AgentState}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Define the nodes we will cycle between}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{agent}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} agent}
\PYG{n}{retrieve} \PYG{o}{=} \PYG{n}{ToolNode}\PYG{p}{(}\PYG{p}{[}\PYG{n}{retriever\PYGZus{}tool}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{retrieve}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} retrieval}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rewrite}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{rewrite}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Re\PYGZhy{}writing the question}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{generate}
\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Generating a response after we know the documents are relevant}
\PYG{c+c1}{\PYGZsh{} Call agent node to decide to retrieve or not}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{n}{START}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Decide whether to retrieve}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{} Assess agent decision}
    \PYG{n}{tools\PYGZus{}condition}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}
        \PYG{c+c1}{\PYGZsh{} Translate the condition outputs to nodes in our graph}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{tools}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{n}{END}\PYG{p}{:} \PYG{n}{END}\PYG{p}{,}
    \PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Edges taken after the `action` node is called.}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}conditional\PYGZus{}edges}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{} Assess agent decision}
    \PYG{n}{grade\PYGZus{}documents}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{END}\PYG{p}{)}
\PYG{n}{workflow}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rewrite}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{agent}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compile}
\PYG{n}{graph} \PYG{o}{=} \PYG{n}{workflow}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{OllamaLLM}} object has no attribute \sphinxcode{\sphinxupquote{bind\_tools}}. You need to Install \sphinxcode{\sphinxupquote{langchain\sphinxhyphen{}experimental}}:
OllamaFunctions is initialized with the desired model name:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{OllamaFunctions}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mistral}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{format}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{json}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{bind\PYGZus{}tools}\PYG{p}{(}\PYG{n}{tools}\PYG{p}{)}
\PYG{n}{response} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{messages}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
If you use OpenAI model, the code should be like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{ChatOpenAI}\PYG{p}{(}\PYG{n}{temperature}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{streaming}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{gpt\PYGZhy{}4\PYGZhy{}turbo}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{bind\PYGZus{}tools}\PYG{p}{(}\PYG{n}{tools}\PYG{p}{)}
\PYG{n}{response} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{invoke}\PYG{p}{(}\PYG{n}{messages}\PYG{p}{)}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\subsection{Graph visualization}
\label{\detokenize{rag:id36}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}\PYG{p}{,} \PYG{n}{display}

\PYG{k}{try}\PYG{p}{:}
    \PYG{n}{display}\PYG{p}{(}\PYG{n}{Image}\PYG{p}{(}\PYG{n}{app}\PYG{o}{.}\PYG{n}{get\PYGZus{}graph}\PYG{p}{(}\PYG{n}{xray}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{o}{.}\PYG{n}{draw\PYGZus{}mermaid\PYGZus{}png}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{except}\PYG{p}{:}
    \PYG{k}{pass}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{agentic_rag_graph}.png}
\caption{Agentic\sphinxhyphen{}RAG Graph}\label{\detokenize{rag:id49}}\label{\detokenize{rag:fig-agentic-rag-graph}}\end{figure}


\subsection{Test}
\label{\detokenize{rag:id37}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pprint}

\PYG{n}{inputs} \PYG{o}{=} \PYG{p}{\PYGZob{}}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{messages}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}
        \PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{user}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What does Lilian Weng say about the types of agent memory?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
    \PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\PYG{k}{for} \PYG{n}{output} \PYG{o+ow}{in} \PYG{n}{graph}\PYG{o}{.}\PYG{n}{stream}\PYG{p}{(}\PYG{n}{inputs}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{for} \PYG{n}{key}\PYG{p}{,} \PYG{n}{value} \PYG{o+ow}{in} \PYG{n}{output}\PYG{o}{.}\PYG{n}{items}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{pprint}\PYG{o}{.}\PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Output from node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{key}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n}{pprint}\PYG{o}{.}\PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n}{pprint}\PYG{o}{.}\PYG{n}{pprint}\PYG{p}{(}\PYG{n}{value}\PYG{p}{,} \PYG{n}{indent}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{width}\PYG{o}{=}\PYG{l+m+mi}{80}\PYG{p}{,} \PYG{n}{depth}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
    \PYG{n}{pprint}\PYG{o}{.}\PYG{n}{pprint}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ouput:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CALL} \PYG{n}{AGENT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Output from node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{agent}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{messages}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[} \PYG{n}{AIMessage}\PYG{p}{(}\PYG{n}{content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{additional\PYGZus{}kwargs}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{response\PYGZus{}metadata}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n+nb}{id}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{run\PYGZhy{}ba7e9f54\PYGZhy{}7b32\PYGZhy{}44be\PYGZhy{}a39b\PYGZhy{}b083a6db462d\PYGZhy{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tool\PYGZus{}calls}\PYG{o}{=}\PYG{p}{[}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{name}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{retrieve\PYGZus{}blog\PYGZus{}posts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{args}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{query}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{types of agent memory}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{id}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{call\PYGZus{}4b1ac43a51c545cb942498b35321693a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{tool\PYGZus{}call}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{CHECK} \PYG{n}{RELEVANCE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{DECISION}\PYG{p}{:} \PYG{n}{DOCS} \PYG{n}{RELEVANT}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Output from node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{retrieve}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{messages}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[} \PYG{n}{ToolMessage}\PYG{p}{(}\PYG{n}{content}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Fig. 7. Comparison of AD, ED, source policy and RL\PYGZca{}2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{dark}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{ environments and DQN for watermaze.(Image source: Laskin et al. 2023)}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Component Two: Memory\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Types of Memory\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Short\PYGZhy{}term memory: I would consider all the in\PYGZhy{}context learning (See Prompt Engineering) as utilizing short\PYGZhy{}term memory of the model to learn.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Tool use}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre\PYGZhy{}training), including current information, code execution capability, access to proprietary information sources and more.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Short\PYGZhy{}term memory as in\PYGZhy{}context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Long\PYGZhy{}term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Maximum Inner Product Search (MIPS)\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner\PYGZhy{}product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)}\PYG{l+s+se}{\PYGZbs{}u200b}\PYG{l+s+s1}{ algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{A couple common choices of ANN algorithms for fast MIPS:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36}\PYG{l+s+s1}{\PYGZpc{}}\PYG{l+s+s1}{) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Generative Agents Simulation\PYGZsh{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM\PYGZhy{}powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Memory stream: is a long\PYGZhy{}term memory module (external database) that records a comprehensive list of agents’ experience in natural language.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{retrieve\PYGZus{}blog\PYGZus{}posts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n+nb}{id}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{2ca2d54b\PYGZhy{}214b\PYGZhy{}4463\PYGZhy{}a491\PYGZhy{}20c8d08e79cc}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{tool\PYGZus{}call\PYGZus{}id}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{call\PYGZus{}4b1ac43a51c545cb942498b35321693a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{GENERATE}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{/}\PYG{n}{usr}\PYG{o}{/}\PYG{n}{local}\PYG{o}{/}\PYG{n}{lib}\PYG{o}{/}\PYG{n}{python3}\PYG{l+m+mf}{.10}\PYG{o}{/}\PYG{n}{dist}\PYG{o}{\PYGZhy{}}\PYG{n}{packages}\PYG{o}{/}\PYG{n}{langsmith}\PYG{o}{/}\PYG{n}{client}\PYG{o}{.}\PYG{n}{py}\PYG{p}{:}\PYG{l+m+mi}{261}\PYG{p}{:} \PYG{n}{LangSmithMissingAPIKeyWarning}\PYG{p}{:} \PYG{n}{API} \PYG{n}{key} \PYG{n}{must} \PYG{n}{be} \PYG{n}{provided} \PYG{n}{when} \PYG{n}{using} \PYG{n}{hosted} \PYG{n}{LangSmith} \PYG{n}{API}
  \PYG{n}{warnings}\PYG{o}{.}\PYG{n}{warn}\PYG{p}{(}
\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Output from node }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{generate}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}\PYGZhy{}\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{messages}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{   }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Lilian Weng describes three types of memory: Sensory }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Memory, Short\PYGZhy{}Term Memory, and Long\PYGZhy{}Term Memory. Sensory }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Memory is the earliest stage, lasting for up to a few }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{seconds, and includes iconic (visual), echoic (auditory), and }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{haptic memory. Short\PYGZhy{}Term Memory is used for in\PYGZhy{}context }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{learning and is finite due to the limited context window }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{length of Transformer. Long\PYGZhy{}Term Memory provides agents with }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{the capability to retain and recall information over extended }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{periods by leveraging an external vector store and fast }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{retrieval.\PYGZcb{}}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZob{}}\PYG{l+s+s2}{: .language\PYGZhy{}json \PYGZcb{}. In the given context, it }\PYG{l+s+s2}{\PYGZdq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{does not explicitly mention any specific agent memory types }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{related to reinforcement learning or simulation experiments. }\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{For those topics, you may want to refer to the sections on }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ }\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{Fine Tuning}
\label{\detokenize{finetuning:fine-tuning}}\label{\detokenize{finetuning:finetuning}}\label{\detokenize{finetuning::doc}}
\begin{sphinxadmonition}{note}{Chinese proverb}

\sphinxAtStartPar
Good tools are prerequisite to the successful execution of a job. \textendash{} old Chinese proverb
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Colab Notebook for This Chapter}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Embedding Model Fine\sphinxhyphen{}tuning: \sphinxhref{https://colab.research.google.com/drive/14aYT8Ydm\_e-z47yGpctAfk246K\_PK1LC?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\item {} 
\sphinxAtStartPar
LLM (Llama 2 7B) Model Fine\sphinxhyphen{}tuning: \sphinxhref{https://colab.research.google.com/drive/1GPu2vNRdcObf0dmP7r\_M42NYx0OXVD\_F?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Fine\sphinxhyphen{}tuning is a machine learning technique where a pre\sphinxhyphen{}trained model (like a large
language model or neural network) is further trained on a smaller, specific dataset
to adapt it to a particular task or domain. Instead of training a model from scratch,
fine\sphinxhyphen{}tuning leverages the knowledge already embedded in the pre\sphinxhyphen{}trained model,
saving time, computational resources, and data requirements.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{fine_tuning}.png}
\caption{The three conventional feature\sphinxhyphen{}based and finetuning approaches (Souce \sphinxhref{https://magazine.sebastianraschka.com/p/finetuning-large-language-models}{Finetuning Sebastian}).}\label{\detokenize{finetuning:id4}}\label{\detokenize{finetuning:fig-fine-tuning}}\end{figure}


\section{Cutting\sphinxhyphen{}Edge Strategies for LLM Fine\sphinxhyphen{}Tuning}
\label{\detokenize{finetuning:cutting-edge-strategies-for-llm-fine-tuning}}
\sphinxAtStartPar
Over the past year, fine\sphinxhyphen{}tuning methods have made remarkable strides. Modern methods
for fine\sphinxhyphen{}tuning LLMs focus on efficiency, scalability, and resource optimization.
The following strategies are at the forefront:


\subsection{LoRA (Low\sphinxhyphen{}Rank Adaptation)}
\label{\detokenize{finetuning:lora-low-rank-adaptation}}
\sphinxAtStartPar
\sphinxstylestrong{LoRA} reduces the number of trainable parameters by introducing \sphinxstylestrong{low\sphinxhyphen{}rank decomposition} into the fine\sphinxhyphen{}tuning process.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lora}.png}
\caption{Weight update matrix (Souce \sphinxhref{https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms}{LORA Sebastian}).}\label{\detokenize{finetuning:id5}}\label{\detokenize{finetuning:fig-lora}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Instead of updating all model weights, LoRA injects \sphinxstylestrong{low\sphinxhyphen{}rank adapters} into the model’s layers.

\item {} 
\sphinxAtStartPar
The original pre\sphinxhyphen{}trained weights remain frozen; only the low\sphinxhyphen{}rank parameters are optimized.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Reduces memory and computational requirements.

\item {} 
\sphinxAtStartPar
Enables fine\sphinxhyphen{}tuning on resource\sphinxhyphen{}constrained hardware.

\end{itemize}


\subsection{QLoRA (Quantized Low\sphinxhyphen{}Rank Adaptation)}
\label{\detokenize{finetuning:qlora-quantized-low-rank-adaptation}}
\sphinxAtStartPar
\sphinxstylestrong{QLoRA} combines \sphinxstylestrong{low\sphinxhyphen{}rank adaptation} with \sphinxstylestrong{4\sphinxhyphen{}bit quantization} of the pre\sphinxhyphen{}trained model.

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The LLM is quantized to \sphinxstylestrong{4\sphinxhyphen{}bit precision} to reduce memory usage.

\item {} 
\sphinxAtStartPar
LoRA adapters are applied to the quantized model for fine\sphinxhyphen{}tuning.

\item {} 
\sphinxAtStartPar
Precision is maintained using methods like \sphinxstylestrong{NF4 (Normalized Float 4)} and double backpropagation.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Further reduces memory usage compared to LoRA.

\item {} 
\sphinxAtStartPar
Enables fine\sphinxhyphen{}tuning of massive models on consumer\sphinxhyphen{}grade GPUs.

\end{itemize}


\subsection{PEFT (Parameter\sphinxhyphen{}Efficient Fine\sphinxhyphen{}Tuning)}
\label{\detokenize{finetuning:peft-parameter-efficient-fine-tuning}}
\sphinxAtStartPar
\sphinxstylestrong{PEFT} is a general framework for fine\sphinxhyphen{}tuning LLMs with minimal trainable parameters.


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\sphinxthistablewithborderlessstyle
\centering
\begin{tabulary}{\linewidth}[t]{TT}
\sphinxtoprule
\sphinxtableatstartofbodyhook
\noindent\sphinxincludegraphics[width=1.000\linewidth]{{peft_1}.png}
&
\noindent\sphinxincludegraphics[width=1.000\linewidth]{{peft_2}.png}
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Source: \sphinxcite{reference:peft}

\sphinxAtStartPar
\sphinxstylestrong{Techniques Under PEFT}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{LoRA}: Low\sphinxhyphen{}rank adaptation of weights.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Adapters}: Small trainable layers inserted into the model.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prefix Tuning}: Fine\sphinxhyphen{}tuning input prefixes instead of weights.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prompt Tuning}: Optimizing soft prompts in the input space.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Reduces the number of trainable parameters.

\item {} 
\sphinxAtStartPar
Faster training and lower hardware requirements.

\end{itemize}


\subsection{SFT (Supervised Fine\sphinxhyphen{}Tuning)}
\label{\detokenize{finetuning:sft-supervised-fine-tuning}}
\sphinxAtStartPar
\sphinxstylestrong{SFT} adapts an LLM using a labeled dataset in a fully supervised manner.

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The model is initialized with pre\sphinxhyphen{}trained weights.

\item {} 
\sphinxAtStartPar
It is fine\sphinxhyphen{}tuned on a task\sphinxhyphen{}specific dataset with a supervised loss function (e.g., cross\sphinxhyphen{}entropy).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Achieves high performance on specific tasks.

\item {} 
\sphinxAtStartPar
Essential for aligning models with labeled datasets.

\end{itemize}


\subsection{RLHF (Reinforcement Learning from Human Feedback)}
\label{\detokenize{finetuning:rlhf-reinforcement-learning-from-human-feedback}}
\sphinxAtStartPar
\sphinxstylestrong{RLHF} is a technique used to fine\sphinxhyphen{}tune language models, aligning their
behavior with human preferences or specific tasks. RLHF incorporates feedback
from humans to guide the model’s learning process, ensuring that its outputs
are not only coherent but also align with desired ethical, practical, or
stylistic goals.

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The model is initialized with pre\sphinxhyphen{}trained weights.

\item {} 
\sphinxAtStartPar
The pretrained model is fine\sphinxhyphen{}tuned further using reinforcement learning,
guided by the reward model.

\item {} 
\sphinxAtStartPar
A reinforcement learning algorithm, such as Proximal Policy Optimization
(PPO), optimizes the model to maximize the reward assigned by the reward model.

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}\begin{itemize}
\item {} \begin{description}
\sphinxlineitem{\sphinxstylestrong{Direct Preference Optimization}}
\sphinxAtStartPar
DPO is a technique for aligning large
language models (LLMs) with human preferences, offering an alternative
to the traditional Reinforcement Learning from Human Feedback (RLHF)
approach that uses Proximal Policy Optimization (PPO). Instead of
training a separate reward model and using reinforcement learning,
DPO simplifies the process by directly leveraging human preference
data to fine\sphinxhyphen{}tune the model through supervised learning.

\end{description}

\item {} \begin{description}
\sphinxlineitem{\sphinxstylestrong{Proximal Policy Optimization}}
\sphinxAtStartPar
PPO is a reinforcement learning algorithm
commonly used in RLHF to fine\sphinxhyphen{}tune LLMs. PPO optimizes the model’s policy
by maximizing the reward signal provided by a reward model, which
represents human preferences.

\end{description}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Comparison: DPO vs PPO}
\begin{quote}


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{Feature}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{DPO}
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\sphinxstylestrong{PPO}
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
\sphinxstylestrong{Training Paradigm}
&
\sphinxAtStartPar
Supervised fine\sphinxhyphen{}tuning with preferences
&
\sphinxAtStartPar
Reinforcement learning with a reward
model
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Workflow Complexity}
&
\sphinxAtStartPar
Simpler
&
\sphinxAtStartPar
More complex (requires reward model
and iterative RL)
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Stability}
&
\sphinxAtStartPar
More stable (uses supervised learning)
&
\sphinxAtStartPar
Less stable (inherent to RL methods)
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Efficiency}
&
\sphinxAtStartPar
Computationally efficient
&
\sphinxAtStartPar
Computationally intensive
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Scalability}
&
\sphinxAtStartPar
Scales well with large preference
datasets
&
\sphinxAtStartPar
Requires significant compute for RL
steps
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Use Case}
&
\sphinxAtStartPar
Directly aligns LLM with preferences
&
\sphinxAtStartPar
Optimizes policy for long\sphinxhyphen{}term reward
maximization
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{Human Preference
Modeling}
&
\sphinxAtStartPar
Directly encoded in loss function
&
\sphinxAtStartPar
Encoded via a reward model
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}
\end{quote}

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
RLHF ensures the model’s outputs are ethical, safe, and aligned with human
expectations, reducing harmful or biased content.

\item {} 
\sphinxAtStartPar
Responses become more relevant, helpful, and contextually appropriate,
enhancing user experience.

\item {} 
\sphinxAtStartPar
Fine\sphinxhyphen{}tuning with RLHF allows models to be customized for specific use cases,
such as customer service, creative writing, or technical support.

\end{itemize}


\subsection{Summary Table}
\label{\detokenize{finetuning:summary-table}}

\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
\sphinxstylestrong{Method}
&
\sphinxAtStartPar
\sphinxstylestrong{Description}
&
\sphinxAtStartPar
\sphinxstylestrong{Key Benefit}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{LoRA}
&
\sphinxAtStartPar
Low\sphinxhyphen{}rank adapters for parameter\sphinxhyphen{}efficient
tuning.
&
\sphinxAtStartPar
Reduces trainable parameters significantly.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{QLoRA}
&
\sphinxAtStartPar
LoRA with 4\sphinxhyphen{}bit quantization of the model.
&
\sphinxAtStartPar
Fine\sphinxhyphen{}tunes massive models on smaller
hardware.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{PEFT}
&
\sphinxAtStartPar
General framework for efficient fine\sphinxhyphen{}tuning.
&
\sphinxAtStartPar
Includes LoRA, Adapters, Prefix Tuning,
etc.
\\
\sphinxhline
\sphinxAtStartPar
\sphinxstylestrong{SFT}
&
\sphinxAtStartPar
Supervised fine\sphinxhyphen{}tuning with labeled data.
&
\sphinxAtStartPar
High performance on task\sphinxhyphen{}specific datasets
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
These strategies represent the forefront of \sphinxstylestrong{LLM fine\sphinxhyphen{}tuning}, offering efficient and scalable solutions for
real\sphinxhyphen{}world applications. To choose the most suitable strategy, consider the following factors:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Resource\sphinxhyphen{}Constrained Environments}: Use \sphinxstylestrong{LoRA} or \sphinxstylestrong{QLoRA}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Large\sphinxhyphen{}Scale Models}: \sphinxstylestrong{QLoRA} for low\sphinxhyphen{}memory fine\sphinxhyphen{}tuning.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{High Performance with Labeled Data}: \sphinxstylestrong{SFT}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Minimal Setup}: \sphinxstylestrong{Zero\sphinxhyphen{}shot} or \sphinxstylestrong{Few\sphinxhyphen{}shot} learning.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{General Efficiency}: Use \sphinxstylestrong{PEFT} frameworks.

\end{itemize}


\section{Key Early Fine\sphinxhyphen{}Tuning Methods}
\label{\detokenize{finetuning:key-early-fine-tuning-methods}}
\sphinxAtStartPar
Early fine\sphinxhyphen{}tuning methods laid the foundation for current approaches. These methods
primarily focused on updating the entire model or selected components.


\subsection{Full Fine\sphinxhyphen{}Tuning}
\label{\detokenize{finetuning:full-fine-tuning}}
\sphinxAtStartPar
All the parameters of a pre\sphinxhyphen{}trained model are updated using task\sphinxhyphen{}specific data {\hyperref[\detokenize{finetuning:fig-fine-tuning}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{The three conventional feature\sphinxhyphen{}based and finetuning approaches (Souce Finetuning Sebastian).}}}}} (right).

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The pre\sphinxhyphen{}trained model serves as the starting point.

\item {} 
\sphinxAtStartPar
Fine\sphinxhyphen{}tuning is conducted on a smaller, labeled dataset using a supervised loss function.

\item {} 
\sphinxAtStartPar
A low learning rate is used to prevent \sphinxstylestrong{catastrophic forgetting}.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Effective at adapting models to specific tasks.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Challenges}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Computationally expensive.

\item {} 
\sphinxAtStartPar
Risk of overfitting on small datasets.

\end{itemize}


\subsection{Feature\sphinxhyphen{}Based Approach}
\label{\detokenize{finetuning:feature-based-approach}}
\sphinxAtStartPar
The pre\sphinxhyphen{}trained model is used as a \sphinxstylestrong{feature extractor}, while only a task\sphinxhyphen{}specific head is trained {\hyperref[\detokenize{finetuning:fig-fine-tuning}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{The three conventional feature\sphinxhyphen{}based and finetuning approaches (Souce Finetuning Sebastian).}}}}} (left).

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The model processes inputs and extracts features (embeddings).

\item {} 
\sphinxAtStartPar
A separate classifier (e.g., linear or MLP) is trained on top of these features.

\item {} 
\sphinxAtStartPar
The pre\sphinxhyphen{}trained model weights remain \sphinxstylestrong{frozen}.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Computationally efficient since only the task\sphinxhyphen{}specific head is trained.

\end{itemize}


\subsection{Layer\sphinxhyphen{}Specific Fine\sphinxhyphen{}Tuning}
\label{\detokenize{finetuning:layer-specific-fine-tuning}}
\sphinxAtStartPar
Only certain layers of the pre\sphinxhyphen{}trained model are fine\sphinxhyphen{}tuned while the rest remain frozen {\hyperref[\detokenize{finetuning:fig-fine-tuning}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{The three conventional feature\sphinxhyphen{}based and finetuning approaches (Souce Finetuning Sebastian).}}}}} (middle).

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Earlier layers (which capture general features) are frozen.

\item {} 
\sphinxAtStartPar
Later layers (closer to the output) are fine\sphinxhyphen{}tuned on task\sphinxhyphen{}specific data.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Balances computational efficiency and task adaptation.

\end{itemize}


\subsection{Task\sphinxhyphen{}Adaptive Pre\sphinxhyphen{}training}
\label{\detokenize{finetuning:task-adaptive-pre-training}}
\sphinxAtStartPar
Before fine\sphinxhyphen{}tuning on a specific task, the model undergoes additional \sphinxstylestrong{pre\sphinxhyphen{}training} on a domain\sphinxhyphen{}specific corpus.

\sphinxAtStartPar
\sphinxstylestrong{How It Works}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
A general pre\sphinxhyphen{}trained model is further pre\sphinxhyphen{}trained (unsupervised) on domain\sphinxhyphen{}specific data.

\item {} 
\sphinxAtStartPar
Fine\sphinxhyphen{}tuning is then performed on the downstream task.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Benefits}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Provides a better starting point for domain\sphinxhyphen{}specific tasks.

\end{itemize}


\section{Embedding Model Fine\sphinxhyphen{}Tuning}
\label{\detokenize{finetuning:embedding-model-fine-tuning}}
\sphinxAtStartPar
In the chapter {\hyperref[\detokenize{rag:rag}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Retrieval\sphinxhyphen{}Augmented Generation}}}}}, we discussed how embedding models are crucial for the success of RAG applications.
However, their general\sphinxhyphen{}purpose training often limits their effectiveness for company\sphinxhyphen{} or domain\sphinxhyphen{}specific
use cases. Customizing embeddings with domain\sphinxhyphen{}specific data can significantly improve the retrieval
performance of your RAG application.

\sphinxAtStartPar
In this chapter, we will demonstrate how to fine\sphinxhyphen{}tune embedding models using the
\sphinxcode{\sphinxupquote{SentenceTransformersTrainer}}, building on insights shared in the blog \sphinxcite{reference:finetuneembedding} and
Sentence Transformer \sphinxhref{https://sbert.net/docs/sentence\_transformer/training\_overview.html\#dataset-format}{Training Overview}. Our main contribution was introducing LoRA to enable functionality on
NVIDIA T4 GPUs, while the rest of the pipeline and code remained almost unchanged.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Please ensure that the package versions are set as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pip} \PYG{n}{install}  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{torch==2.1.2}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n}{tensorboard}

\PYG{n}{pip} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{upgrade} \PYGZbs{}
    \PYG{n}{sentence}\PYG{o}{\PYGZhy{}}\PYG{n}{transformers}\PYG{o}{\PYGZgt{}}\PYG{o}{=}\PYG{l+m+mi}{3} \PYGZbs{}
    \PYG{n}{datasets}\PYG{o}{==}\PYG{l+m+mf}{2.19}\PYG{l+m+mf}{.1}  \PYGZbs{}
    \PYG{n}{transformers}\PYG{o}{==}\PYG{l+m+mf}{4.41}\PYG{l+m+mf}{.2} \PYGZbs{}
    \PYG{n}{peft}\PYG{o}{==}\PYG{l+m+mf}{0.10}\PYG{l+m+mf}{.0}
\end{sphinxVerbatim}

\sphinxAtStartPar
Otherwise, you may encounter the error.
\end{sphinxadmonition}


\subsection{Prepare Dataset}
\label{\detokenize{finetuning:prepare-dataset}}
\sphinxAtStartPar
We are going to directly use the synthetic dataset \sphinxcode{\sphinxupquote{philschmid/finanical\sphinxhyphen{}rag\sphinxhyphen{}embedding\sphinxhyphen{}dataset}}, which includes 7,000
positive text pairs of questions and corresponding context from the \sphinxhref{https://stocklight.com/stocks/us/nasdaq-nvda/nvidia/annual-reports/nasdaq-nvda-2023-10K-23668751.pdf}{2023\_10 NVIDIA SEC Filing}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{load\PYGZus{}dataset}

\PYG{c+c1}{\PYGZsh{} Load dataset from the hub}
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{load\PYGZus{}dataset}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{philschmid/finanical\PYGZhy{}rag\PYGZhy{}embedding\PYGZhy{}dataset}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{split}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} rename columns}
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{dataset}\PYG{o}{.}\PYG{n}{rename\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{question}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{anchor}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{dataset}\PYG{o}{.}\PYG{n}{rename\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{context}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{positive}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add an id column to the dataset}
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{dataset}\PYG{o}{.}\PYG{n}{add\PYGZus{}column}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{dataset}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} split dataset into a 10\PYGZpc{} test set}
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{dataset}\PYG{o}{.}\PYG{n}{train\PYGZus{}test\PYGZus{}split}\PYG{p}{(}\PYG{n}{test\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} save datasets to disk}
\PYG{n}{dataset}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}json}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train\PYGZus{}dataset.json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{orient}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{records}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{dataset}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}json}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{test\PYGZus{}dataset.json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{orient}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{records}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
In practice, most dataset configurations will take one of four forms:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Positive Pair}: A pair of related sentences. This can be used both for symmetric tasks
(semantic textual similarity) or asymmetric tasks (semantic search), with examples
including pairs of paraphrases, pairs of full texts and their summaries, pairs of
duplicate questions, pairs of \sphinxcode{\sphinxupquote{(query, response)}}, or pairs of
\sphinxcode{\sphinxupquote{(source\_language, target\_language)}}.
Natural Language Inference datasets can also be formatted this way by pairing entailing sentences.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Triplets}: \sphinxcode{\sphinxupquote{(anchor, positive, negative)}} text triplets. These datasets don’t need labels.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Pair with Similarity Score}: A pair of sentences with a score indicating their similarity.
Common examples are “Semantic Textual Similarity” datasets.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Texts with Classes}: A text with its corresponding class. This data format is easily
converted by loss functions into three sentences (triplets) where the first is an “anchor”,
the second a “positive” of the same class as the anchor, and the third a “negative” of a different class.

\end{itemize}

\sphinxAtStartPar
Note that it is often simple to transform a dataset from one format to another, such that it works with
your loss function of choice.
\end{sphinxadmonition}


\subsection{Import and Evaluate Pretrained Baseline Model}
\label{\detokenize{finetuning:import-and-evaluate-pretrained-baseline-model}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{torch}
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers} \PYG{k+kn}{import} \PYG{n}{SentenceTransformer}
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers}\PYG{n+nn}{.}\PYG{n+nn}{evaluation} \PYG{k+kn}{import} \PYG{p}{(}
    \PYG{n}{InformationRetrievalEvaluator}\PYG{p}{,}
    \PYG{n}{SequentialEvaluator}\PYG{p}{,}
\PYG{p}{)}
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers}\PYG{n+nn}{.}\PYG{n+nn}{util} \PYG{k+kn}{import} \PYG{n}{cos\PYGZus{}sim}
\PYG{k+kn}{from} \PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{load\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{concatenate\PYGZus{}datasets}
\PYG{k+kn}{from} \PYG{n+nn}{peft} \PYG{k+kn}{import} \PYG{n}{LoraConfig}\PYG{p}{,} \PYG{n}{TaskType}

\PYG{n}{model\PYGZus{}id} \PYG{o}{=}  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{BAAI/bge\PYGZhy{}base\PYGZhy{}en\PYGZhy{}v1.5}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{matryoshka\PYGZus{}dimensions} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{512}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{128}\PYG{p}{,} \PYG{l+m+mi}{64}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} Important: large to small}

\PYG{c+c1}{\PYGZsh{} Load a model}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{SentenceTransformer}\PYG{p}{(}
    \PYG{n}{model\PYGZus{}id}\PYG{p}{,}
    \PYG{n}{trust\PYGZus{}remote\PYGZus{}code}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{device}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cuda}\PYG{l+s+s2}{\PYGZdq{}} \PYG{k}{if} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{cuda}\PYG{o}{.}\PYG{n}{is\PYGZus{}available}\PYG{p}{(}\PYG{p}{)} \PYG{k}{else} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cpu}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} load test dataset}
\PYG{n}{test\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{load\PYGZus{}dataset}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{data\PYGZus{}files}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{test\PYGZus{}dataset.json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{split}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{train\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{load\PYGZus{}dataset}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{data\PYGZus{}files}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train\PYGZus{}dataset.json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{split}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{corpus\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{concatenate\PYGZus{}datasets}\PYG{p}{(}\PYG{p}{[}\PYG{n}{train\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{test\PYGZus{}dataset}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Convert the datasets to dictionaries}
\PYG{n}{corpus} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}
    \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{corpus\PYGZus{}dataset}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{corpus\PYGZus{}dataset}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{positive}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Our corpus (cid =\PYGZgt{} document)}
\PYG{n}{queries} \PYG{o}{=} \PYG{n+nb}{dict}\PYG{p}{(}
    \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{test\PYGZus{}dataset}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{test\PYGZus{}dataset}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{anchor}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Our queries (qid =\PYGZgt{} question)}

\PYG{c+c1}{\PYGZsh{} Create a mapping of relevant document (1 in our case) for each query}
\PYG{n}{relevant\PYGZus{}docs} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}  \PYG{c+c1}{\PYGZsh{} Query ID to relevant documents (qid =\PYGZgt{} set([relevant\PYGZus{}cids])}
\PYG{k}{for} \PYG{n}{q\PYGZus{}id} \PYG{o+ow}{in} \PYG{n}{queries}\PYG{p}{:}
    \PYG{n}{relevant\PYGZus{}docs}\PYG{p}{[}\PYG{n}{q\PYGZus{}id}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{n}{q\PYGZus{}id}\PYG{p}{]}


\PYG{n}{matryoshka\PYGZus{}evaluators} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} Iterate over the different dimensions}
\PYG{k}{for} \PYG{n}{dim} \PYG{o+ow}{in} \PYG{n}{matryoshka\PYGZus{}dimensions}\PYG{p}{:}
    \PYG{n}{ir\PYGZus{}evaluator} \PYG{o}{=} \PYG{n}{InformationRetrievalEvaluator}\PYG{p}{(}
        \PYG{n}{queries}\PYG{o}{=}\PYG{n}{queries}\PYG{p}{,}
        \PYG{n}{corpus}\PYG{o}{=}\PYG{n}{corpus}\PYG{p}{,}
        \PYG{n}{relevant\PYGZus{}docs}\PYG{o}{=}\PYG{n}{relevant\PYGZus{}docs}\PYG{p}{,}
        \PYG{n}{name}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dim\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dim}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{n}{truncate\PYGZus{}dim}\PYG{o}{=}\PYG{n}{dim}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} Truncate the embeddings to a certain dimension}
        \PYG{n}{score\PYGZus{}functions}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cosine}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{n}{cos\PYGZus{}sim}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{p}{)}
    \PYG{n}{matryoshka\PYGZus{}evaluators}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{ir\PYGZus{}evaluator}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Create a sequential evaluator}
\PYG{n}{evaluator} \PYG{o}{=} \PYG{n}{SequentialEvaluator}\PYG{p}{(}\PYG{n}{matryoshka\PYGZus{}evaluators}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
If you encounter the error \sphinxcode{\sphinxupquote{Cannot import name \textquotesingle{}EncoderDecoderCache\textquotesingle{} from \textquotesingle{}transformers\textquotesingle{}}},
ensure that the package versions are set to \sphinxcode{\sphinxupquote{peft==0.10.0}} and \sphinxcode{\sphinxupquote{transformers==4.37.2}}.
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Evaluate the model}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{evaluator}\PYG{p}{(}\PYG{n}{model}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Print the main score}
\PYG{k}{for} \PYG{n}{dim} \PYG{o+ow}{in} \PYG{n}{matryoshka\PYGZus{}dimensions}\PYG{p}{:}
    \PYG{n}{key} \PYG{o}{=} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dim\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dim}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}cosine\PYGZus{}ndcg@10}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n+nb}{print}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{key}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{results}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dim\PYGZus{}768\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.754897248109794}
\PYG{n}{dim\PYGZus{}512\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.7549275773474213}
\PYG{n}{dim\PYGZus{}256\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.7454714780163237}
\PYG{n}{dim\PYGZus{}128\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.7116728650043451}
\PYG{n}{dim\PYGZus{}64\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.6477174937632066}
\end{sphinxVerbatim}


\subsection{Loss Function with Matryoshka Representation}
\label{\detokenize{finetuning:loss-function-with-matryoshka-representation}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers} \PYG{k+kn}{import} \PYG{n}{SentenceTransformerModelCardData}\PYG{p}{,} \PYG{n}{SentenceTransformer}

\PYG{c+c1}{\PYGZsh{} Hugging Face model ID: https://huggingface.co/BAAI/bge\PYGZhy{}base\PYGZhy{}en\PYGZhy{}v1.5}
\PYG{n}{model\PYGZus{}id} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{BAAI/bge\PYGZhy{}base\PYGZhy{}en\PYGZhy{}v1.5}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} load model with SDPA for using Flash Attention 2}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{SentenceTransformer}\PYG{p}{(}
    \PYG{n}{model\PYGZus{}id}\PYG{p}{,}
    \PYG{n}{model\PYGZus{}kwargs}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{attn\PYGZus{}implementation}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sdpa}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{n}{model\PYGZus{}card\PYGZus{}data}\PYG{o}{=}\PYG{n}{SentenceTransformerModelCardData}\PYG{p}{(}
        \PYG{n}{language}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{en}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{n}{license}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{apache\PYGZhy{}2.0}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{n}{model\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{BGE base Financial Matryoshka}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{p}{)}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Apply PEFT with PromptTuningConfig}
\PYG{n}{peft\PYGZus{}config} \PYG{o}{=} \PYG{n}{LoraConfig}\PYG{p}{(}
    \PYG{n}{task\PYGZus{}type}\PYG{o}{=}\PYG{n}{TaskType}\PYG{o}{.}\PYG{n}{FEATURE\PYGZus{}EXTRACTION}\PYG{p}{,}
    \PYG{n}{inference\PYGZus{}mode}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{r}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{,}
    \PYG{n}{lora\PYGZus{}alpha}\PYG{o}{=}\PYG{l+m+mi}{32}\PYG{p}{,}
    \PYG{n}{lora\PYGZus{}dropout}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add\PYGZus{}adapter}\PYG{p}{(}\PYG{n}{peft\PYGZus{}config}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dense}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} train loss}
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers}\PYG{n+nn}{.}\PYG{n+nn}{losses} \PYG{k+kn}{import} \PYG{n}{MatryoshkaLoss}\PYG{p}{,} \PYG{n}{MultipleNegativesRankingLoss}

\PYG{n}{matryoshka\PYGZus{}dimensions} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{768}\PYG{p}{,} \PYG{l+m+mi}{512}\PYG{p}{,} \PYG{l+m+mi}{256}\PYG{p}{,} \PYG{l+m+mi}{128}\PYG{p}{,} \PYG{l+m+mi}{64}\PYG{p}{]}  \PYG{c+c1}{\PYGZsh{} Important: large to small}
\PYG{n}{inner\PYGZus{}train\PYGZus{}loss} \PYG{o}{=} \PYG{n}{MultipleNegativesRankingLoss}\PYG{p}{(}\PYG{n}{model}\PYG{p}{)}
\PYG{n}{train\PYGZus{}loss} \PYG{o}{=} \PYG{n}{MatryoshkaLoss}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,}
                            \PYG{n}{inner\PYGZus{}train\PYGZus{}loss}\PYG{p}{,}
                            \PYG{n}{matryoshka\PYGZus{}dims}\PYG{o}{=}\PYG{n}{matryoshka\PYGZus{}dimensions}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Loss functions play a critical role in the performance of your fine\sphinxhyphen{}tuned model.
Sadly, there is no “one size fits all” loss function. Ideally,
this table should help narrow down your choice of loss function(s) by matching
them to your data formats.

\sphinxAtStartPar
You can often convert one training data format into another, allowing more loss
functions to be viable for your scenario. For example,


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Inputs
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Labels
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Appropriate Loss Functions
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{single sentences}}
&
\sphinxAtStartPar
\sphinxtitleref{class}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{BatchAllTripletLoss}}, \sphinxcode{\sphinxupquote{BatchHardSoftMarginTripletLoss}}, \sphinxcode{\sphinxupquote{BatchHardTripletLoss}}, \sphinxcode{\sphinxupquote{BatchSemiHardTripletLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{single sentences}}
&
\sphinxAtStartPar
\sphinxtitleref{none}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ContrastiveTensionLoss}}, \sphinxcode{\sphinxupquote{DenoisingAutoEncoderLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(anchor, anchor)}} pairs
&
\sphinxAtStartPar
\sphinxtitleref{none}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ContrastiveTensionLossInBatchNegatives}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(damaged\_sentence, original\_sentence)}} pairs
&
\sphinxAtStartPar
\sphinxtitleref{none}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{DenoisingAutoEncoderLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(sentence\_A, sentence\_B)}} pairs
&
\sphinxAtStartPar
\sphinxtitleref{class}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{SoftmaxLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(anchor, positive)}} pairs
&
\sphinxAtStartPar
\sphinxtitleref{none}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{MultipleNegativesRankingLoss}}, \sphinxcode{\sphinxupquote{CachedMultipleNegativesRankingLoss}}, \sphinxcode{\sphinxupquote{MultipleNegativesSymmetricRankingLoss}},
\sphinxcode{\sphinxupquote{CachedMultipleNegativesSymmetricRankingLoss}}, \sphinxcode{\sphinxupquote{MegaBatchMarginLoss}}, \sphinxcode{\sphinxupquote{GISTEmbedLoss}}, \sphinxcode{\sphinxupquote{CachedGISTEmbedLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(anchor, positive/negative)}} pairs
&
\sphinxAtStartPar
\sphinxtitleref{1 if positive, 0 if negative}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ContrastiveLoss}}, \sphinxcode{\sphinxupquote{OnlineContrastiveLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(sentence\_A, sentence\_B)}} pairs
&
\sphinxAtStartPar
\sphinxtitleref{float similarity score}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{CoSENTLoss}}, \sphinxcode{\sphinxupquote{AnglELoss}}, \sphinxcode{\sphinxupquote{CosineSimilarityLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{(anchor, positive, negative)}} triplets
&
\sphinxAtStartPar
\sphinxtitleref{none}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{MultipleNegativesRankingLoss}}, \sphinxcode{\sphinxupquote{CachedMultipleNegativesRankingLoss}}, \sphinxcode{\sphinxupquote{TripletLoss}},
\sphinxcode{\sphinxupquote{CachedGISTEmbedLoss}}, \sphinxcode{\sphinxupquote{GISTEmbedLoss}}
\\
\sphinxhline
\sphinxAtStartPar
\sphinxtitleref{(anchor, positive, negative\_1, …, negative\_n)\textasciigrave{}}
&
\sphinxAtStartPar
\sphinxtitleref{none}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{MultipleNegativesRankingLoss}}, \sphinxcode{\sphinxupquote{CachedMultipleNegativesRankingLoss}}, \sphinxcode{\sphinxupquote{CachedGISTEmbedLoss}}
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}
\end{sphinxadmonition}


\subsection{Fine\sphinxhyphen{}tune Embedding Model}
\label{\detokenize{finetuning:fine-tune-embedding-model}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers} \PYG{k+kn}{import} \PYG{n}{SentenceTransformerTrainingArguments}
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers}\PYG{n+nn}{.}\PYG{n+nn}{training\PYGZus{}args} \PYG{k+kn}{import} \PYG{n}{BatchSamplers}

\PYG{c+c1}{\PYGZsh{} load train dataset again}
\PYG{n}{train\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{load\PYGZus{}dataset}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{data\PYGZus{}files}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train\PYGZus{}dataset.json}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{split}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} define training arguments}
\PYG{n}{args} \PYG{o}{=} \PYG{n}{SentenceTransformerTrainingArguments}\PYG{p}{(}
    \PYG{n}{output\PYGZus{}dir}\PYG{o}{=}\PYG{n}{output\PYGZus{}dir}\PYG{p}{,} \PYG{c+c1}{\PYGZsh{} output directory and hugging face model ID}
    \PYG{n}{num\PYGZus{}train\PYGZus{}epochs}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}                         \PYG{c+c1}{\PYGZsh{} number of epochs}
    \PYG{n}{per\PYGZus{}device\PYGZus{}train\PYGZus{}batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{32}\PYG{p}{,}             \PYG{c+c1}{\PYGZsh{} train batch size}
    \PYG{n}{gradient\PYGZus{}accumulation\PYGZus{}steps}\PYG{o}{=}\PYG{l+m+mi}{16}\PYG{p}{,}             \PYG{c+c1}{\PYGZsh{} for a global batch size of 512}
    \PYG{n}{per\PYGZus{}device\PYGZus{}eval\PYGZus{}batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{16}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{} evaluation batch size}
    \PYG{n}{warmup\PYGZus{}ratio}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,}                           \PYG{c+c1}{\PYGZsh{} warmup ratio}
    \PYG{n}{learning\PYGZus{}rate}\PYG{o}{=}\PYG{l+m+mf}{2e\PYGZhy{}5}\PYG{p}{,}                         \PYG{c+c1}{\PYGZsh{} learning rate, 2e\PYGZhy{}5 is a good value}
    \PYG{n}{lr\PYGZus{}scheduler\PYGZus{}type}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cosine}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}                 \PYG{c+c1}{\PYGZsh{} use constant learning rate scheduler}
    \PYG{n}{optim}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{adamw\PYGZus{}torch\PYGZus{}fused}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}                  \PYG{c+c1}{\PYGZsh{} use fused adamw optimizer}
    \PYG{n}{tf32}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}                                  \PYG{c+c1}{\PYGZsh{} use tf32 precision}
    \PYG{n}{bf16}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}                                  \PYG{c+c1}{\PYGZsh{} use bf16 precision}
    \PYG{n}{batch\PYGZus{}sampler}\PYG{o}{=}\PYG{n}{BatchSamplers}\PYG{o}{.}\PYG{n}{NO\PYGZus{}DUPLICATES}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} MultipleNegativesRankingLoss benefits from no duplicate samples in a batch}
    \PYG{n}{eval\PYGZus{}strategy}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{epoch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}                      \PYG{c+c1}{\PYGZsh{} evaluate after each epoch}
    \PYG{n}{save\PYGZus{}strategy}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{epoch}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}                      \PYG{c+c1}{\PYGZsh{} save after each epoch}
    \PYG{n}{logging\PYGZus{}steps}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,}                           \PYG{c+c1}{\PYGZsh{} log every 10 steps}
    \PYG{n}{save\PYGZus{}total\PYGZus{}limit}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,}                         \PYG{c+c1}{\PYGZsh{} save only the last 3 models}
    \PYG{n}{load\PYGZus{}best\PYGZus{}model\PYGZus{}at\PYGZus{}end}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}                \PYG{c+c1}{\PYGZsh{} load the best model when training ends}
    \PYG{n}{metric\PYGZus{}for\PYGZus{}best\PYGZus{}model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{eval\PYGZus{}dim\PYGZus{}128\PYGZus{}cosine\PYGZus{}ndcg@10}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} Optimizing for the best ndcg@10 score for the 128 dimension}
    \PYG{n}{greater\PYGZus{}is\PYGZus{}better}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}                     \PYG{c+c1}{\PYGZsh{} maximize the ndcg@10 score}
\PYG{p}{)}

\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers} \PYG{k+kn}{import} \PYG{n}{SentenceTransformerTrainer}

\PYG{n}{trainer} \PYG{o}{=} \PYG{n}{SentenceTransformerTrainer}\PYG{p}{(}
    \PYG{n}{model}\PYG{o}{=}\PYG{n}{model}\PYG{p}{,} \PYG{c+c1}{\PYGZsh{} bg\PYGZhy{}base\PYGZhy{}en\PYGZhy{}v1}
    \PYG{n}{args}\PYG{o}{=}\PYG{n}{args}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} training arguments}
    \PYG{n}{train\PYGZus{}dataset}\PYG{o}{=}\PYG{n}{train\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{select\PYGZus{}columns}\PYG{p}{(}
        \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{anchor}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{positive}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
    \PYG{p}{)}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{} training dataset}
    \PYG{n}{loss}\PYG{o}{=}\PYG{n}{train\PYGZus{}loss}\PYG{p}{,}
    \PYG{n}{evaluator}\PYG{o}{=}\PYG{n}{evaluator}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} start training}
\PYG{n}{trainer}\PYG{o}{.}\PYG{n}{train}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} save the best model}
\PYG{c+c1}{\PYGZsh{}trainer.save\PYGZus{}model()}
\PYG{n}{trainer}\PYG{o}{.}\PYG{n}{model}\PYG{o}{.}\PYG{n}{save\PYGZus{}pretrained}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bge\PYGZhy{}base\PYGZhy{}finetuning}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Evaluate Fine\sphinxhyphen{}tuned Model}
\label{\detokenize{finetuning:evaluate-fine-tuned-model}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sentence\PYGZus{}transformers} \PYG{k+kn}{import} \PYG{n}{SentenceTransformer}

\PYG{n}{fine\PYGZus{}tuned\PYGZus{}model} \PYG{o}{=} \PYG{n}{SentenceTransformer}\PYG{p}{(}
    \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bge\PYGZhy{}base\PYGZhy{}finetuning}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{device}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cuda}\PYG{l+s+s2}{\PYGZdq{}} \PYG{k}{if} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{cuda}\PYG{o}{.}\PYG{n}{is\PYGZus{}available}\PYG{p}{(}\PYG{p}{)} \PYG{k}{else} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cpu}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Evaluate the model}
\PYG{n}{results} \PYG{o}{=} \PYG{n}{evaluator}\PYG{p}{(}\PYG{n}{fine\PYGZus{}tuned\PYGZus{}model}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} \PYGZsh{} COMMENT IN for full results}
\PYG{c+c1}{\PYGZsh{} print(results)}

\PYG{c+c1}{\PYGZsh{} Print the main score}
\PYG{k}{for} \PYG{n}{dim} \PYG{o+ow}{in} \PYG{n}{matryoshka\PYGZus{}dimensions}\PYG{p}{:}
    \PYG{n}{key} \PYG{o}{=} \PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dim\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dim}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}cosine\PYGZus{}ndcg@10}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{key}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{results}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dim\PYGZus{}768\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.7650276801072632}
\PYG{n}{dim\PYGZus{}512\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.7603951540556889}
\PYG{n}{dim\PYGZus{}256\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.754743133407988}
\PYG{n}{dim\PYGZus{}128\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.7205317098443929}
\PYG{n}{dim\PYGZus{}64\PYGZus{}cosine\PYGZus{}ndcg}\PYG{o}{@}\PYG{l+m+mi}{10}\PYG{p}{:} \PYG{l+m+mf}{0.6609117856061502}
\end{sphinxVerbatim}


\subsection{Results Comparison}
\label{\detokenize{finetuning:results-comparison}}
\sphinxAtStartPar
Although we did not observe the significant performance boost reported in the original
blog, the fine\sphinxhyphen{}tuned model outperformed the baseline model across all dimensions using
only 6.3k samples and partial parameter fine\sphinxhyphen{}tuning. MOre details can be found as follows:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Dimension
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Baseline
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Fine\sphinxhyphen{}tuned
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Improvement
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
768
&
\sphinxAtStartPar
0.75490
&
\sphinxAtStartPar
0.76503
&
\sphinxAtStartPar
1.34\%
\\
\sphinxhline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.75492
&
\sphinxAtStartPar
0.76040
&
\sphinxAtStartPar
0.73\%
\\
\sphinxhline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.74547
&
\sphinxAtStartPar
0.75474
&
\sphinxAtStartPar
1.24\%
\\
\sphinxhline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.71167
&
\sphinxAtStartPar
0.72053
&
\sphinxAtStartPar
1.24\%
\\
\sphinxhline
\sphinxAtStartPar
64
&
\sphinxAtStartPar
0.64772
&
\sphinxAtStartPar
0.66091
&
\sphinxAtStartPar
2.04\%
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{fine_tuning_wandb}.png}
\caption{Epoch, Training Loss/steps in Wandb}\label{\detokenize{finetuning:id6}}\label{\detokenize{finetuning:fig-wandb}}\end{figure}


\section{LLM Fine\sphinxhyphen{}Tuning}
\label{\detokenize{finetuning:llm-fine-tuning}}
\sphinxAtStartPar
In this chapter, we will demonstrate how to fine\sphinxhyphen{}tune a Llama 2 model with 7 billion parameters using
a T4 GPU with 16 GB of VRAM. Due to VRAM limitations, traditional fine\sphinxhyphen{}tuning is not feasible,
making parameter\sphinxhyphen{}efficient fine\sphinxhyphen{}tuning (PEFT) techniques like LoRA or QLoRA essential. For this
demonstration, we use QLoRA, which leverages 4\sphinxhyphen{}bit precision to significantly reduce VRAM consumption.

\sphinxAtStartPar
The folloing code is from notebook \sphinxcite{reference:finetunellm}, and the copyright belongs to the original author.


\subsection{Load Dataset and Pretrained Model}
\label{\detokenize{finetuning:load-dataset-and-pretrained-model}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Step 1 : Load dataset (you can process it here)}
\PYG{n}{dataset} \PYG{o}{=} \PYG{n}{load\PYGZus{}dataset}\PYG{p}{(}\PYG{n}{dataset\PYGZus{}name}\PYG{p}{,} \PYG{n}{split}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 2 :Load tokenizer and model with QLoRA configuration}
\PYG{n}{compute\PYGZus{}dtype} \PYG{o}{=} \PYG{n+nb}{getattr}\PYG{p}{(}\PYG{n}{torch}\PYG{p}{,} \PYG{n}{bnb\PYGZus{}4bit\PYGZus{}compute\PYGZus{}dtype}\PYG{p}{)}

\PYG{n}{bnb\PYGZus{}config} \PYG{o}{=} \PYG{n}{BitsAndBytesConfig}\PYG{p}{(}
    \PYG{n}{load\PYGZus{}in\PYGZus{}4bit}\PYG{o}{=}\PYG{n}{use\PYGZus{}4bit}\PYG{p}{,}
    \PYG{n}{bnb\PYGZus{}4bit\PYGZus{}quant\PYGZus{}type}\PYG{o}{=}\PYG{n}{bnb\PYGZus{}4bit\PYGZus{}quant\PYGZus{}type}\PYG{p}{,}
    \PYG{n}{bnb\PYGZus{}4bit\PYGZus{}compute\PYGZus{}dtype}\PYG{o}{=}\PYG{n}{compute\PYGZus{}dtype}\PYG{p}{,}
    \PYG{n}{bnb\PYGZus{}4bit\PYGZus{}use\PYGZus{}double\PYGZus{}quant}\PYG{o}{=}\PYG{n}{use\PYGZus{}nested\PYGZus{}quant}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 3 :Check GPU compatibility with bfloat16}
\PYG{k}{if} \PYG{n}{compute\PYGZus{}dtype} \PYG{o}{==} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{float16} \PYG{o+ow}{and} \PYG{n}{use\PYGZus{}4bit}\PYG{p}{:}
    \PYG{n}{major}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{cuda}\PYG{o}{.}\PYG{n}{get\PYGZus{}device\PYGZus{}capability}\PYG{p}{(}\PYG{p}{)}
    \PYG{k}{if} \PYG{n}{major} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{l+m+mi}{8}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{=}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{*} \PYG{l+m+mi}{80}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Your GPU supports bfloat16: accelerate training with bf16=True}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{=}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{*} \PYG{l+m+mi}{80}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 4 :Load base model}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{AutoModelForCausalLM}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}
    \PYG{n}{model\PYGZus{}name}\PYG{p}{,}
    \PYG{n}{quantization\PYGZus{}config}\PYG{o}{=}\PYG{n}{bnb\PYGZus{}config}\PYG{p}{,}
    \PYG{n}{device\PYGZus{}map}\PYG{o}{=}\PYG{n}{device\PYGZus{}map}
\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{config}\PYG{o}{.}\PYG{n}{use\PYGZus{}cache} \PYG{o}{=} \PYG{k+kc}{False}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{config}\PYG{o}{.}\PYG{n}{pretraining\PYGZus{}tp} \PYG{o}{=} \PYG{l+m+mi}{1}

\PYG{c+c1}{\PYGZsh{} Step 5 :Load LLaMA tokenizer}
\PYG{n}{tokenizer} \PYG{o}{=} \PYG{n}{AutoTokenizer}\PYG{o}{.}\PYG{n}{from\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{model\PYGZus{}name}\PYG{p}{,} \PYG{n}{trust\PYGZus{}remote\PYGZus{}code}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{add\PYGZus{}special\PYGZus{}tokens}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pad\PYGZus{}token}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{[PAD]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{pad\PYGZus{}token} \PYG{o}{=} \PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{eos\PYGZus{}token}
\PYG{n}{tokenizer}\PYG{o}{.}\PYG{n}{padding\PYGZus{}side} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{right}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}


\subsection{Fine\sphinxhyphen{}tuning Configuration}
\label{\detokenize{finetuning:fine-tuning-configuration}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Step 6 :Load LoRA configuration}
\PYG{n}{peft\PYGZus{}config} \PYG{o}{=} \PYG{n}{LoraConfig}\PYG{p}{(}
    \PYG{n}{lora\PYGZus{}alpha}\PYG{o}{=}\PYG{n}{lora\PYGZus{}alpha}\PYG{p}{,}
    \PYG{n}{lora\PYGZus{}dropout}\PYG{o}{=}\PYG{n}{lora\PYGZus{}dropout}\PYG{p}{,}
    \PYG{n}{r}\PYG{o}{=}\PYG{n}{lora\PYGZus{}r}\PYG{p}{,}
    \PYG{n}{bias}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{none}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{task\PYGZus{}type}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CAUSAL\PYGZus{}LM}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 7 :Set training parameters}
\PYG{n}{training\PYGZus{}arguments} \PYG{o}{=} \PYG{n}{TrainingArguments}\PYG{p}{(}
    \PYG{n}{output\PYGZus{}dir}\PYG{o}{=}\PYG{n}{output\PYGZus{}dir}\PYG{p}{,}
    \PYG{n}{num\PYGZus{}train\PYGZus{}epochs}\PYG{o}{=}\PYG{n}{num\PYGZus{}train\PYGZus{}epochs}\PYG{p}{,}
    \PYG{n}{per\PYGZus{}device\PYGZus{}train\PYGZus{}batch\PYGZus{}size}\PYG{o}{=}\PYG{n}{per\PYGZus{}device\PYGZus{}train\PYGZus{}batch\PYGZus{}size}\PYG{p}{,}
    \PYG{n}{gradient\PYGZus{}accumulation\PYGZus{}steps}\PYG{o}{=}\PYG{n}{gradient\PYGZus{}accumulation\PYGZus{}steps}\PYG{p}{,}
    \PYG{n}{optim}\PYG{o}{=}\PYG{n}{optim}\PYG{p}{,}
    \PYG{n}{save\PYGZus{}steps}\PYG{o}{=}\PYG{n}{save\PYGZus{}steps}\PYG{p}{,}
    \PYG{n}{logging\PYGZus{}steps}\PYG{o}{=}\PYG{n}{logging\PYGZus{}steps}\PYG{p}{,}
    \PYG{n}{learning\PYGZus{}rate}\PYG{o}{=}\PYG{n}{learning\PYGZus{}rate}\PYG{p}{,}
    \PYG{n}{weight\PYGZus{}decay}\PYG{o}{=}\PYG{n}{weight\PYGZus{}decay}\PYG{p}{,}
    \PYG{n}{fp16}\PYG{o}{=}\PYG{n}{fp16}\PYG{p}{,}
    \PYG{n}{bf16}\PYG{o}{=}\PYG{n}{bf16}\PYG{p}{,}
    \PYG{n}{max\PYGZus{}grad\PYGZus{}norm}\PYG{o}{=}\PYG{n}{max\PYGZus{}grad\PYGZus{}norm}\PYG{p}{,}
    \PYG{n}{max\PYGZus{}steps}\PYG{o}{=}\PYG{n}{max\PYGZus{}steps}\PYG{p}{,}
    \PYG{n}{warmup\PYGZus{}ratio}\PYG{o}{=}\PYG{n}{warmup\PYGZus{}ratio}\PYG{p}{,}
    \PYG{n}{group\PYGZus{}by\PYGZus{}length}\PYG{o}{=}\PYG{n}{group\PYGZus{}by\PYGZus{}length}\PYG{p}{,}
    \PYG{n}{lr\PYGZus{}scheduler\PYGZus{}type}\PYG{o}{=}\PYG{n}{lr\PYGZus{}scheduler\PYGZus{}type}\PYG{p}{,}
    \PYG{n}{report\PYGZus{}to}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{tensorboard}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Fine\sphinxhyphen{}tune model}
\label{\detokenize{finetuning:fine-tune-model}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Step 8 :Set supervised fine\PYGZhy{}tuning parameters}
\PYG{n}{trainer} \PYG{o}{=} \PYG{n}{SFTTrainer}\PYG{p}{(}
    \PYG{n}{model}\PYG{o}{=}\PYG{n}{model}\PYG{p}{,}
    \PYG{n}{train\PYGZus{}dataset}\PYG{o}{=}\PYG{n}{dataset}\PYG{p}{,}
    \PYG{n}{peft\PYGZus{}config}\PYG{o}{=}\PYG{n}{peft\PYGZus{}config}\PYG{p}{,}
    \PYG{n}{dataset\PYGZus{}text\PYGZus{}field}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{text}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{max\PYGZus{}seq\PYGZus{}length}\PYG{o}{=}\PYG{n}{max\PYGZus{}seq\PYGZus{}length}\PYG{p}{,}
    \PYG{n}{tokenizer}\PYG{o}{=}\PYG{n}{tokenizer}\PYG{p}{,}
    \PYG{n}{args}\PYG{o}{=}\PYG{n}{training\PYGZus{}arguments}\PYG{p}{,}
    \PYG{n}{packing}\PYG{o}{=}\PYG{n}{packing}\PYG{p}{,}
\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 9 :Train model}
\PYG{n}{trainer}\PYG{o}{.}\PYG{n}{train}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Step 10 :Save trained model}
\PYG{n}{trainer}\PYG{o}{.}\PYG{n}{model}\PYG{o}{.}\PYG{n}{save\PYGZus{}pretrained}\PYG{p}{(}\PYG{n}{new\PYGZus{}model}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{fine_tuning_llm}.png}
\caption{Llama 2 Model Fine\sphinxhyphen{}Tuning TensorBoard}\label{\detokenize{finetuning:id7}}\label{\detokenize{finetuning:fig-fine-tuning-llm}}\end{figure}

\sphinxstepscope


\chapter{Pre\sphinxhyphen{}training}
\label{\detokenize{pretraining:pre-training}}\label{\detokenize{pretraining:pretraining}}\label{\detokenize{pretraining::doc}}
\begin{sphinxadmonition}{note}{Proverb}

\sphinxAtStartPar
Pre\sphinxhyphen{}training as we know it will end. \textendash{} Ilya Sutskever at neurips 2024

\begin{figure}[H]
\centering
\capstart

\noindent\sphinxincludegraphics{{ilya_sutskever}.png}
\caption{Ilya Sutskever at neurips 2024}\label{\detokenize{pretraining:id3}}\label{\detokenize{pretraining:fig-ilya}}\end{figure}
\end{sphinxadmonition}

\sphinxAtStartPar
In industry, most companies focus primarily on prompt engineering, RAG, and fine\sphinxhyphen{}tuning,
while advanced techniques like pre\sphinxhyphen{}training from scratch or deep model customization
remain less common due to the significant resources and expertise required.

\sphinxAtStartPar
LLMs, like GPT (Generative Pre\sphinxhyphen{}trained Transformer), BERT (Bidirectional Encoder
Representations from Transformers), and others, are large\sphinxhyphen{}scale models built using
the transformer architecture. These models are trained on vast amounts of text data to
learn patterns in language, enabling them to generate human\sphinxhyphen{}like text, answer questions,
summarize information, and perform other natural language processing tasks.

\sphinxAtStartPar
This chapter delves into transformer models, drawing on insights from
\sphinxhref{https://nlp.seas.harvard.edu/annotated-transformer/}{The Annotated Transformer} and \sphinxhref{https://towardsdatascience.com/tracing-the-transformer-in-diagrams-95dbeb68160c}{Tracing the Transformer in Diagrams}, to explore their underlying architecture and practical applications.


\section{Transformer Architecture}
\label{\detokenize{pretraining:transformer-architecture}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{transformer_architecture}.png}
\caption{Transformer Architecture (source: \sphinxcite{reference:attentionallyouneed})}\label{\detokenize{pretraining:id4}}\end{figure}


\subsection{Attention Is All You Need}
\label{\detokenize{pretraining:attention-is-all-you-need}}
\sphinxAtStartPar
The Transformer is a deep learning model designed to handle sequential
data, such as text, by relying entirely on attention mechanisms rather
than recurrence or convolution. It consists of an \sphinxstylestrong{encoder\sphinxhyphen{}decoder
structure}, where the \sphinxstylestrong{encoder} transforms an input sequence into a
set of rich contextual representations, and the \sphinxstylestrong{decoder} generates
the output sequence by attending to these representations and previously
generated tokens. Both encoder and decoder are composed of stacked
layers, each featuring \sphinxstylestrong{multi\sphinxhyphen{}head self\sphinxhyphen{}attention} (to capture
relationships between tokens), \sphinxstylestrong{feedforward neural networks} (for
non\sphinxhyphen{}linear transformations), and \sphinxstylestrong{residual connections with layer
normalization} (to improve training stability). Positional encodings
are added to token embeddings to retain sequence order information, and
the architecture’s parallelism and scalability make it highly efficient
for tasks like machine translation, summarization, and language
modeling.

\sphinxAtStartPar
When the Transformer architecture was introduced in the paper
\sphinxstyleemphasis{“Attention Is All You Need”} (Vaswani et al., 2017), the primary task
it aimed to address was \sphinxstylestrong{machine translation}. The researchers wanted
to develop a model that could translate text from one language to
another more efficiently and effectively than the existing
sequence\sphinxhyphen{}to\sphinxhyphen{}sequence (Seq2Seq) models, which relied heavily on recurrent
neural networks (RNNs) or long short\sphinxhyphen{}term memory (LSTM) networks. RNNs /
LSTMs suffer from slow training and inference, short\sphinxhyphen{}term memory, and
vanishing / exploding gradients challenges, due to their sequentual
nature and long\sphinxhyphen{}range dependencies. The Transformer with self\sphinxhyphen{}attention
mechanism achieved to eliminate the sequential bottleneck of RNNs while
retaining the ability to capture dependencies across the entire input
sequence.


\subsection{Encoder\sphinxhyphen{}Decoder}
\label{\detokenize{pretraining:encoder-decoder}}
\sphinxAtStartPar
Transformer has an encoding component, a decoding component, and
connections between them. The encoding component is a stack of encoders
\sphinxhyphen{} usually 6\sphinxhyphen{}12 layers, though it can go higher (e.g. T5\sphinxhyphen{}large has 24
encoder layers). The decoder component is a stack of decoders, usually
in the same number of layers for balance.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Each \sphinxstylestrong{encoder} layer includes multi\sphinxhyphen{}head self\sphinxhyphen{}attention, feedforward
neural network (FNN), add \& norm, and positional encoding. It reads
the input sequence (e.g., a sentence in Chinese) and produces a
context\sphinxhyphen{}aware representation.

\item {} 
\sphinxAtStartPar
Each \sphinxstylestrong{decoder} layer includes masked multi\sphinxhyphen{}head self\sphinxhyphen{}attention,
encoder\sphinxhyphen{}decoder attention, feedforward neural network (FFN), add \&
norm, and positional encoding. It generates the output sequence (e.g.,
a translation in English) using the encoder’s output and previously
generated tokens.

\end{itemize}

\sphinxAtStartPar
The encoder\sphinxhyphen{}decoder structure was inspired by earlier Seq2Seq models
(Sutskever et al., 2014), which used separate RNNs or LSTMs for encoding
the input sequence and decoding the output sequence. The innovation of
the Transformer was replacing the recurrent nature of those models with
an attention\sphinxhyphen{}based approach. The Transformer revolutionized not just
machine translation but also the entire field of natural language
processing (NLP). Its encoder\sphinxhyphen{}decoder structure provided a blueprint for
subsequent models:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Encoder\sphinxhyphen{}only models} (e.g., BERT, RoBERTa, DistilBERT) for
understanding tasks such as classification, sentiment analysis, named
entity recognition, and question answering.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Unlike encoder\sphinxhyphen{}decoder or decoder\sphinxhyphen{}only models, encoder\sphinxhyphen{}only models
don’t generate new sequences. Its architecture and training
objectives are optimized for extracting contextual representations
from input sequences. They focus solely on understanding and
representing the input.

\item {} 
\sphinxAtStartPar
Encoder\sphinxhyphen{}only models typically use \sphinxstylestrong{bidirectional self\sphinxhyphen{}attention},
meaning each token can attend to all other tokens in the sequence
(both before and after it). This contrasts with decoder\sphinxhyphen{}only models,
which use causal masking and can only attend to past tokens.
Bidirectionality provides a more holistic understanding of the
input.

\item {} 
\sphinxAtStartPar
Encoder\sphinxhyphen{}only models are often pretrained with tasks like \sphinxstylestrong{masked
language modeling (MLM)}, where random tokens in the input are
masked and the model learns to predict them based on context.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Decoder\sphinxhyphen{}only models} (e.g., GPT series, Transformer\sphinxhyphen{}XL) for text
generation tasks.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Decoder\sphinxhyphen{}only models are trained with an \sphinxstylestrong{autoregressive
objective}, meaning they predict the next token in a sequence based
on the tokens seen so far. This makes them inherently suited for
producing coherent, contextually relevant continuations.

\item {} 
\sphinxAtStartPar
The self\sphinxhyphen{}attention mechanism in decoder\sphinxhyphen{}only models is \sphinxstylestrong{causal},
meaning each token attends only to previous tokens (including
itself). They are pretrained with \sphinxstylestrong{causal language modeling
(CLM)}, where they learn to predict the next token given the
previous ones.

\item {} 
\sphinxAtStartPar
Decoder\sphinxhyphen{}only models are not constrained to fixed\sphinxhyphen{}length outputs and
can generate sequences of arbitrary lengths, making them ideal for
open\sphinxhyphen{}ended tasks such as story writing, dialogue generation, and
summarization.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Encoder\sphinxhyphen{}decoder models} (e.g., Original Transformer, BART, T5) for
sequence\sphinxhyphen{}to\sphinxhyphen{}sequence tasks such as machine translation, summarization,
and text generation.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Encoder and decoder are designed to handle different parts of the
task \sphinxhyphen{} creating a contextual representation and generating output
sequence. This decoupling of encoding and decoding allows the model
to flexibly handle inputs and outputs of different lengths.

\item {} 
\sphinxAtStartPar
The \sphinxstylestrong{encoder\sphinxhyphen{}decoder attention mechanism} in the decoder allows
the model to focus on specific parts of the encoded input sequence
while generating the output sequence. This \sphinxstylestrong{cross\sphinxhyphen{}attention}
mechanism helps maintain the relationship between the input and
output sequences.

\item {} 
\sphinxAtStartPar
In many encoder\sphinxhyphen{}decoder models (such as those based on
Transformers), the encoder processes the input sequence
\sphinxstylestrong{bidirectionally}, meaning it can attend to both preceding and
succeeding tokens when creating the representations. This ensures a
comprehensive understanding of the input sequence before it is
passed to the decoder.

\item {} 
\sphinxAtStartPar
During training, the encoder\sphinxhyphen{}decoder model is typically provided
with a sequence of \sphinxstylestrong{input\sphinxhyphen{}output pairs} (e.g., a Chinese sentence
and its English translation). This paired structure makes the model
highly suited for tasks like translation, where the goal is to map
input sequences in one language to corresponding output sequences in
another language.

\end{itemize}

\end{itemize}


\subsection{Positional Encoding}
\label{\detokenize{pretraining:positional-encoding}}
\sphinxAtStartPar
\sphinxstylestrong{Positional encoding} is a mechanism used in transformers to provide
information about the order of tokens in a sequence. Unlike recurrent
neural networks (RNNs), transformers process all tokens in parallel, and
therefore lack a built\sphinxhyphen{}in way to capture sequential information.
Positional encoding solves this by injecting position\sphinxhyphen{}dependent
information into the input embeddings.


\subsubsection{Sinusoidal Positional Encodings}
\label{\detokenize{pretraining:sinusoidal-positional-encodings}}
\sphinxAtStartPar
Sinusoidal positional encoding adds a vector to the embedding of each
token, with the vector values derived using \sphinxstylestrong{sinusoidal functions}.
For a token at position \(pos\) in the sequence and a specific
dimension \(i\) of the embedding:
\begin{equation*}
\begin{split}PE(pos,2i) = \sin\Big({pos\over 10000^{2i/d}}\Big)\\
PE(pos,2i+1) = \cos\Big({pos\over 10000^{2i/d}}\Big)\end{split}
\end{equation*}
\sphinxAtStartPar
where
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(pos\): Position of the token in the sequence.

\item {} 
\sphinxAtStartPar
\(i\): Index of the embedding dimension.

\item {} 
\sphinxAtStartPar
\(d\): Total dimension of the embedding vector.

\end{itemize}

\sphinxAtStartPar
The positional encodings are added directly to the token embeddings:
\begin{equation*}
\begin{split}\text{Input to Transformer} = \text{Token Embedding} + \text{Positional Encoding}\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{position_embedding}.png}
\caption{Positional Embedding}\label{\detokenize{pretraining:id5}}\end{figure}


\subsubsection{Rotary Positional Embeddings (RoPE)}
\label{\detokenize{pretraining:rotary-positional-embeddings-rope}}
\sphinxAtStartPar
Rotary positional embedding is a modern variant that introduces
positional information through rotation in a complex vector space. It
encodes positional information by rotating the query and key vectors in
the attention mechanism using a transformation in a complex vector
space. RoPE mitigates the limitations of absolute positional encodings
by focusing on relative relationships, enabling smooth transitions and
better handling of long sequences. This makes it particularly
advantageous in large\sphinxhyphen{}scale language models like GPT\sphinxhyphen{}4, LLaMA, where
long\sphinxhyphen{}range dependencies and adaptability are crucial.

\sphinxAtStartPar
Given a token vector \(x\) with positional encoding, RoPE applies a
rotation:
\begin{equation*}
\begin{split}\text{RoPE} = R(pos)\cdot x\end{split}
\end{equation*}
\sphinxAtStartPar
where \(R(pos)\) is the rotation matrix determined by the token’s
position.

\sphinxAtStartPar
Specifically, for a rotation by an angle \(\theta\), the 2D rotation
matrix is
\begin{equation*}
\begin{split}R(\theta) = \begin{bmatrix} \cos(\theta) & -\sin(\theta) \\ \sin(\theta) & \cos(\theta)\end{bmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
For each pair of dimensions \((x_{even}, x_{odd})\), the rotation is
performed as
\begin{equation*}
\begin{split}\begin{bmatrix}x'_{even} \\x'_{odd} \end{bmatrix} = \begin{bmatrix} \cos(\theta) & -\sin(\theta) \\ \sin(\theta) & \cos(\theta)\end{bmatrix} \cdot \begin{bmatrix}x_{even} \\x_{odd} \end{bmatrix}\end{split}
\end{equation*}

\subsubsection{\sphinxstylestrong{Learnable Positional Encodings}}
\label{\detokenize{pretraining:learnable-positional-encodings}}
\sphinxAtStartPar
Learnable Positional Encodings are a type of positional encoding used in
transformer\sphinxhyphen{}based models where the positional information is not fixed
(like in \sphinxstylestrong{sinusoidal} encoding) but is \sphinxstylestrong{learned during training}.
These encodings are treated as trainable parameters and are updated
through backpropagation, just like other parameters in the model.


\subsubsection{Summary}
\label{\detokenize{pretraining:summary}}

\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Feature
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Sinusoidal
Positional Encoding
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Rotary Positional
Embeddings (RoPE)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Learnable
Positional
Encodings
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
Type
&
\sphinxAtStartPar
Absolute
&
\sphinxAtStartPar
Relative
&
\sphinxAtStartPar
Absolute
\\
\sphinxhline
\sphinxAtStartPar
Learnable
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
No
&
\sphinxAtStartPar
Yes
\\
\sphinxhline
\sphinxAtStartPar
Advantages
&
\sphinxAtStartPar
Fixed, no trainable
parameters;
Generalizes to
unseen sequence
lengths;
Computationally
simple.
&
\sphinxAtStartPar
Encodes relative
positional
relationships;
Scales efficiently
to long sequences;
Smooth handling of
long\sphinxhyphen{}range
dependencies.
&
\sphinxAtStartPar
Flexible for
task\sphinxhyphen{}specific
adaptation;
Optimized during
training.
\\
\sphinxhline
\sphinxAtStartPar
Disadvantages
&
\sphinxAtStartPar
Fixed, cannot adapt
to data; Encodes
only absolute
positions; Less
flexible for
relative tasks.
&
\sphinxAtStartPar
More complex to
implement;
Relatively new,
less widespread for
general tasks.
&
\sphinxAtStartPar
Limited to a fixed
maximum sequence
length; No inherent
relative
positioning;
Requires more
parameters.
\\
\sphinxhline
\sphinxAtStartPar
Usage
&
\sphinxAtStartPar
Early models (e.g.,
original
Transformer);
S
equence\sphinxhyphen{}to\sphinxhyphen{}sequence
tasks like
translation.
&
\sphinxAtStartPar
Modern LLMs (e.g.,
GPT\sphinxhyphen{}4, LLaMA) with
long context
lengths; Tasks
requiring
long\sphinxhyphen{}range
dependencies.
&
\sphinxAtStartPar
Popular in earlier
models like GPT\sphinxhyphen{}2,
BERT; Tasks with
shorter sequences.
\\
\sphinxhline
\sphinxAtStartPar
Best For
&
\sphinxAtStartPar
Simplicity,
generalization to
unseen data.
&
\sphinxAtStartPar
Long\sphinxhyphen{}context tasks,
relative
dependencies,
efficient scaling.
&
\sphinxAtStartPar
Task\sphinxhyphen{}specific
optimization,
shorter context
tasks.
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\subsection{Embedding Matrix}
\label{\detokenize{pretraining:embedding-matrix}}
\sphinxAtStartPar
\sphinxstylestrong{Embedding} refers to the process of converting \sphinxstylestrong{discrete tokens
(words, subwords, or characters)} into \sphinxstylestrong{continuous vector
representations} in a high\sphinxhyphen{}dimensional space. These vectors capture the
semantic and syntactic properties of tokens, allowing the model to
process and understand language more effectively. Embedding layer is a
necessary component because:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Discrete symbols are not directly understandable by the model.
Embeddings transform these discrete tokens into continuous vectors.
Neural networks process continuous numbers more effectively than
discrete symbols.

\item {} 
\sphinxAtStartPar
Embeddings help the model learn relationships between words. By
learning the \sphinxstylestrong{semantic properties} of tokens during training, words
with similar meanings (e.g. “king” and “queen”) should have similar
vector representations.

\item {} 
\sphinxAtStartPar
In Transformer based models, embeddings are not just static
representations but can be adjusted as the model learns from the
context of a sentence to capture subtle semantic nuances and
dependencies between words.

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{word_embedding_matrix}.png}
\caption{Word Embedding}\label{\detokenize{pretraining:id6}}\end{figure}

\sphinxAtStartPar
Take an example of embedding matrix \(W_E\) with \textasciitilde{}50k vocabulary
size, each token in the vocabulary has a corresponding vector, typically
initialized \sphinxstylestrong{randomly} at the beginning of training. Embedding matrix
does not only represent individual words. They also encode the
information about the position of the word. And through training process
(passing through self\sphinxhyphen{}attention and multiple layers), these embeddings
are transformed into \sphinxstylestrong{contextual embeddings}, encoding not only the
individual word but also its relationship to other words in the
sequence.

\sphinxAtStartPar
The reason why a model predicting the next word requires efficient
context incorporation, is that the meaning of a word is clearly informed
by its surroundings, sometimes this includes context from a long
distance away. For example, with contextual embeddings, the dot products
of pieces of this sentence “\sphinxstyleemphasis{Harry Potter attends Hogwarts School of
Witchcraft and Wizardry, retrieves the Philosopher’s Stone, battles a
basilisk, and ultimately leads a final battle at Hogwarts, defeating
Voldemort and bringing peace to the wizarding world}” results in the
following projections in embedding space:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{contextual_embedding}.png}
\caption{Contextual Embedding}\label{\detokenize{pretraining:id7}}\end{figure}

\sphinxAtStartPar
Embedding matrix contains vectors of all words in the vocabulary. It’s
the first pile of weights in our model. If the vocabulary size is
\(V\) and the embedding dimension is \(d\), the embedding matrix
\(W_E\) has dimensions \(d \times V\). The total number of
parameters in this embedding matrix is calculated by \(d \times V\).


\subsection{Attention Mechanism}
\label{\detokenize{pretraining:attention-mechanism}}

\subsubsection{Self\sphinxhyphen{}Attention}
\label{\detokenize{pretraining:self-attention}}
\sphinxAtStartPar
A \sphinxstylestrong{self\sphinxhyphen{}attention} is called single\sphinxhyphen{}head attention, which enables the
model to effectively capture relationships and dependencies between
different tokens within the same input sequence. Multi\sphinxhyphen{}headed attention
has multiple self\sphinxhyphen{}attentions running in parallel. The goal of
self\sphinxhyphen{}attention is to produce a refined embedding where each word has
ingested contextual meanings from other words by a series of
computations. For example, in the input of “The brave wizard cast a
powerful spell”, the refined embedding E3’ of ‘wizard’ should contain
the meaning of ‘brave’, and the refined embedding E7’ of ‘spell’ should
contain the meaning of ‘powerful’.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{selfattention_goal}.png}
\end{figure}

\sphinxAtStartPar
The computation involved in self\sphinxhyphen{}attention in transformers consists of
several key steps: generating query, key, and value representations,
calculating attention scores, applying softmax, and computing a weighted
sum of the values.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Linear Projection to Query space}

\sphinxAtStartPar
Given an input represention with dimension of \((d \times N)\)
where \(d\) is the embedding dimension and \(N\) is the token
number. Query matrix \(W_Q\) with dimension of
\((N \times d_q)\) (\(d_q\) is usually small e.g. 128)
contains learnable parameters. It is used to project input
representation \(W_E\) to the smaller query space \(Q\) by
matrix multiplication.
\begin{equation*}
\begin{split}Q = W_E W_Q\\ \space(N\times d)(d\times d_q) \rightarrow (N \times d_q)\end{split}
\end{equation*}
\sphinxAtStartPar
Conceptually, the query matrix aims to ask each word a question
regarding what kinds of relationship it has with each of the other
words.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{query_projection}.png}
\caption{Query Projection}\label{\detokenize{pretraining:id8}}\end{figure}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Linear Projection to Key space}

\sphinxAtStartPar
Key matrix \(W_k\) with dimension of \((N \times d_k)\)
contains learnable parameters. It is used to project input
representation \(W_E\) to the smaller key space \(K\) by
matrix multiplication.
\begin{equation*}
\begin{split}K = W_E W_K \\ \space (N \times d) (d \times d_k) \rightarrow (N \times d_k)\end{split}
\end{equation*}
\sphinxAtStartPar
Conceptually, the keys are answering the queries by matching the
queries whenever they closely align with each other. In our example
of “The brave wizard cast a powerful spell”, the key metrix maps the
word ‘brave’ to vectors that are closely aligned with the query
produced by the word ‘wizard’.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{key_projection}.png}
\caption{Key Projection}\label{\detokenize{pretraining:id9}}\end{figure}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Compute Attention Scores}

\sphinxAtStartPar
Attention scores are calculated by taking the \sphinxstylestrong{dot product} of the
query vectors with the key vectors. These scores as a measurement of
relationship represent how well each key matches each query. They can
be values from negative infinity to positive infinity.
\begin{equation*}
\begin{split}\text{Attention Score} = QK^T\end{split}
\end{equation*}
\sphinxAtStartPar
In our example, the attention score produced by \(K_2 \cdot Q_3\)
is expected to be a large positive value because ‘brave’ is an
adjective to ‘wizard’. In other words, the embedding of ‘brave’
\sphinxstylestrong{attends to} the embedding of ‘wizard’.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{attention_score}.png}
\caption{Attention Score}\label{\detokenize{pretraining:id10}}\end{figure}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Scaling and softmax normalization}

\sphinxAtStartPar
To prevent large values in the attention scores (which could lead to
very small gradients), the scores are often scaled by the square root
of the dimension of the key vectors \(\sqrt{d_k}\). This scaling
helps stabilize the softmax function used in the next step.
\begin{equation*}
\begin{split}\text{Scaled Attention Score} = {QK^T \over \sqrt{d_k}}\end{split}
\end{equation*}
\sphinxAtStartPar
The attention scores are passed through a \sphinxstylestrong{softmax} function, which
normalizes them into a probability distribution. This ensures that
each column of the attention matrix sums to 1, so each token has a
clear distribution of “attention” over all tokens.
\begin{equation*}
\begin{split}\text{Attention Weights} = \text{softmax}\Big({QK^T\over{\sqrt{d_k}}}\Big)\end{split}
\end{equation*}
\sphinxAtStartPar
Note that for a \sphinxstylestrong{masked} self attention, the bottom left triangle
of attention scores are set to negative infinity before softmax
normalization. The purpose is to mask those information as latter
words are not allowed to influence earlier words. After softmax
normalization, those masked attention information becomes zero and
the columns stay normalized. This process is called \sphinxstylestrong{masking}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Computing weighted sum of values}

\sphinxAtStartPar
In the attention score matrix with dimension of \(N \times N\),
each column is giving weights according to how relevant the word in
key space (on the left in the figure) is to the correpsonding word in
query space (on the top in the figure). This matrix is also called
\sphinxstylestrong{attention pattern}.

\sphinxAtStartPar
The size of attention pattern is the square of the context size,
therefore, context size is a huge bottleneck for LLMs. Recent years,
some variations of attention mechanism are developed such as Sparse
Attention Mechanism, Blockwise Attention, Linformer, Reformer,
Longformer, etc, aiming to make context more scalable.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Linear Projection to Value space}

\sphinxAtStartPar
Value matrix \(W_v\) with dimension of \((N \times d_v)\)
contains learnable parameters. It is used to project input
representation \(W_E\) to the smaller value space \(V\) by
matrix multiplication.
\begin{equation*}
\begin{split}V = W_E W_V \\ \space (N \times d) (d \times d_v) \rightarrow (N \times d_v)\end{split}
\end{equation*}
\sphinxAtStartPar
Conceptually, by maping the embedding of a word to the value space,
it’s trying to figure out what should be added to the embedding of
other words, if this word is relevant to adjusting the meaning of
other words.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Compute Weighted Sum of Values}

\sphinxAtStartPar
Each token’s output is computed by taking a \sphinxstylestrong{weighted sum} of the
value vectors, where the weights come from the attention distribution
obtained in the previous step.
\begin{equation*}
\begin{split}\text{Output} = \text{Attention Weights} \times V\\
(N \times N) (N \times d_v) \rightarrow (N \times d_v)\end{split}
\end{equation*}
\sphinxAtStartPar
This results in a matrix of size \(N \times d_v\) where for each
word there is a weighted sum of the value vectors \(\Delta E\)
based on the attention distribution. Conceptually, this is the change
going to be added to the original embedding, resulting in a more
refined vector, encoding contextually rich meaning.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{value_projection_weighted_sum}.png}
\caption{Value Projection and Weighted Sum}\label{\detokenize{pretraining:id11}}\end{figure}

\end{enumerate}

\sphinxAtStartPar
To sum up, given \(W_E\) input matrix (\(N \times d\)),
\(W_Q, W_K, W_V\) as weight matrices
(\(d\times d_q, d\times d_k, d\times d_v\)), the matrix form of the
full self\sphinxhyphen{}attention process can be written as:
\begin{equation*}
\begin{split}\text{Output} = \text{softmax}\Big({(W_EW_Q)(W_EW_K)^T \over \sqrt{d_k}}\Big) \times (W_EW_V)\end{split}
\end{equation*}
\sphinxAtStartPar
where the final output matrix is \(N \times d_v\).

\sphinxAtStartPar
A full attention block inside a transformer consists of \sphinxstylestrong{multi\sphinxhyphen{}head
attention}, where self\sphinxhyphen{}attention operations run in parallel, each with
its own distinct Key, Query, Value matrices.

\sphinxAtStartPar
To update embedding matrix, the weighted sum of values is passed through
a linear transformation (via \(W_O\)), and then added to the
original input embeddings via a residual connection.
\begin{equation*}
\begin{split}\text{Final output} = \text{Output} \times W_o\end{split}
\end{equation*}
\sphinxAtStartPar
The number of parameters involved in Attention Mechanism:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TT}
\sphinxtoprule

\sphinxAtStartPar

&\sphinxstyletheadfamily 
\sphinxAtStartPar
\# Parameters
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
Embedding Matrix
&
\sphinxAtStartPar
d\_embed * n\_vocab
\\
\sphinxhline
\sphinxAtStartPar
Key Matrix
&
\sphinxAtStartPar
d\_key * d\_embed * n\_heads * n\_layers
\\
\sphinxhline
\sphinxAtStartPar
Query Matrix
&
\sphinxAtStartPar
d\_query * d\_embed * n\_heads * n\_layers
\\
\sphinxhline
\sphinxAtStartPar
Value Matrix
&
\sphinxAtStartPar
d\_value * d\_embed * n\_heads * n\_layers
\\
\sphinxhline
\sphinxAtStartPar
Output Matrix
&
\sphinxAtStartPar
d\_embed * d\_value * n\_heads * n\_layers
\\
\sphinxhline
\sphinxAtStartPar
Unembedding Matrix
&
\sphinxAtStartPar
n\_vocab * d\_embed
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\subsubsection{Cross Attention}
\label{\detokenize{pretraining:cross-attention}}
\sphinxAtStartPar
\sphinxstylestrong{Cross\sphinxhyphen{}attention} is a mechanism in transformers where the queries
(\(Q\)) come from one sequence (e.g., the decoder), while the keys
(\(K\)) and values (\(V\)) come from another sequence (e.g., the
encoder). It allows the model to align and focus on relevant parts of a
second sequence when processing the current sequence.


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Feature
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Self\sphinxhyphen{}Attention
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Cross\sphinxhyphen{}Attention
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
Source
of
Queries
&
\sphinxAtStartPar
Queries (\(Q\)) come
from the same sequence.
&
\sphinxAtStartPar
Queries (\(Q\)) come
from one sequence (e.g.,
decoder).
\\
\sphinxhline
\sphinxAtStartPar
Source
of
Keys
/Values
&
\sphinxAtStartPar
Keys (\(K\)) and Values
(\(V\)) come from the
same sequence.
&
\sphinxAtStartPar
Keys (\(K\)) and Values
(\(V\)) come from a
different sequence (e.g.,
encoder).
\\
\sphinxhline
\sphinxAtStartPar
Purpose
&
\sphinxAtStartPar
Captures relationships
within the same sequence.
&
\sphinxAtStartPar
Aligns and integrates
information between two
sequences.
\\
\sphinxhline
\sphinxAtStartPar
Example
Usage
&
\sphinxAtStartPar
Used in both encoder and
decoder to process input or
output tokens.
&
\sphinxAtStartPar
Used in encoder\sphinxhyphen{}decoder
models (e.g., translation)
to let the decoder focus on
encoder outputs.
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\subsection{Layer Normalization}
\label{\detokenize{pretraining:layer-normalization}}
\sphinxAtStartPar
Layer Normalization is crucial in transformers because it helps
stabilize and accelerate the training of deep neural networks by
normalizing the activations across the layers. The transformer
architecture, which consists of many layers and complex operations,
benefits significantly from this technique for several reasons:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Internal Covariate Shift}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Deep models like transformers often suffer from \sphinxstylestrong{internal
covariate shift}, where the distribution of activations changes
during training due to the update of model parameters. This can
make training slower and less stable.

\item {} 
\sphinxAtStartPar
Layer normalization helps mitigate this by ensuring that the output
of each layer has a consistent distribution, which leads to faster
convergence and more stable training.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Gradient Flow}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
In deep models, the gradients can become either very small
(vanishing gradient problem) or very large (exploding gradient
problem) as they propagate through the layers. Layer normalization
helps keep the gradients within a reasonable range, ensuring
\sphinxstylestrong{efficient gradient flow} and preventing these issues.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Improved Convergence}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
By normalizing the activations, layer normalization allows the
model to use \sphinxstylestrong{larger learning rates}, which speeds up training
and leads to better convergence.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Works Across Batch Sizes}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Unlike \sphinxstylestrong{Batch Normalization}, which normalizes activations across
the batch dimension, \sphinxstylestrong{Layer Normalization} normalizes across the
feature dimension for each individual example, making it more
suitable for tasks like \sphinxstylestrong{sequence modeling}, where the batch size
may vary and the model deals with sequences of different lengths.

\end{itemize}

\end{enumerate}

\sphinxAtStartPar
The process can be broken down into the following steps:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Compute the Mean and Variance: for a given input
\(x = [x_1, ..., x_d]\):
\begin{equation*}
\begin{split}\mu = {1\over d} \sum^d_{i=1}x_i\\
\sigma^2 = {1\over d} \sum^d_{i=1} \sum^d_{i=1} (x_i-\mu)^2\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\mu\) is the mean and \(\sigma^2\) is the variance of
the input.

\item {} 
\sphinxAtStartPar
Normalize the input: subtracting the mean and dividing by the
standard deviation:
\begin{equation*}
\begin{split}\hat{x_i} = { x_i - \mu \over \sqrt{\sigma^2 + \epsilon}}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\epsilon\) is a small constant added to the variance to
avoid division by zero.

\item {} 
\sphinxAtStartPar
Scale and shift: after normalization, the output is scaled and
shifted by \sphinxstylestrong{learnable parameters} \(\gamma\) (scale) and
\(\beta\) (shift), which allow the model to restore the original
distribution if needed:
\begin{equation*}
\begin{split}y_i = \gamma \cdot \hat{x_i} + \beta\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\gamma\) and \(\beta\) are trainable parameters
learned during the training process.

\end{enumerate}


\subsection{Residual Connections}
\label{\detokenize{pretraining:residual-connections}}
\sphinxAtStartPar
In the transformer architecture, \sphinxstylestrong{residual connections} are used after
each key operation, such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{After Self\sphinxhyphen{}Attention}: The input to the attention layer is added
back to the output of the self\sphinxhyphen{}attention mechanism.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{After Feed\sphinxhyphen{}Forward Networks}: Similarly, after the output of the
feed\sphinxhyphen{}forward network is computed, the input to the feed\sphinxhyphen{}forward block
is added back to the result.

\end{itemize}

\sphinxAtStartPar
In both cases, the sum is typically passed through a \sphinxstylestrong{Layer
Normalization} operation, which stabilizes the training process
further.

\sphinxAtStartPar
Residual connection has the following advantages:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Skip Connection}: The original input to the layer is \sphinxstylestrong{skipped
over} and added directly to the output of the layer. This allows the
model to preserve the information from earlier layers, helping it
learn faster and more efficiently.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Enabling Easier Gradient Flow}: In deep neural networks, as layers
become deeper, gradients can either vanish or explode, making
training difficult. Residual connections mitigate the vanishing
gradient problem by allowing gradients to flow more easily through
the network during backpropagation.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Helping with Identity Mapping}: Residual connections allow the
network to learn \sphinxstylestrong{identity mappings}. If a certain layer doesn’t
need to make any modifications to the input, the network can simply
learn to output the input directly, ensuring that deeper layers don’t
hurt the performance of the network. This helps the network avoid
situations where deeper layers perform worse than shallow layers.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Stabilizing Training}: The direct path from the input to the
output, via the residual connection, helps stabilize the training by
providing an additional gradient flow, making the learning process
more robust to initialization and hyperparameters.

\end{enumerate}


\subsection{Feed\sphinxhyphen{}Forward Networks}
\label{\detokenize{pretraining:feed-forward-networks}}
\sphinxAtStartPar
In the Transformer architecture, \sphinxstylestrong{Feed\sphinxhyphen{}Forward Networks (FFNs)} are a
key component within each layer of the encoder and decoder. FFNs are
applied independently to each token in the sequence, after the attention
mechanism (self\sphinxhyphen{}attention or cross\sphinxhyphen{}attention). They process the
information passed through the attention mechanism to refine the
representations of each token.

\sphinxAtStartPar
The characteristics and roles of FFN:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Position\sphinxhyphen{}Independent}: FFNs operate \sphinxstylestrong{independently} on each
token’s embedding, without considering the sequence structure. Each
token is treated individually.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Non\sphinxhyphen{}Linearity}: The \sphinxstylestrong{activation function} (like ReLU or GELU)
introduces \sphinxstylestrong{non\sphinxhyphen{}linearity} into the model, which is crucial for
allowing the network to learn complex patterns in the data

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Parameter Sharing}: The same FFN is applied to each token in the
sequence independently. The parameters are shared across all tokens,
which is computationally efficient and reduces the number of
parameters in the model.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Dimensionality Expansion}: The hidden layer size \(d_{ff}\) is
typically \sphinxstylestrong{larger} than the model dimension
\(d_{\text{model}}\) (often by a factor of 4), allowing the
network to learn richer representations in the intermediate space.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Local Information Processing}: FFNs only process \sphinxstylestrong{local}
information about each token’s embedding, as opposed to the
self\sphinxhyphen{}attention mechanism, which captures \sphinxstylestrong{global dependencies}
across all tokens in the sequence.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Residual Connection}: FFNs in transformers use \sphinxstylestrong{residual
connections}, where the input to the FFN is added to the output.
This helps \sphinxstylestrong{prevent vanishing gradient issues} and makes training
deep models more efficient.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Parallelization}: Since FFNs are applied independently to each
token, they can be \sphinxstylestrong{parallelized} effectively, leading to faster
training and inference.

\end{enumerate}

\sphinxAtStartPar
The network can only process a fixed number of vectors at a time, known
as its \sphinxstylestrong{context size}. The context size can be 4096 (GPT\sphinxhyphen{}3) up to 2M
tokens (LongRoPE).


\subsection{Label Smoothing}
\label{\detokenize{pretraining:label-smoothing}}
\sphinxAtStartPar
In transformer models, \sphinxstylestrong{label smoothing} is commonly applied during
the training phase to improve the model’s generalization by modifying
the target labels used for training. This technique is typically used in
tasks like \sphinxstylestrong{machine translation}, \sphinxstylestrong{language modeling}, and other
sequence\sphinxhyphen{}to\sphinxhyphen{}sequence tasks.

\sphinxAtStartPar
Label smoothing is applied after the decoder generates a probability
distribution over the vocabulary in the final layer. The output of the
decoder is a vector of logits (raw predictions), which are transformed
into a probability distribution using \sphinxstylestrong{softmax}. After applying
softmax, the predicted probabilities are compared to the smoothed target
distribution to calculate the loss.

\sphinxAtStartPar
The target distribution is originally an one\sphinxhyphen{}hot vector. After \sphinxstylestrong{label
smoothing}, the one\sphinxhyphen{}hot encoding is adjusted so that the correct token
has a reduced probability, and the incorrect tokens share a small amount
of probability mass. For example, if the origianl one\sphinxhyphen{}hot vector is
\([0, 1, 0, 0]\), then label smoothing would convert this vector
into something like \([0.05, 0.9, 0.05, 0.05]\).

\sphinxAtStartPar
During training, the model computes the \sphinxstylestrong{cross\sphinxhyphen{}entropy loss} between
the predicted probabilities and the smoothed target distribution. The
loss function is modified as follows:
\begin{equation*}
\begin{split}L = -\sum_i{\hat{y_i} \log(p_i)}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\hat{y_i}\) is the smoothed target probability for class
\(i\), and \(p_i\) is the predicted probability for class
\(i\).

\sphinxAtStartPar
The model’s output probabilities are then adjusted during training by
backpropagating the modified loss. This encourages the model to
distribute some probability to alternative tokens, making it less likely
to become overly confident in its predictions.

\sphinxAtStartPar
Label smoothing is important in transformers because
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Prevents Overfitting}: Label smoothing forces the model to spread
some probability mass over other tokens, making it \sphinxstylestrong{less
overconfident} and more likely to generalize well to unseen data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Encourages Robustness}: By smoothing the target labels, the
transformer is encouraged to explore alternative possibilities for
each token rather than memorizing the exact sequence of tokens in the
training data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Improved Calibration}: The model learns to \sphinxstylestrong{distribute probability
more evenly} across all tokens, which often results in
\sphinxstylestrong{better\sphinxhyphen{}calibrated probabilities} that improve performance in tasks
such as \sphinxstylestrong{classification} and \sphinxstylestrong{sequence generation}.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Training Stability}: Label smoothing reduces the effect of outliers
and noisy labels in the training data, improving the overall stability
of training and leading to faster convergence.

\end{itemize}


\subsection{Softmax and Temperature}
\label{\detokenize{pretraining:softmax-and-temperature}}
\sphinxAtStartPar
The \sphinxstylestrong{softmax function} is a mathematical operation used to transform a
vector of raw scores (\sphinxstylestrong{logits}) into a vector of \sphinxstylestrong{probabilities}. It
takes a vector of real numbers, \(z = [z_1, z_2, \dots, z_n]\), and
maps it to a probability distribution, where each element is in the
range {[}0, 1{]}, and the sum of all elements equals 1. Mathematically,
\begin{equation*}
\begin{split}p_i=\text{softmax}(z_i) = {e^{z_i}\over \sum^n_{j=1}e^{z_j}}\end{split}
\end{equation*}
\sphinxAtStartPar
The softmax function has been used in GPT in two ways:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Probability Distribution}: It converts raw scores into
probabilities that sum to 1. Next token as prediction will be the
token with the highest probability.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Attention Weights}: In attention mechanism, softmax is applied to
the score of all tokens in the sequence to normalize them into
attention weights.

\end{itemize}

\sphinxAtStartPar
Properties of Softmax:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Exponentiation}: Amplifies the difference between higher and lower
scores, making the largest score dominate.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Normalization}: Ensures that the output probabilities sum to 1.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Differentiable}: Enables backpropagation for training the model.

\end{itemize}

\sphinxAtStartPar
The \sphinxstylestrong{temperature} parameter is used in the softmax function to control
the sharpness or smoothness of the probability distribution over the
logits, affecting how confident or diverse the model’s predictions are.
When using a temperature \(T > 0\), the logits are scaled by
\(\frac{1}{T}\) before applying softmax:
\begin{equation*}
\begin{split}p_i = \text{softmax}(z_i) = {\exp(z_i/T)\over \sum^n_{j=1}\exp(z_j/T)}\end{split}
\end{equation*}
\sphinxAtStartPar
When \(T\) is larger, more weight is given to the lower values, then
the distribution is more uniform. If \(T\) is smaller, the biggest
logit score will dominate more aggresively. Setting \(T=0\) gives
all the weights to the maximum value resulting a \textasciitilde{}100\% probability.


\subsection{Unembedding Matrix}
\label{\detokenize{pretraining:unembedding-matrix}}
\sphinxAtStartPar
The \sphinxstylestrong{unembedding matrix} in the final layer of GPT is the counterpart
to the \sphinxstylestrong{embedding matrix} used at the input layer. GPT’s final hidden
layer outputs continuous vectors for each token position in the input
sequence. The unembedding matrix projects these vectors into a space
where each dimension corresponds to a token in the vocabulary, producing
logits for all vocabulary tokens.

\sphinxAtStartPar
The unembedding matrix is not randomly initialized, instead, it’s
initialized as the transpose of the embedding matrix
\(W_U = W_E^T\). If the vocabulary size is \(V\) and the hidden
layer size is \(d\), the unembedding matrix \(W_U\) has
dimensions \(V \times d\). In the final layer, GPT produces a hidden
state \(h\) with size \(d\) for each token position. The
unembedding matrix is applied as follows.
\begin{equation*}
\begin{split}\text{Logits} = h \cdot W_U^T\end{split}
\end{equation*}
\sphinxAtStartPar
The logits are passed through the \sphinxstylestrong{softmax function} to generate
probabilities over the vocabulary. The token with the highest
probability (or sampled stochastically) is chosen as the next token.

\sphinxAtStartPar
Using a learned unembedding matrix to compute logits in the final layer
of GPT offers critical advantages over directly computing logits from
the final hidden vector without this additional projection step:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The embedding and unembedding matrices establish a connection between
the input and output token spaces. Without an unembedding matrix,
there would be no learned mechanism to align the model’s internal
representation to the specific vocabulary used for prediction.

\item {} 
\sphinxAtStartPar
The model’s hidden states are designed to represent rich features of
the input sequence rather than being explicitly tied to the vocabulary
size. The unembedding matrix translates the compressed hidden state
(e.g. 768 or 1024 size) into a vocabulary distribution (e.g. \textasciitilde{}50k
tokens), ensuring the model can scale to larger vocabularies or output
spaces.

\item {} 
\sphinxAtStartPar
The unembedding matrix learns how to transform these rich
representations into logits that accurately reflect token
probabilities in the specific vocabulary. It provides a structured way
for gradients from the loss function (e.g., cross\sphinxhyphen{}entropy loss) to
update both the model’s hidden representations and the vocabulary
mappings.

\end{itemize}


\subsection{Decoding}
\label{\detokenize{pretraining:decoding}}
\sphinxAtStartPar
In transformer models, \sphinxstylestrong{decoding} refers to the process of generating
output sequences from a model’s learned representations. Decoder takes
the hidden state generated by encoder from input representations as well
as previously generated tokens (or a start token) and progressively
generates the output sequence one by one based on the probability
distribution over all possible words in the vocabulary for the next
token.

\sphinxAtStartPar
Depending on the specific task and goals (e.g., translation, generation,
or summarization), different decoding strategies like \sphinxstylestrong{beam search},
\sphinxstylestrong{top\sphinxhyphen{}k sampling}, \sphinxstylestrong{top\sphinxhyphen{}p sampling}, and \sphinxstylestrong{temperature sampling} can
be used to strike the right balance between creativity and accuracy.


\subsubsection{Greedy Decoding}
\label{\detokenize{pretraining:greedy-decoding}}
\sphinxAtStartPar
Greedy decoding is the simplest and most straightforward method. At each
time step, the model chooses the token with the highest probability from
the predicted distribution and adds it to the output sequence.


\subsubsection{Beam Search}
\label{\detokenize{pretraining:beam-search}}
\sphinxAtStartPar
Beam search is a more advanced method than greedy decoding. It keeps
track of multiple hypotheses at each decoding step (instead of just the
most probable one) and selects the top\sphinxhyphen{}k most likely sequences (called
the “beam width”).

\sphinxAtStartPar
At each decoding step, beam search explores the top\sphinxhyphen{}k candidate
sequences (instead of just one) and chooses the one with the highest
cumulative probability. A hyperparameter, \sphinxstylestrong{beam width}, controls how
many candidate sequences are considered at each step.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{beam_search}.png}
\caption{Beam Search}\label{\detokenize{pretraining:id12}}\end{figure}


\subsubsection{Summary}
\label{\detokenize{pretraining:summary-1}}\label{\detokenize{pretraining:id2}}

\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Method
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Advantages
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Disadvantages
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Use Cases
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
Greedy
Decoding
&
\sphinxAtStartPar
Simple, fast,
deterministic
&
\sphinxAtStartPar
May produce
repetitive or
suboptimal
sequences
&
\sphinxAtStartPar
When speed is
important, low
diversity tasks
\\
\sphinxhline
\sphinxAtStartPar
Beam
Search
&
\sphinxAtStartPar
Produces
higher\sphinxhyphen{}quality
sequences, less
repetitive
&
\sphinxAtStartPar
Computationally
expensive,
limited by beam
width
&
\sphinxAtStartPar
Machine
translation,
summarization
\\
\sphinxhline
\sphinxAtStartPar
Top\sphinxhyphen{}k
Sampling
&
\sphinxAtStartPar
Adds diversity,
avoids repetitive
output
&
\sphinxAtStartPar
May reduce
coherence in
some cases
&
\sphinxAtStartPar
Creative text
generation,
storytelling
\\
\sphinxhline
\sphinxAtStartPar
Top\sphinxhyphen{}p
Sampling
&
\sphinxAtStartPar
Dynamically adjusts
for diversity, more
natural
&
\sphinxAtStartPar
May still
produce
incoherent
outputs
&
\sphinxAtStartPar
Creative text
generation,
dialogue systems
\\
\sphinxhline
\sphinxAtStartPar
Temperature
Sampling
&
\sphinxAtStartPar
Fine control over
and diversity
randomness, balance
between coherence
&
\sphinxAtStartPar
Requires tuning
for optimal
results
&
\sphinxAtStartPar
Creative text
randomness
generation,
fine\sphinxhyphen{}tuning output
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\section{Modern Transformer Techniques}
\label{\detokenize{pretraining:modern-transformer-techniques}}

\subsection{KV Cache}
\label{\detokenize{pretraining:kv-cache}}
\sphinxAtStartPar
The primary purpose of the KV cache is to \sphinxstylestrong{speed up the inference
process} and make it more efficient. Specifically, during
autoregressive generation (such as generating text one token at a time),
the transformer model processes the input tokens sequentially, which
means that for each new token, it needs to compute the attention scores
between the current token and all previous tokens.

\sphinxAtStartPar
Instead of recalculating the \sphinxstylestrong{key (K)} and \sphinxstylestrong{value (V)} vectors for
the entire sequence at each step (which would be computationally
expensive), the KV cache allows the model to \sphinxstylestrong{reuse the keys and
values} from previous tokens, thus reducing redundant computations.

\sphinxAtStartPar
As demonstrated in the diagram below, during the training process,
attention scores are calculated by this formula without KV Cache:
\begin{equation*}
\begin{split}\text{Attention Weights} = \text{softmax}\Big({QK^T\over{\sqrt{d_k}}}\Big)\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxincludegraphics{{qkv_attention_pattern}.png}

\sphinxAtStartPar
When generating the next token during inference, the model doesn’t need
to recompute the keys and values for the tokens it has already
processed. Instead, it simply retrieves the stored keys and values from
the cache for all previously generated tokens. Only the new token’s key
and value are computed for the current timestep and added to the cache.

\sphinxAtStartPar
During the attention computation for each new token, the model uses both
the new key and value (for the current token) and the cached keys and
values (for all previous tokens). This way, the attention mechanism can
still compute the correct attention scores and weighted sums without
recalculating everything from scratch.

\sphinxAtStartPar
\sphinxstylestrong{The attention formula with Cache:} for a new token \(t\),
\begin{equation*}
\begin{split}\text{Attention Output} = \text{softmax} \Big({Q_t \cdot [K_{\text{cache}}, K_t]^T\over \sqrt{d_k}}\Big) \cdot [V_{\text{cache}}, V_t]\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxincludegraphics{{kv_cache}.png}

\sphinxAtStartPar
\sphinxstylestrong{Why Not Cache Queries:} \sphinxstylestrong{Queries} are specific to the token being
processed at the current step of generation. For every new token in
autoregressive decoding, the query vector needs to be freshly computed
because it is derived from the embedding of the current token. Keys and
values, on the other hand, represent the context of the previous tokens,
which remains the same across multiple steps until the sequence is
extended.

\sphinxAtStartPar
\sphinxstylestrong{Space complexity of KV Cache is huge without optimization}: The space
complexity is calculated by number of layers * number of batch size * number
of attention heads * attention head size * sequence length.

\sphinxAtStartPar
Space complexity can be optimized by reducing “number of attention
heads” without too much penalty on performance.


\subsection{Multi\sphinxhyphen{}Query Attention}
\label{\detokenize{pretraining:multi-query-attention}}
\sphinxAtStartPar
\sphinxstylestrong{Multi\sphinxhyphen{}Query Attention (MQA)} is a variant of the attention mechanism
introduced to improve the efficiency of transformer models, particularly
in scenarios where decoding speed and memory usage are critical. It
modifies the standard multi\sphinxhyphen{}head attention by using multiple query heads
but sharing the key and value matrices across all the heads. There are
still multiple independent query heads (\(Q\)), but the \sphinxstylestrong{key
(:math:\textasciigrave{}K\textasciigrave{}) and value (:math:\textasciigrave{}V\textasciigrave{}) matrices are shared} across all the
heads.

\sphinxAtStartPar
Each query head \(i\) computes its attention scores with the shared
key matrix:
\begin{equation*}
\begin{split}\text{Attention}_i = \text{softmax} \Big({Q_i K^T \over \sqrt{d_k}}\Big)V\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{multiquery_attention}.png}
\caption{Multi\sphinxhyphen{}Query Attention}\label{\detokenize{pretraining:id13}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Advantages of MQA:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Efficiency in Memory Usage}: By sharing the \(K\) and \(V\)
matrices across heads, the memory footprint is reduced, particularly
for the KV cache used during autoregressive generation in large
models. This is especially valuable for serving large\sphinxhyphen{}scale language
models with limited GPU/TPU memory.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Faster Decoding}: During autoregressive decoding (e.g., in GPT\sphinxhyphen{}like
models), each query needs to attend to the cached keys and values. In
standard multi\sphinxhyphen{}head attention, this involves accessing multiple
\(K\) and \(V\) matrices, which can slow down decoding. In
MQA, since only one shared \(K\) and \(V\) matrix is used, the
decoding process is faster and more streamlined

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Minimal Performance Tradeoff}: Despite simplifying the model, MQA
often achieves comparable performance to standard multi\sphinxhyphen{}head attention
in many tasks, particularly in large\sphinxhyphen{}scale language models.

\end{itemize}


\subsection{Grouped\sphinxhyphen{}Query Attention}
\label{\detokenize{pretraining:grouped-query-attention}}
\sphinxAtStartPar
\sphinxstylestrong{Grouped\sphinxhyphen{}Query Attention (GQA)} is a hybrid approach between
\sphinxstylestrong{Multi\sphinxhyphen{}Head Attention (MHA)} and \sphinxstylestrong{Multi\sphinxhyphen{}Query Attention (MQA)} that
balances computational efficiency and expressivity. In GQA, multiple
query heads are grouped together, and each group shares a set of
\sphinxstylestrong{keys} and \sphinxstylestrong{values}. This design seeks to retain some of the
flexibility of MHA while reducing the memory and computational overhead,
similar to MQA.

\sphinxAtStartPar
Mathematically, if there are \(G\) groups, each with \(H / G\)
heads, the queries are processed independently for each group but share
keys and values within the group:
\begin{equation*}
\begin{split}\text{Attention}_i = \text{softmax} \Big({Q_i K^T_{\text{group,i}}\over \sqrt{d_k}}\Big) V_{group,i}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(i\) is the query head within a group.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{grouped_query_attention}.png}
\caption{Grouped Query Attention}\label{\detokenize{pretraining:id14}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Advantages of GQA:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Efficiency}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Reduced KV Cache Size: GQA requires fewer key and value matrices
compared to MHA. This reduces memory usage, especially during
autoregressive decoding when keys and values for all previous tokens
are stored in a cache.

\item {} 
\sphinxAtStartPar
Faster Inference: By reducing the number of keys and values to
process, GQA speeds up attention computations during decoding,
particularly in long\sphinxhyphen{}sequence tasks.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Balance Between Flexibility and Efficiency}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
More Expressivity Than MQA: Unlike MQA, where all heads share the
same keys and values, GQA allows multiple groups of keys and values,
enabling more flexibility for the attention mechanism to learn
diverse patterns.

\item {} 
\sphinxAtStartPar
Simpler Than MHA: GQA is less computationally expensive and
memory\sphinxhyphen{}intensive than MHA, as fewer sets of keys and values are
used.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Scalability}:
\begin{itemize}
\item {} 
\sphinxAtStartPar
GQA is well\sphinxhyphen{}suited for very large models and long\sphinxhyphen{}sequence tasks
where standard MHA becomes computationally and memory prohibitive.

\end{itemize}

\end{itemize}


\subsection{Flash Attention}
\label{\detokenize{pretraining:flash-attention}}
\sphinxstepscope


\chapter{LLM Evaluation Metrics}
\label{\detokenize{evaluation:llm-evaluation-metrics}}\label{\detokenize{evaluation:evaluation}}\label{\detokenize{evaluation::doc}}
\begin{sphinxadmonition}{note}{Colab Notebook for This Chapter}

\sphinxAtStartPar
GEval with DeepEval: \sphinxhref{https://colab.research.google.com/drive/17aARKonCOzBzsfk1ceLESTboEPkKNJi1?usp=drive\_link}{\sphinxincludegraphics{{colab-badge}.png}}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{metrics_llm}.png}
\caption{Types of metric scorers (Source: \sphinxhref{https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation}{LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide})}\label{\detokenize{evaluation:id3}}\label{\detokenize{evaluation:fig-metrics-llm}}\end{figure}


\section{Statistical Scorers (Traditional Metrics)}
\label{\detokenize{evaluation:statistical-scorers-traditional-metrics}}
\sphinxAtStartPar
These metrics evaluate text outputs based on statistical comparisons to references
or expected outputs.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
I completely agree with the author of \sphinxhref{https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation}{LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide}
that statistical scoring methods are,
in my opinion, non\sphinxhyphen{}essential to focus on. These methods tend to perform poorly
whenever reasoning is required, making them too inaccurate as scorers for
most LLM evaluation criteria. Additionally, more advanced metrics,
such as GEval {\hyperref[\detokenize{evaluation:sec-geval}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{GEval with DeepEval}}}}}, provide significantly better alternatives.
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{BLEU (Bilingual Evaluation Understudy):}
Measures overlap of n\sphinxhyphen{}grams between generated and reference texts.
Common for translation tasks.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{ROUGE (Recall\sphinxhyphen{}Oriented Understudy for Gisting Evaluation):}
Focuses on recall of n\sphinxhyphen{}grams (ROUGE\sphinxhyphen{}N), longest common subsequences (ROUGE\sphinxhyphen{}L),
and skip bigrams (ROUGE\sphinxhyphen{}S). Popular in summarization tasks.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{METEOR (Metric for Evaluation of Translation with Explicit ORdering):}
Considers synonymy and paraphrasing via stemming and synonym matching.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{TER (Translation Edit Rate):}
Measures the number of edits required to turn the generated output into the
reference text.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{CIDEr (Consensus\sphinxhyphen{}based Image Description Evaluation):}
Designed for image captioning, using TF\sphinxhyphen{}IDF weighting of n\sphinxhyphen{}grams.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{BERTScore:}
Leverages contextual embeddings (e.g., BERT) to compute similarity between
generated and reference texts.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{GLEU (Google BLEU):}
A variation of BLEU designed for grammatical error correction tasks.

\end{itemize}


\section{Model\sphinxhyphen{}Based Scorers (Learned Metrics)}
\label{\detokenize{evaluation:model-based-scorers-learned-metrics}}
\sphinxAtStartPar
These metrics employ models trained to assess the quality of generated text,
often based on human annotations.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{BLEURT:}
Combines pre\sphinxhyphen{}trained models (e.g., BERT) with fine\sphinxhyphen{}tuning on human judgment data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{COMET (Cross\sphinxhyphen{}lingual Optimized Metric for Evaluation of Translation):}
A neural network model trained on translation quality data.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{PRISM:}
Measures semantic similarity by paraphrasing both the hypothesis and reference into a shared space.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{UniEval:}
A unified framework for evaluation across multiple tasks, focusing on both factual accuracy and linguistic quality.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Perplexity:}
Estimates the likelihood of generated text under the original model’s probability distribution (lower is better).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{GPTScore:}
Uses a large pre\sphinxhyphen{}trained LLM (e.g., GPT\sphinxhyphen{}4) to rate the quality of outputs.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{MAUVE:}
Measures the divergence between the distribution of generated text and that of human\sphinxhyphen{}written text.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{DRIFT:}
Focuses on domain\sphinxhyphen{}specific evaluation, checking how well outputs align with domain\sphinxhyphen{}specific data distributions.

\end{itemize}


\section{Human\sphinxhyphen{}Centric Evaluations (Augmenting Metrics)}
\label{\detokenize{evaluation:human-centric-evaluations-augmenting-metrics}}
\sphinxAtStartPar
While not automated, human evaluations are crucial for assessing subjective qualities such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Fluency}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Coherence}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Relevance}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Factuality}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Style Appropriateness}

\end{itemize}

\sphinxAtStartPar
Both statistical and model\sphinxhyphen{}based scorers are often used in tandem with human evaluation to ensure a holistic assessment of LLM outputs.


\section{GEval with DeepEval}
\label{\detokenize{evaluation:geval-with-deepeval}}\label{\detokenize{evaluation:sec-geval}}
\sphinxAtStartPar
G\sphinxhyphen{}Eval is a recently developed evaluation framework developed from paper \sphinxcite{reference:geval} to assess large language models (LLMs) using GPT\sphinxhyphen{}based evaluators.
It leverages the capabilities of advanced LLMs (like GPT\sphinxhyphen{}4 or beyond) to rate and critique the outputs of other models, including themselves,
across various tasks. This approach shifts the evaluation paradigm by relying on the intrinsic understanding and reasoning power of the models,
rather than traditional metrics.


\subsection{G\sphinxhyphen{}Eval Algorithm}
\label{\detokenize{evaluation:g-eval-algorithm}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{geval}.png}
\caption{G\sphinxhyphen{}Eval Algorithm (Source: \sphinxcite{reference:geval})}\label{\detokenize{evaluation:id4}}\label{\detokenize{evaluation:fig-geval}}\end{figure}


\subsection{G\sphinxhyphen{}Eval with DeepEval}
\label{\detokenize{evaluation:g-eval-with-deepeval}}
\sphinxAtStartPar
In \sphinxhref{https://docs.confident-ai.com/docs/metrics-introduction}{DeepEval},, a metric serves as a standard for measuring the performance
of an LLM’s output based on specific criteria of interest. Essentially,
while the metric functions as the “ruler”, a test case represents the
subject being measured. \sphinxhref{https://docs.confident-ai.com/docs/metrics-introduction}{DeepEval}, provides a variety of default metrics
to help you get started quickly, including:
\begin{itemize}
\item {} 
\sphinxAtStartPar
G\sphinxhyphen{}Eval

\item {} 
\sphinxAtStartPar
Summarization

\item {} 
\sphinxAtStartPar
Faithfulness

\item {} 
\sphinxAtStartPar
Answer Relevancy

\item {} 
\sphinxAtStartPar
Contextual Relevancy

\item {} 
\sphinxAtStartPar
Contextual Precision

\item {} 
\sphinxAtStartPar
Contextual Recall

\item {} 
\sphinxAtStartPar
Ragas

\item {} 
\sphinxAtStartPar
Hallucination

\item {} 
\sphinxAtStartPar
Toxicity

\item {} 
\sphinxAtStartPar
Bias

\end{itemize}

\sphinxAtStartPar
DeepEval also provides conversational metrics, designed to evaluate entire
conversations rather than individual, granular LLM interactions. These include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Conversation Completeness

\item {} 
\sphinxAtStartPar
Conversation Relevancy

\item {} 
\sphinxAtStartPar
Knowledge Retention

\end{itemize}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Set Up Local Model}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{deepeval} \PYG{n+nb}{set}\PYG{o}{\PYGZhy{}}\PYG{n}{local}\PYG{o}{\PYGZhy{}}\PYG{n}{model} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{model}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mistral}\PYG{l+s+s1}{\PYGZsq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{base}\PYG{o}{\PYGZhy{}}\PYG{n}{url}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{http://localhost:11434/v1/}\PYG{l+s+s2}{\PYGZdq{}} \PYGZbs{}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{api}\PYG{o}{\PYGZhy{}}\PYG{n}{key}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ollama}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}
\end{quote}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Default Metrics}
\begin{itemize}
\item {} 
\sphinxAtStartPar
AnswerRelevancyMetric
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval} \PYG{k+kn}{import} \PYG{n}{evaluate}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{AnswerRelevancyMetric}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCase}

\PYG{n}{answer\PYGZus{}relevancy\PYGZus{}metric} \PYG{o}{=} \PYG{n}{AnswerRelevancyMetric}\PYG{p}{(}\PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{)}
\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What if these shoes don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t fit?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{} Replace this with the actual output from your LLM application}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{We offer a 30\PYGZhy{}day full refund at no extra costs.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{All customers are eligible for a 30 day full refund at no extra costs.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{p}{)}
\PYG{n}{evaluate}\PYG{p}{(}\PYG{p}{[}\PYG{n}{test\PYGZus{}case}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{answer\PYGZus{}relevancy\PYGZus{}metric}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Metrics Summary
\begin{itemize}
\item {} 
\sphinxAtStartPar
Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: local model,
reason: The score is 1.00 because it directly and accurately answered the question about
shoe fitting, making it highly relevant., error: None)

\end{itemize}

\item {} 
\sphinxAtStartPar
For test case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
input: What if these shoes don’t fit?

\item {} 
\sphinxAtStartPar
actual output: We offer a 30\sphinxhyphen{}day full refund at no extra costs.

\item {} 
\sphinxAtStartPar
expected output: None

\item {} 
\sphinxAtStartPar
context: None

\item {} 
\sphinxAtStartPar
retrieval context: {[}‘All customers are eligible for a 30 day full refund at no extra costs.’{]}

\end{itemize}

\item {} 
\sphinxAtStartPar
Overall Metric Pass Rates
\begin{quote}

\sphinxAtStartPar
Answer Relevancy: 100.00\% pass rate
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EvaluationResult}\PYG{p}{(}\PYG{n}{test\PYGZus{}results}\PYG{o}{=}\PYG{p}{[}\PYG{n}{TestResult}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{test\PYGZus{}case\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{success}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{metrics\PYGZus{}data}\PYG{o}{=}\PYG{p}{[}\PYG{n}{MetricData}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Answer Relevancy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,} \PYG{n}{success}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{score}\PYG{o}{=}\PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{n}{reason}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The score is 1.00 because it directly and accurately answered the question about shoe fitting, making it highly relevant.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{strict\PYGZus{}mode}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{evaluation\PYGZus{}model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{local model}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{error}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{evaluation\PYGZus{}cost}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{verbose\PYGZus{}logs}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Statements:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{We offer a 30\PYGZhy{}day full refund}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The refund does not incur any additional costs}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{] }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Verdicts:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{verdict}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{reason}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The statements about the refund policy are relevant to addressing the input, which asks about what to do if the shoes don}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{t fit.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{},}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{verdict}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{reason}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The statement that the refund does not incur any additional costs is also relevant as it provides further information about the refund process.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{conversational}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{multimodal}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n+nb}{input}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What if these shoes don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t fit?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{We offer a 30\PYGZhy{}day full refund at no extra costs.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{context}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{All customers are eligible for a 30 day full refund at no extra costs.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{confident\PYGZus{}link}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
\end{sphinxVerbatim}
\end{quote}

\item {} 
\sphinxAtStartPar
FaithfulnessMetric
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval} \PYG{k+kn}{import} \PYG{n}{evaluate}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{FaithfulnessMetric}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCase}


\PYG{c+c1}{\PYGZsh{} input}
\PYG{n+nb}{input} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What if these shoes don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t fit?}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Replace this with the actual output from your LLM application}
\PYG{n}{actual\PYGZus{}output} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{We offer a 30\PYGZhy{}day full refund at no extra cost.}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Replace this with the actual retrieved context from your RAG pipeline}
\PYG{n}{retrieval\PYGZus{}context} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{All customers are eligible for a 30 day full refund at no extra cost.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{n}{metric} \PYG{o}{=} \PYG{n}{FaithfulnessMetric}\PYG{p}{(}
    \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{}model=\PYGZdq{}gpt\PYGZhy{}4\PYGZdq{},}
    \PYG{n}{include\PYGZus{}reason}\PYG{o}{=}\PYG{k+kc}{True}
\PYG{p}{)}
\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=}\PYG{n+nb}{input}\PYG{p}{,}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{n}{actual\PYGZus{}output}\PYG{p}{,}
    \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{n}{retrieval\PYGZus{}context}
\PYG{p}{)}

\PYG{n}{metric}\PYG{o}{.}\PYG{n}{measure}\PYG{p}{(}\PYG{n}{test\PYGZus{}case}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{score}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{reason}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} or evaluate test cases in bulk}
\PYG{n}{evaluate}\PYG{p}{(}\PYG{p}{[}\PYG{n}{test\PYGZus{}case}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{metric}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Metrics Summary
\begin{itemize}
\item {} 
\sphinxAtStartPar
Faithfulness (score: 1.0, threshold: 0.7, strict: False, evaluation model:
local model, reason: The faithfulness score is 1.00 because there are no
contradictions found between the actual output and the retrieval context., error: None)

\end{itemize}

\item {} 
\sphinxAtStartPar
For test case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
input: What if these shoes don’t fit?

\item {} 
\sphinxAtStartPar
actual output: We offer a 30\sphinxhyphen{}day full refund at no extra cost.

\item {} 
\sphinxAtStartPar
expected output: None

\item {} 
\sphinxAtStartPar
context: None

\item {} 
\sphinxAtStartPar
retrieval context: {[}‘All customers are eligible for a 30 day full refund at no extra cost.’{]}

\end{itemize}

\item {} 
\sphinxAtStartPar
Overall Metric Pass Rates
\begin{quote}

\sphinxAtStartPar
Faithfulness: 100.00\% pass rate
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EvaluationResult}\PYG{p}{(}\PYG{n}{test\PYGZus{}results}\PYG{o}{=}\PYG{p}{[}\PYG{n}{TestResult}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{test\PYGZus{}case\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{success}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{metrics\PYGZus{}data}\PYG{o}{=}\PYG{p}{[}\PYG{n}{MetricData}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Faithfulness}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,} \PYG{n}{success}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{score}\PYG{o}{=}\PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{n}{reason}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The faithfulness score is 1.00 because there are no contradictions found between the actual output and the retrieval context.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{strict\PYGZus{}mode}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{evaluation\PYGZus{}model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{local model}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{error}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{evaluation\PYGZus{}cost}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{verbose\PYGZus{}logs}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Truths (limit=None):}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Customers are eligible for a 30 day full refund.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The refund is at no extra cost.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{] }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Claims:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The refund is offered for a period of 30 days.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{The refund does not incur any additional costs.}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{] }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Verdicts:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{verdict}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{reason}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: null}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{},}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{verdict}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{yes}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{        }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{reason}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{: null}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    \PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{conversational}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{multimodal}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n+nb}{input}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What if these shoes don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t fit?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{We offer a 30\PYGZhy{}day full refund at no extra cost.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{context}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{All customers are eligible for a 30 day full refund at no extra cost.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{confident\PYGZus{}link}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
\end{sphinxVerbatim}
\end{quote}

\item {} 
\sphinxAtStartPar
ContextualPrecisionMetric
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval} \PYG{k+kn}{import} \PYG{n}{evaluate}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{ContextualPrecisionMetric}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCase}

\PYG{c+c1}{\PYGZsh{} input}
\PYG{n+nb}{input} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What if these shoes don}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{t fit?}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Replace this with the actual output from your LLM application}
\PYG{n}{actual\PYGZus{}output} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{We offer a 30\PYGZhy{}day full refund at no extra cost.}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Replace this with the expected output from your RAG generator}
\PYG{n}{expected\PYGZus{}output} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{You are eligible for a 30 day full refund at no extra cost.}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Replace this with the actual retrieved context from your RAG pipeline}
\PYG{n}{retrieval\PYGZus{}context} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{All customers are eligible for a 30 day full refund at no extra cost.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{n}{metric} \PYG{o}{=} \PYG{n}{ContextualPrecisionMetric}\PYG{p}{(}
    \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{}model=\PYGZdq{}gpt\PYGZhy{}4\PYGZdq{},}
    \PYG{n}{include\PYGZus{}reason}\PYG{o}{=}\PYG{k+kc}{True}
\PYG{p}{)}
\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=}\PYG{n+nb}{input}\PYG{p}{,}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{n}{actual\PYGZus{}output}\PYG{p}{,}
    \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{n}{expected\PYGZus{}output}\PYG{p}{,}
    \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{n}{retrieval\PYGZus{}context}
\PYG{p}{)}

\PYG{n}{metric}\PYG{o}{.}\PYG{n}{measure}\PYG{p}{(}\PYG{n}{test\PYGZus{}case}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{score}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{reason}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} or evaluate test cases in bulk}
\PYG{n}{evaluate}\PYG{p}{(}\PYG{p}{[}\PYG{n}{test\PYGZus{}case}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{metric}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Metrics Summary
\begin{itemize}
\item {} 
\sphinxAtStartPar
Contextual Precision (score: 1.0, threshold: 0.7, strict: False, evaluation
model: local model, reason: The contextual precision score is 1.00 because
the node ranked first (with reason: ‘The text verifies that customers are
indeed eligible for a 30 day full refund at no extra cost.’) is relevant
and correctly placed as the highest\sphinxhyphen{}ranked response to the input
‘What if these shoes don’t fit?’. All other nodes, if present,
should be ranked lower due to their irrelevance to the question., error: None)

\end{itemize}

\item {} 
\sphinxAtStartPar
For test case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
input: What if these shoes don’t fit?

\item {} 
\sphinxAtStartPar
actual output: We offer a 30\sphinxhyphen{}day full refund at no extra cost.

\item {} 
\sphinxAtStartPar
expected output: You are eligible for a 30 day full refund at no extra cost.

\item {} 
\sphinxAtStartPar
context: None

\item {} 
\sphinxAtStartPar
retrieval context: {[}‘All customers are eligible for a 30 day full refund at no extra cost.’{]}

\end{itemize}

\item {} 
\sphinxAtStartPar
Overall Metric Pass Rates
\begin{itemize}
\item {} 
\sphinxAtStartPar
Contextual Precision: 100.00\% pass rate

\end{itemize}

\end{itemize}
\end{quote}

\item {} 
\sphinxAtStartPar
ContextualRecallMetric
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval} \PYG{k+kn}{import} \PYG{n}{evaluate}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{ContextualRecallMetric}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCase}

\PYG{n}{metric} \PYG{o}{=} \PYG{n}{ContextualRecallMetric}\PYG{p}{(}
    \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}
    \PYG{n}{model}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{gpt\PYGZhy{}4}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{include\PYGZus{}reason}\PYG{o}{=}\PYG{k+kc}{True}
\PYG{p}{)}
\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=}\PYG{n+nb}{input}\PYG{p}{,}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{n}{actual\PYGZus{}output}\PYG{p}{,}
    \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{n}{expected\PYGZus{}output}\PYG{p}{,}
    \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{n}{retrieval\PYGZus{}context}
\PYG{p}{)}

\PYG{n}{metric}\PYG{o}{.}\PYG{n}{measure}\PYG{p}{(}\PYG{n}{test\PYGZus{}case}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{score}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{reason}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} or evaluate test cases in bulk}
\PYG{n}{evaluate}\PYG{p}{(}\PYG{p}{[}\PYG{n}{test\PYGZus{}case}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{metric}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Metrics Summary
\begin{itemize}
\item {} 
\sphinxAtStartPar
Contextual Recall (score: 1.0, threshold: 0.7, strict: False, evaluation
model: local model, reason: The score is 1.00 because the expected output
is exactly as stated in the retrieval context., error: None)

\end{itemize}

\item {} 
\sphinxAtStartPar
For test case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
input: What if these shoes don’t fit?

\item {} 
\sphinxAtStartPar
actual output: We offer a 30\sphinxhyphen{}day full refund at no extra cost.

\item {} 
\sphinxAtStartPar
expected output: You are eligible for a 30 day full refund at no extra cost.

\item {} 
\sphinxAtStartPar
context: None

\item {} 
\sphinxAtStartPar
retrieval context: {[}‘All customers are eligible for a 30 day full refund at no extra cost.’{]}

\end{itemize}

\item {} 
\sphinxAtStartPar
Overall Metric Pass Rates
\begin{itemize}
\item {} 
\sphinxAtStartPar
Contextual Recall: 100.00\% pass rate

\end{itemize}

\end{itemize}
\end{quote}

\item {} 
\sphinxAtStartPar
HallucinationMetric
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval} \PYG{k+kn}{import} \PYG{n}{evaluate}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{HallucinationMetric}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCase}

\PYG{c+c1}{\PYGZsh{} input}

\PYG{n+nb}{input} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{What was the blond doing?}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Replace this with the actual documents that you are passing as input to your LLM.}
\PYG{n}{context}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{A man with blond\PYGZhy{}hair, and a brown shirt drinking out of a public water fountain.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Replace this with the actual output from your LLM application}
\PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{A blond drinking water in public.}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=} \PYG{n+nb}{input}\PYG{p}{,}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{n}{actual\PYGZus{}output}\PYG{p}{,}
    \PYG{n}{context}\PYG{o}{=}\PYG{n}{context}
\PYG{p}{)}
\PYG{n}{metric} \PYG{o}{=} \PYG{n}{HallucinationMetric}\PYG{p}{(}\PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}

\PYG{n}{metric}\PYG{o}{.}\PYG{n}{measure}\PYG{p}{(}\PYG{n}{test\PYGZus{}case}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{score}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{metric}\PYG{o}{.}\PYG{n}{reason}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} or evaluate test cases in bulk}
\PYG{n}{evaluate}\PYG{p}{(}\PYG{p}{[}\PYG{n}{test\PYGZus{}case}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{metric}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Metrics Summary
\begin{itemize}
\item {} 
\sphinxAtStartPar
Hallucination (score: 0.0, threshold: 0.5, strict: False,
evaluation model: local model, reason: The score is 0.00 because the actual
output correctly aligns with the provided context., error: None)

\end{itemize}

\item {} 
\sphinxAtStartPar
For test case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
input: What was the blond doing?

\item {} 
\sphinxAtStartPar
actual output: A blond drinking water in public.

\item {} 
\sphinxAtStartPar
expected output: None

\item {} 
\sphinxAtStartPar
context: {[}‘A man with blond\sphinxhyphen{}hair, and a brown shirt drinking out of a public water fountain.’{]}

\item {} 
\sphinxAtStartPar
retrieval context: None

\end{itemize}

\item {} 
\sphinxAtStartPar
Overall Metric Pass Rates
\begin{quote}

\sphinxAtStartPar
Hallucination: 100.00\% pass rate
\end{quote}

\end{itemize}
\end{quote}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Custom Metrics}
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{GEval}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCaseParams}

\PYG{n}{correctness\PYGZus{}metric} \PYG{o}{=} \PYG{n}{GEval}\PYG{p}{(}
    \PYG{n}{name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Correctness}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{criteria}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Determine whether the actual output is factually correct based on the expected output.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{} NOTE: you can only provide either criteria or evaluation\PYGZus{}steps, and not both}
    \PYG{n}{evaluation\PYGZus{}steps}\PYG{o}{=}\PYG{p}{[}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Check whether the facts in }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{actual output}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ contradicts any facts in }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{expected output}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{You should also heavily penalize omission of detail}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Vague language, or contradicting OPINIONS, are OK}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{p}{]}\PYG{p}{,}
    \PYG{n}{evaluation\PYGZus{}params}\PYG{o}{=}\PYG{p}{[}\PYG{n}{LLMTestCaseParams}\PYG{o}{.}\PYG{n}{INPUT}\PYG{p}{,} \PYG{n}{LLMTestCaseParams}\PYG{o}{.}\PYG{n}{ACTUAL\PYGZus{}OUTPUT}\PYG{p}{,} \PYG{n}{LLMTestCaseParams}\PYG{o}{.}\PYG{n}{EXPECTED\PYGZus{}OUTPUT}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The dog chased the cat up the tree, who ran up the tree?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{It depends, some might consider the cat, while others might argue the dog.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The cat.}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}

\PYG{n}{correctness\PYGZus{}metric}\PYG{o}{.}\PYG{n}{measure}\PYG{p}{(}\PYG{n}{test\PYGZus{}case}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{correctness\PYGZus{}metric}\PYG{o}{.}\PYG{n}{score}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{correctness\PYGZus{}metric}\PYG{o}{.}\PYG{n}{reason}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Event} \PYG{n}{loop} \PYG{o+ow}{is} \PYG{n}{already} \PYG{n}{running}\PYG{o}{.} \PYG{n}{Applying} \PYG{n}{nest\PYGZus{}asyncio} \PYG{n}{patch} \PYG{n}{to} \PYG{n}{allow} \PYG{k}{async} \PYG{n}{execution}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{l+m+mf}{0.1}
\PYG{n}{The} \PYG{n}{actual} \PYG{n}{output} \PYG{n}{does} \PYG{o+ow}{not} \PYG{n}{match} \PYG{n}{the} \PYG{n}{expected} \PYG{n}{output} \PYG{o+ow}{and} \PYG{n}{omits} \PYG{n}{specific} \PYG{n}{details} \PYG{n}{about} \PYG{n}{which} \PYG{n}{animal} \PYG{n}{climbed} \PYG{n}{the} \PYG{n}{tree}\PYG{o}{.}
\end{sphinxVerbatim}
\end{quote}

\end{itemize}

\sphinxAtStartPar
Evaluation Framework:
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{deepeval} \PYG{k+kn}{import} \PYG{n}{evaluate}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{GEval}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCase}
\PYG{k+kn}{from} \PYG{n+nn}{deepeval}\PYG{n+nn}{.}\PYG{n+nn}{test\PYGZus{}case} \PYG{k+kn}{import} \PYG{n}{LLMTestCaseParams}

\PYG{n}{correctness\PYGZus{}metric} \PYG{o}{=} \PYG{n}{GEval}\PYG{p}{(}
    \PYG{n}{name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Correctness}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{criteria}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Determine whether the actual output is factually correct based on the expected output.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{c+c1}{\PYGZsh{} NOTE: you can only provide either criteria or evaluation\PYGZus{}steps, and not both}
    \PYG{n}{evaluation\PYGZus{}steps}\PYG{o}{=}\PYG{p}{[}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Check whether the facts in }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{actual output}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{ contradicts any facts in }\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{expected output}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{You should also heavily penalize omission of detail}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Vague language, or contradicting OPINIONS, are OK}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{p}{]}\PYG{p}{,}
    \PYG{n}{evaluation\PYGZus{}params}\PYG{o}{=}\PYG{p}{[}\PYG{n}{LLMTestCaseParams}\PYG{o}{.}\PYG{n}{INPUT}\PYG{p}{,} \PYG{n}{LLMTestCaseParams}\PYG{o}{.}\PYG{n}{ACTUAL\PYGZus{}OUTPUT}\PYG{p}{,} \PYG{n}{LLMTestCaseParams}\PYG{o}{.}\PYG{n}{EXPECTED\PYGZus{}OUTPUT}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{)}

\PYG{n}{test\PYGZus{}case} \PYG{o}{=} \PYG{n}{LLMTestCase}\PYG{p}{(}
    \PYG{n+nb}{input}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The dog chased the cat up the tree, who ran up the tree?}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{It depends, some might consider the cat, while others might argue the dog.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{The cat.}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{p}{)}

\PYG{n}{evaluate}\PYG{p}{(}\PYG{p}{[}\PYG{n}{test\PYGZus{}case}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{n}{correctness\PYGZus{}metric}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Metrics Summary
\begin{itemize}
\item {} 
\sphinxAtStartPar
Correctness (GEval) (score: 0.2, threshold: 0.5, strict: False, evaluation
model: local model, reason: Actual output omits the expected detail (the cat)
and contradicts the expected output., error: None)

\end{itemize}

\item {} 
\sphinxAtStartPar
For test case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
input: The dog chased the cat up the tree, who ran up the tree?

\item {} 
\sphinxAtStartPar
actual output: It depends, some might consider the cat, while others might argue the dog.

\item {} 
\sphinxAtStartPar
expected output: The cat.

\item {} 
\sphinxAtStartPar
context: None

\item {} 
\sphinxAtStartPar
retrieval context: None

\end{itemize}

\item {} 
\sphinxAtStartPar
Overall Metric Pass Rates
\begin{quote}

\sphinxAtStartPar
Correctness (GEval): 0.00\% pass rate
\end{quote}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EvaluationResult}\PYG{p}{(}\PYG{n}{test\PYGZus{}results}\PYG{o}{=}\PYG{p}{[}\PYG{n}{TestResult}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{test\PYGZus{}case\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{success}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{metrics\PYGZus{}data}\PYG{o}{=}\PYG{p}{[}\PYG{n}{MetricData}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Correctness (GEval)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{n}{success}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{score}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,} \PYG{n}{reason}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Actual output omits the expected detail (the cat) and contradicts the expected output.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{strict\PYGZus{}mode}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{evaluation\PYGZus{}model}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{local model}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{error}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{evaluation\PYGZus{}cost}\PYG{o}{=}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{n}{verbose\PYGZus{}logs}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Criteria:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Determine whether the actual output is factually correct based on the expected output. }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{ }\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Evaluation Steps:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{[}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Check whether the facts in }\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{actual output}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{ contradicts any facts in }\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{expected output}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{You should also heavily penalize omission of detail}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Vague language, or contradicting OPINIONS, are OK}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{conversational}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{multimodal}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n+nb}{input}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The dog chased the cat up the tree, who ran up the tree?}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{actual\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{It depends, some might consider the cat, while others might argue the dog.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{expected\PYGZus{}output}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{The cat.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{context}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{retrieval\PYGZus{}context}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{confident\PYGZus{}link}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
\end{sphinxVerbatim}
\end{quote}

\sphinxstepscope


\chapter{Main Reference}
\label{\detokenize{reference:main-reference}}\label{\detokenize{reference:reference}}\label{\detokenize{reference::doc}}
\begin{sphinxthebibliography}{attentio}
\bibitem[GenAI]{reference:genai}
\sphinxAtStartPar
Wenqiang Feng, Di Zhen.
\sphinxhref{https://runawayhorse001.github.io/GenAI\_Best\_Practices}{GenAI: Best Practices}, 2024.
\bibitem[PySpark]{reference:pyspark}
\sphinxAtStartPar
Wenqiang Feng.
\sphinxhref{https://runawayhorse001.github.io/LearningApacheSpark}{Learning Apache Spark with Python}, 2017.
\bibitem[lateChunking]{reference:latechunking}
\sphinxAtStartPar
Michael Gunther etc.
\sphinxhref{https://arxiv.org/pdf/2409.04701}{Late Chunking: Contextual Chunk Embeddings Using Long\sphinxhyphen{}Context Embedding Models}, 2024.
\bibitem[selfRAG]{reference:selfrag}
\sphinxAtStartPar
Akari Asai etc.
\sphinxhref{https://arxiv.org/pdf/2310.11511}{Self\sphinxhyphen{}RAG: Learning to Retrieve, Generate, and Critique through Self\sphinxhyphen{}Reflection}, 2023.
\bibitem[PEFT]{reference:peft}
\sphinxAtStartPar
Yunho Mo etc.
\sphinxhref{https://www.mdpi.com/2227-7390/11/14/3048}{Parameter\sphinxhyphen{}Efficient Fine\sphinxhyphen{}Tuning Method for Task\sphinxhyphen{}Oriented Dialogue Systems}, 2023.
\bibitem[fineTuneEmbedding]{reference:finetuneembedding}
\sphinxAtStartPar
Philipp Schmid.
\sphinxhref{https://www.philschmid.de/fine-tune-embedding-model-for-rag}{Fine\sphinxhyphen{}tune Embedding models for Retrieval Augmented Generation (RAG)}, 2024.
\bibitem[attentionAllYouNeed]{reference:attentionallyouneed}
\sphinxAtStartPar
Ashish Vaswani etc.
\sphinxhref{https://arxiv.org/pdf/1706.03762}{Attention Is All You Need}, 2017.
\bibitem[fineTuneLLM]{reference:finetunellm}
\sphinxAtStartPar
Maxime Labonne.
\sphinxhref{https://mlabonne.github.io/blog/posts/Fine\_Tune\_Your\_Own\_Llama\_2\_Model\_in\_a\_Colab\_Notebook.html}{Fine\sphinxhyphen{}Tune Your Own Llama 2 Model in a Colab Notebook}, 2024.
\bibitem[GEval]{reference:geval}
\sphinxAtStartPar
Yang Liu.
\sphinxhref{https://arxiv.org/pdf/2303.16634}{G\sphinxhyphen{}EVAL: NLG Evaluation using GPT\sphinxhyphen{}4 with Better Human Alignment}, 2023.
\end{sphinxthebibliography}



\renewcommand{\indexname}{Index}
\printindex
\end{document}